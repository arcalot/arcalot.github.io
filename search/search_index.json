{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Arcalot: Another Repository Containing A Lot Of Things","text":"<p>The Arcalot community develops tools, plugins, and libraries that you can use either standalone as a library, and/or via a user interface or CLI. You can run the tools locally, remotely, or as part of a bigger system. Arcalot:</p> <ul> <li>Helps you create workflows with normalized input and output schemas</li> <li>Provides you with assisted and automated root cause analysis for the workflows you create as well as CI and other log systems</li> <li>Provides stable plugins for several workloads</li> </ul>"},{"location":"#arcaflow","title":"Arcaflow","text":"<p>Arcaflow is a workflow engine consisting of three main components:</p> <ul> <li>Core engine</li> <li>UI</li> <li>Plugins (including SDKs for Go and Python to write your own plugins)</li> </ul> <p>It allows you to click and drag plugins into a workflow for your systems and, if needed, feed the resulting data back into the UI for further analysis. You can also use it just to generate a workflow with parallel and subsequent tasks via the command line. There is a range of supported plugins, written either in Go or Python.</p> <p>Read more</p>"},{"location":"#arcalog","title":"Arcalog","text":"<p>Arcalog can assist you with or automate your root cause analysis in CI or other log systems either as a standalone tool or by embedding it into your applications.</p> <p>It also provides additional tooling to download jobs from various log systems or add your own log files for analysis.</p> <p>Read more</p>"},{"location":"#community","title":"Community","text":"<p>You can find our general community health files like our code of conduct and contribution guidelines in the .github repository. If you have any questions or suggestions, please use the issues in the respective repository or contribute to the discussions.</p> <p>If you would like to contribute, check out the issues in the individual repositories and our project boards where we organize our work.</p> <p>If you want to participate in our bi-weekly meeting you can add our recurring meeting to your calendar: Arcalot Project Community meeting (iCal)</p>"},{"location":"arcaflow/","title":"Arcaflow: The noble workflow engine","text":"<p>Arcaflow is a workflow engine in development which provides the ability to execute workflow steps in sequence, in parallel, repeatedly, etc. The main difference to competitors such as Netflix Conductor is the ability to run ad-hoc workflows without an infrastructure setup required.</p> <p>The engine uses containers to execute plugins and runs them either locally in Docker/Podman or remotely on a Kubernetes cluster. The workflow system is strongly typed and allows for generating JSON schema and OpenAPI documents for all data formats involved.</p> <p>A long-term goal is to provide the ability to package workflows and the engine together into CLI tools, webservices, Kubernetes operators, or integrated in a CI system with no additional coding work involved.</p> <p>The planned user interface will allow for editing workflows and reviewing the executions in detail.</p>"},{"location":"arcaflow/#roadmap","title":"Roadmap","text":"<p>Our roadmap can be found on GitHub.</p>"},{"location":"arcaflow/#use-cases","title":"Use cases","text":"<p>Our primary use case at this time is running performance and chaos testing tools on demand. Secondary use cases that we are considering:</p> <ul> <li>QE/testing</li> <li>Security testing</li> <li>ETL and other infrastructure migration jobs (once data streaming is available)</li> </ul>"},{"location":"arcaflow/#architecture","title":"Architecture","text":"<pre><code>flowchart LR\n    subgraph laptop[Your laptop]\n        direction LR\n\n        ui(UI)\n        engine(Engine)\n        git(Git)\n\n        ui -- Workflow --&gt; engine\n        ui -- Workflow --&gt; git -- Workflow --&gt; engine\n        engine -- Execution results --&gt; ui\n    end\n\n    subgraph docker[Docker/Podman&lt;br&gt;on your laptop]\n        direction LR\n\n        plugins1(Plugin)\n\n        engine -- Step execution --&gt; plugins1\n    end\n    engine -- Launch plugin --&gt; docker\n\n    subgraph k8s[Kubernetes]\n        direction LR\n\n        plugins2(Plugin)\n\n        engine -- Step execution --&gt; plugins2\n    end\n    engine -- Launch plugin --&gt; k8s\n\n    apis(Other APIs)\n    plugins1 --&gt; apis\n    plugins2 --&gt; apis    </code></pre> <p>The Arcaflow architecture consists of the following 3 keys elements:</p> <ol> <li>Plugins</li> <li>The Engine</li> <li>The User Interface</li> </ol>"},{"location":"arcaflow/#schemas","title":"Schemas","text":"<p>A core element of the Arcaflow system is the schema system. Each plugin and the engine itself will provide a machine-readable data structure that describes what inputs are expected and what outputs may be produced. If you are familiar with JSON schema or OpenAPI, this is similar, and Arcaflow can produce those schema documents. However, the Arcaflow system is stricter than those industry standards to optimize for performance and simpler implementation in all supported programming languages.</p>"},{"location":"arcaflow/#plugins","title":"Plugins","text":"<p>Plugins provide execution for one or more steps for a workflow. The job of a plugin is to do one job and do it well. They provide a thin layer over third party tools, or an own implementation of features. Their main job is to provide accurate input and output schema information to the engine and transform the data as needed.</p> <p>For example, a plugin may output unformatted text, which a plugin has to parse and build a machine-readable data structure for that information. This reformatting of data allows the engine to pipe data between steps and reliably check the data for faults.</p> <p>The current plan is to provide plugin SDKs for Python, GO, and Rust (in that order).</p>"},{"location":"arcaflow/#engine","title":"Engine","text":"<p>The engine is responsible for the orchestration of the workflow steps. It has several duties:</p> <ol> <li>Provide schemas for workflow files, read workflows and construct execution graphs.</li> <li>Type-check the execution graphs to make sure that the data transfers between steps are typesafe.</li> <li>Orchestrate plugin execution with Docker, Podman and Kubernetes.</li> <li>Execute the workflow, following the workflow rules.</li> </ol> <p>The engine itself is designed to be run from a command line interface, possibly as a webserver, but is not designed to run in a redundant fashion. Instead of implementing redundancy itself, the engine will receive support to execute workflows in third party systems, such as Kafka.</p> <p>A stretch goal for the engine is to make it fully embeddable, possibly with in-binary workflows and execution images to make them easily to ship in network-restricted environments. </p>"},{"location":"arcaflow/#user-interface","title":"User Interface","text":"<p>The user interface has two goals:</p> <ol> <li>Allow users to edit workflows</li> <li>Inspect workflow results, debugging possible failures </li> </ol> <p>Future possible extensions will allow for integrating the user interface into other systems for using the workflow engine as an embedded system.</p>"},{"location":"arcaflow/getting-started/","title":"Arcaflow Getting Started Guide","text":""},{"location":"arcaflow/getting-started/#introduction","title":"Introduction","text":"<p>Arcaflow is a modular system that enables engineers to easily build complex parallelized workflows without requiring any pre-installation or deployment of prerequisite software stacks. It has a plugin architecture that is used to build workflows, and execution of the workflows is coordinated by an engine. Workflows are composable and highly portable, capable of orchestrating complex interrelated actions between plugins. This effectively allows for engineering workflow expertise to be packaged up, version controlled, and shared for repeatability across environments and platforms.</p> <p>The engine component is intended to run from your laptop, jump host, or wherever you have network connectivity to the target environment. No installation is required of any Arcaflow components, either on your system or the target environment. The engine processes the workflow definition, invokes the plugins in the target environment, and passes the required data to the plugins as directed by the workflow.</p> <p>The plugins are containers that can speak the engine\u2019s CBOR protocol and that have explicitly defined input and output schemas. Plugins can be run locally via Docker or Podman, or in a remote Kubernetes cluster (and in the future on a remote system via SSH and Docker/Podman). Plugins can also be run alone from the command line, independent of the engine.</p>"},{"location":"arcaflow/getting-started/#workflow-basics","title":"Workflow Basics","text":"<p>Logically, a workflow looks like a path being followed from one plugin to another. Functionally, it works in a star pattern with the engine at the center. So the output of a plugin is passed back to the engine, which then hands off data to the next plugin(s).</p>"},{"location":"arcaflow/getting-started/#logical-flow","title":"Logical Flow","text":"<pre><code>flowchart TD\ninput(input)--&gt;plugin1[plugin]\ninput--&gt;plugin2[plugin]\ninput--&gt;plugin3[plugin]\nplugin1--&gt;plugin4[plugin]\nplugin2--&gt;plugin4\nplugin3---&gt;output(output)\nplugin4--&gt;output</code></pre>"},{"location":"arcaflow/getting-started/#functional-flow","title":"Functional Flow","text":"<pre><code>flowchart TD\ninput(input)--&gt;engine((engine))\nengine--&gt;plugin1[plugin]--&gt;engine\nengine--&gt;plugin2[plugin]--&gt;engine\nengine--&gt;plugin3[plugin]--&gt;engine\nengine--&gt;output(output)</code></pre>"},{"location":"arcaflow/getting-started/#example-workflow","title":"Example Workflow","text":"<p>Consider below a sample workflow that runs a sysbench CPU load, a PCP metrics collector, an Ansible gather facts metadata collector, and sends the output to an Elasticsearch index. A bonus feature we get from the engine is that it will output the workflow in mermaid format for rendering, so we can see that it looks like this visually (error nodes are removed below for simplicity):</p> <pre><code>flowchart LR\nsubgraph input\ninput.sysbench_threads\ninput.sysbench_events\ninput.elastic_password\ninput.sysbench_runtime\ninput.elastic_index\ninput.pmlogger_interval\ninput.sysbench_cpumaxprime\ninput.elastic_username\ninput.elastic_host\nend\nsteps.metadata--&gt;steps.metadata.outputs.success\nsteps.metadata--&gt;steps.metadata.outputs.error\ninput.elastic_password--&gt;steps.opensearch\nsteps.opensearch.outputs.success--&gt;output\nsteps.pcp.outputs.success--&gt;steps.opensearch\nsteps.pcp.outputs.success--&gt;output\ninput.pmlogger_interval--&gt;steps.pcp\nsteps.sysbench.outputs.success--&gt;steps.opensearch\nsteps.sysbench.outputs.success--&gt;output\nsteps.metadata.outputs.success--&gt;steps.opensearch\nsteps.metadata.outputs.success--&gt;output\ninput.elastic_index--&gt;steps.opensearch\ninput.sysbench_runtime--&gt;steps.pcp\ninput.sysbench_runtime--&gt;steps.sysbench\ninput.elastic_host--&gt;steps.opensearch\ninput.elastic_username--&gt;steps.opensearch\ninput.sysbench_events--&gt;steps.sysbench\ninput.sysbench_cpumaxprime--&gt;steps.sysbench\nsteps.opensearch--&gt;steps.opensearch.outputs.success\nsteps.opensearch--&gt;steps.opensearch.outputs.error\ninput.sysbench_threads--&gt;steps.sysbench\nsteps.pcp--&gt;steps.pcp.outputs.error\nsteps.pcp--&gt;steps.pcp.outputs.success\nsteps.sysbench--&gt;steps.sysbench.outputs.error\nsteps.sysbench--&gt;steps.sysbench.outputs.success</code></pre> <p>This example workflow expects input parameters that are passed down to the plugins, in this case to the PCP, sysbench, and opensearch plugins. These parameters determine the details of the actions that those plugins will perform. The metadata plugin used here requires no inputs, as evidenced in the workflow diagram. The success outputs of the PCP, sysbench, and metadata plugins are then directed to the elasticsearch plugin, and and all success outputs are directed to the output of the workflow.</p> <p>Note: The complete example workflow definition is below in the Using and Contributing Level 2 section.</p>"},{"location":"arcaflow/getting-started/#using-and-contributing","title":"Using and Contributing","text":"<p>The entry point for working with Arcaflow as a new user is intended to be very low. Pre-composed workflows are things you should be able to download and use with very little in terms of prerequisites, allowing you with little experience to run workflows in the same ways as domain experts.</p> <p>Moving up through layers of sophistication as a user and contributor should be equally straightforward. As you become familiar with running workflows, you may be drawn into tweaking and modifying those workflows to suit your needs, or further into authoring new plugins to expand functionality or even into contributing to our core components. The sections below should give you an idea of how to get started at each level of sophistication.</p>"},{"location":"arcaflow/getting-started/#level-0","title":"Level 0","text":"<p>Yeoman - Workflow User</p> <p>Welcome to the community! We are more than happy to help you get started. You should get a feel for things by running a workflow or two. Below is an example you can try out. You will need a Golang runtime and Docker to run the containers (Podman can be used with the system service enabled for socket connections, which are required by the engine to communicate with the plugins). The example used here is the same one from the Example Workflow section above.</p> <p>Clone the engine: <pre><code>$ git clone https://github.com/arcalot/arcaflow-engine.git\n</code></pre></p> <p>Clone the workflows and set your workflow directory path: <pre><code>$ git clone https://github.com/arcalot/arcaflow-workflows.git\n$ export WFPATH=$(pwd)/arcaflow-workflows/example-workflow\n</code></pre></p> <p>Run the workflow (the containers will run on your local machine via Docker): <pre><code>$ cd arcaflow-engine\n$ go run cmd/arcaflow/main.go -input ${WFPATH}/input.yaml -config ${WFPATH}/config.yaml -context ${WFPATH}\n</code></pre></p> <p>The <code>config.yaml</code> file is set for debug output, so you\u2019ll get a lot returned to the terminal (including the mermaid code mentioned above). This workflow is set to simply return the output of the various plugins, so in the end you\u2019ll get that formatted content dumped to the terminal.</p>"},{"location":"arcaflow/getting-started/#level-1","title":"Level 1","text":"<p>Page - Advanced Workflow User</p> <p>The next layer of sophistication is modifying the test parameters, which are in the <code>input.yaml</code> file referenced in the above command. For our simple workflow here, there are parameters to adjust how the CPU stress test is performed and to adjust the resolution of PCP\u2019s data collection. You can freely adjust these parameters to your needs without needing to change anything about the workflow itself. This requires some understanding of what the underlying sysbench and PCP tools do, and of course caution should be taken since this test will apply load to the system where it is run.</p> <p>The example <code>input.yaml</code> file looks like this: <pre><code>pmlogger_interval: 1\nsysbench_threads: 20\nsysbench_events: 0\nsysbench_cpumaxprime: 12000\nsysbench_runtime: 20\nelastic_host: foo\nelastic_username: foo\nelastic_password: foo\nelastic_index: foo\n</code></pre></p>"},{"location":"arcaflow/getting-started/#level-2","title":"Level 2","text":"<p>Squire - Workflow Creator</p> <p>So you\u2019re more adventurous and want to change or author workflows? This is the layer at which we think most of our technical users will spend a majority of their effort. Our goals of packaging, version controlling, and shipping domain expertise are primarily facilitated here. A workflow author dreams up a series of tests with various loops and parallelizations they want to run, determines how to collect and transport data and metadata, and then bundles this all into a workflow that can be shared as easily as the one presented in the examples above. A workflow user just needs the engine and your <code>workflow.yaml</code> file. That\u2019s it.</p> <p>The workflow file has an input section where it defines the workflow schema. The workflow author can get creative here in how they want to represent the available parameters to the user or set defaults, and there are mechanics for self-documentation when good practices are followed with schema metadata. Then there is a steps section, which defines the plugins and their relationships. In the reference examples here, we show some data passing both from the input section to the plugins and between plugins where outputs are passed to the elasticsearch plugin (we have another example with uperf that gets more complicated with kubernetes and data passing, once you\u2019re ready to dig in more). Then finally the output section defines what the workflow will return to the user.</p> <p>The complete workflow definition for the example above looks like this: <pre><code>input:\nroot: RootObject\nobjects:\nRootObject:\nid: RootObject\nproperties:\npmlogger_interval:\ndisplay:\ndescription: The logger collection interval for PCP pmlogger\nname: PCP pmlogger collection interval\ntype:\ntype_id: integer\nsysbench_threads:\ndisplay:\ndescription: The number of threads sysbench will run\nname: sysbench threads\ntype:\ntype_id: integer\nsysbench_events:\ndisplay:\ndescription: The number of events sysbench will run\nname: sysbench events\ntype:\ntype_id: integer\nsysbench_cpumaxprime:\ndisplay:\ndescription: The upper limit of the number of prime numbers generated\nname: sysbench cpu max primes\ntype:\ntype_id: integer\nsysbench_runtime:\ndisplay:\ndescription: The total runtime in seconds for the sysbench tests\nname: sysbench runtime seconds\ntype:\ntype_id: integer\nelastic_host:\ndisplay:\ndescription: The host URL for the ElasticSearch service\nname: elasticsearch host url\ntype:\ntype_id: string\nelastic_username:\ndisplay:\ndescription: The username for the ElasticSearch service\nname: elasticsearch username\ntype:\ntype_id: string\nelastic_password:\ndisplay:\ndescription: The password for the ElasticSearch service\nname: elasticsearch password\ntype:\ntype_id: string\nelastic_index:\ndisplay:\ndescription: The index for the ElasticSearch service\nname: elasticsearch index\ntype:\ntype_id: string\nsteps:\npcp:\nplugin: quay.io/arcalot/arcaflow-plugin-pcp:0.2.0\nstep: start-pcp\ninput:\npmlogger_interval: !expr $.input.pmlogger_interval\nrun_duration: !expr $.input.sysbench_runtime\nsysbench:\nplugin: quay.io/arcalot/arcaflow-plugin-sysbench:0.1.0\nstep: sysbenchcpu\ninput:\nthreads: !expr $.input.sysbench_threads\nevents: !expr $.input.sysbench_events\ncpu-max-prime: !expr $.input.sysbench_cpumaxprime\ntime: !expr $.input.sysbench_runtime\nmetadata:\nplugin: quay.io/arcalot/arcaflow-plugin-metadata:0.1.0\ninput: {}\nopensearch:\nplugin: quay.io/arcalot/arcaflow-plugin-opensearch:0.1.1\ninput:\nurl: !expr $.input.elastic_host\nusername: !expr $.input.elastic_username\npassword: !expr $.input.elastic_password\nindex: !expr $.input.elastic_index\ndata:\npcp: !expr $.steps.pcp.outputs.success\nsysbench: !expr $.steps.sysbench.outputs.success\nmetadata: !expr $.steps.metadata.outputs.success\noutput:\npcp: !expr $.steps.pcp.outputs.success\nsysbench: !expr $.steps.sysbench.outputs.success\nmetadata: !expr $.steps.metadata.outputs.success\nopensearch: !expr $.steps.opensearch.outputs.success\n</code></pre></p>"},{"location":"arcaflow/getting-started/#level-3","title":"Level 3","text":"<p>Knight - Plugin Author</p> <p>So now you want to build plugins or add features to existing plugins? Great! Welcome to the Arcalot Round Table! We provide Software Development Kits (SDKs) for Python and Golang to get you started. The main thing you need to understand is that a plugin is expected to define and adhere to its schemas, so the SDK enforces strict typing, which can be a little strange at first for a Python developer. Optimally, a plugin follows the Unix philosophy of do one thing and do it well, and a plugin should not be created in an opinionated way \u2013 Leave the opinions for how a plugin\u2019s actions will run to the workflow definition as much as possible.</p> <p>When creating a plugin, you should consider how you will expose all parameters and configuration values via a single schema, and collect all output similarly in a single schema. The plugins provide the API endpoints for functions or actions, and workflows glue together those endpoints to make use of the data in an opinionated way. Sometimes creating a schema for a plugin wrapping an existing tool is relatively simple, sometimes it is pretty involved. You can start digging into the technical details more in the Concepts and Plugins sections of the documentation.</p>"},{"location":"arcaflow/getting-started/#level-4","title":"Level 4","text":"<p>Liege - Core Components Contributor</p> <p>If you have a grasp on everything above and still want to dig in deeper, then welcome to core components development! Here you can participate in the development of the workflow engine and its related libraries, the SDKs, the build system, and more.</p>"},{"location":"arcaflow/getting-started/#community","title":"Community","text":"<p>If you\u2019re looking for a place to jump in and help, have a look at our Project boards and our Discussions page. We also manage our charter, code of conduct, and licensing, as well as significant project decisions, via our Arcalot Round Table project. We can also always use help with our documentation efforts.</p>"},{"location":"arcaflow/concepts/plugin-protocol/","title":"Plugin protocol specification","text":"<p>Work in Progress</p> <p>This document is work in progress and may change until the final release!</p> <p>Arcaflow runs plugins locally in a container using Docker or Podman, or remotely in Kubernetes. Each plugin must be containerized and communicates with the engine over standard input/output. This document outlines the protocol the engine and the plugins use to communicate.</p> <p>Hint</p> <p>You do not need this page if you only intend to implement a plugin with the SDK!</p>"},{"location":"arcaflow/concepts/plugin-protocol/#execution-model","title":"Execution model","text":"<p>A single plugin execution is intended to run a single task and not more. This simplifies the code since there is no need to try and clean up after each task. Each plugin is executed in a container and must communicate with the engine over standard input/output. Furthermore, the plugin must add a handler for <code>SIGTERM</code> and properly clean up if there are services running in the background.</p> <p>Each plugin is executed at the start of the workflow, or workflow block, and is terminated only at the end of the current workflow or workflow block. The plugin can safely rely on being able to start a service in the background and then keeping it running until the SIGTERM comes to shut down the container.</p> <p>However, the plugin must, under no circumstances, start doing work until the engine sends the command to do so. This includes starting any services inside the container or outside. This restriction is necessary to be able to launch the plugin with minimal resource consumption locally on the engine host to fetch the schema.</p> <p>The plugin execution is divided into three major steps.</p> <ol> <li>When the plugin is started, it must output the current plugin protocol version and its schema to the standard output. The engine will read this output from the container logs.</li> <li>When it is time to start the work, the engine will send the desired step ID with its input parameters over the standard input. The plugin acknowledges this and starts to work. When the work is complete, the plugin must automatically output the results to the standard output.</li> <li>When a shutdown is desired, the engine will send a <code>SIGTERM</code> to the plugin. The plugin has up to 30 seconds to shut down. The SIGTERM may come at any time, even while the work is still running, and the plugin must appropriately shut down. If the work is not complete, the plugin may attempt to output an error output data to the standard out, but must not do so. If the plugin fails to stop by itself within 30 seconds, the plugin container is forcefully stopped.</li> </ol>"},{"location":"arcaflow/concepts/plugin-protocol/#protocol","title":"Protocol","text":"<p>As a data transport protocol, we use CBOR messages RFC 8949 back to back due to their self-delimiting nature. This section provides the entire protocol as JSON schema below.</p>"},{"location":"arcaflow/concepts/plugin-protocol/#step-0-the-start-output-message","title":"Step 0: The \u201cstart output\u201d message","text":"<p>Because Kubernetes has no clean way of capturing an output right at the start, the initial step of the plugin execution involves the engine sending an empty CBOR message (<code>None</code> or <code>Nil</code>) to the plugin. This indicates, that the plugin may start its output now.</p>"},{"location":"arcaflow/concepts/plugin-protocol/#step-1-hello-message","title":"Step 1: Hello message","text":"<p>The \u201cHello\u201d message is a way for the plugin to introduce itself and present its steps and schema. Transcribed to JSON, a message of this kind would look as follows:</p> <pre><code>{\n\"version\": 1,\n\"steps\": {\n\"step-id-1\": {\n\"name\": \"Step 1\",\n\"description\": \"This is the first step\",\n\"input\": {\n\"schema\": {\n// Input schema\n}\n},\n\"outputs\": {\n\"output-id-1\": {\n\"name\": \"Name for this output kind\",\n\"description\": \"Description for this output\",\n\"schema\": {\n// Output schema\n}\n}\n}\n}\n}\n}\n</code></pre> <p>The schemas must describe the data structure the plugin expects. For a simple hello world input would look as follows:</p> <pre><code>{\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\n\"type\": \"string\"\n}\n}\n}\n</code></pre> <p>The full schema is described below in the Schema section.</p>"},{"location":"arcaflow/concepts/plugin-protocol/#step-2-start-work-message","title":"Step 2: Start work message","text":"<p>The \u201cstart work\u201d message has the following parameters in CBOR:</p> <pre><code>{\n\"id\": \"id-of-the-step-to-execute\",\n\"config\": {\n// Input parameters according to schema here\n}\n}\n</code></pre> <p>The plugin must respond with a CBOR message of the following format:</p> <pre><code>{\n\"status\": \"started\"\n}\n</code></pre>"},{"location":"arcaflow/concepts/plugin-protocol/#step-3a-crash","title":"Step 3/a: Crash","text":"<p>If the plugin execution ended unexpectedly, the plugin should crash and output a reasonable error message to the standard error. The plugin must exit with a non-zero exit status to notify the engine that the execution failed.</p>"},{"location":"arcaflow/concepts/plugin-protocol/#step-3b-output","title":"Step 3/b: Output","text":"<p>When the plugin has executed successfully, it must emit a CBOR message to the standard output:</p> <pre><code>{\n\"output_id\": \"id-of-the-declared-output\",\n\"output_data\": {\n// Result data of the plugin\n},\n\"debug_logs\": \"Unstructured logs here for debugging as a string.\"\n}\n</code></pre>"},{"location":"arcaflow/concepts/plugin-protocol/#schema","title":"Schema","text":"<p>This section contains the exact schema that the plugin sends to the engine.</p> Type: <code>scope</code> Root object: Schema Properties steps (<code>map[string, reference[Step]]</code>) Name: Steps Description: Steps this schema supports. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Step]</code> Referenced object: Step Objects AnySchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> BoolSchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Display (<code>object</code>) Type: <code>object</code> Properties description (<code>string</code>) Name: Description Description: Description for this item if needed. Required: No Minimum: 1 Examples <pre><code>\"Please select the fruit you would like.\"\n</code></pre> icon (<code>string</code>) Name: Icon Description: SVG icon for this item. Must have the declared size of 64x64, must not include additional namespaces, and must not reference external resources. Required: No Minimum: 1 Examples <pre><code>\"&lt;svg ...&gt;&lt;/svg&gt;\"\n</code></pre> name (<code>string</code>) Name: Name Description: Short text serving as a name or title for this item. Required: No Minimum: 1 Examples <pre><code>\"Fruit\"\n</code></pre> Float (<code>object</code>) Type: <code>object</code> Properties max (<code>float</code>) Name: Maximum Description: Maximum value for this float (inclusive). Required: No Examples <pre><code>16.0\n</code></pre> min (<code>float</code>) Name: Minimum Description: Minimum value for this float (inclusive). Required: No Examples <pre><code>5.0\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> Int (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> IntEnum (<code>object</code>) Type: <code>object</code> Properties units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> values (<code>map[int, reference[Display]]</code>) Name: Values Description: Possible values for this field. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>int</code> Value type Type: <code>reference[Display]</code> Referenced object: Display Examples <pre><code>{\"1024\": {\"name\": \"kB\"}, \"1048576\": {\"name\": \"MB\"}}\n</code></pre> List (<code>object</code>) Type: <code>object</code> Properties items (<code>one of[string]</code>) Name: Items Description: ReflectedType definition for items in this list. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> Map (<code>object</code>) Type: <code>object</code> Properties keys (<code>one of[string]</code>) Name: Keys Description: ReflectedType definition for keys in this map. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> values (<code>one of[string]</code>) Name: Values Description: ReflectedType definition for values in this map. Required: No Object (<code>object</code>) Type: <code>object</code> Properties id (<code>string</code>) Name: ID Description: Unique identifier for this object within the current scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> properties (<code>map[string, reference[Property]]</code>) Name: Properties Description: Properties of this object. Required: Yes Key type Type: <code>string</code> Minimum: 1 Value type Type: <code>reference[Property]</code> Referenced object: Property OneOfIntSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[int, one of[string]]</code>) Name: Types Required: No Key type Type: <code>int</code> Value type Type: <code>one of[string]</code> OneOfStringSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[string, one of[string]]</code>) Name: Types Required: No Key type Type: <code>string</code> Value type Type: <code>one of[string]</code> Pattern (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Property (<code>object</code>) Type: <code>object</code> Properties conflicts (<code>list[string]</code>) Name: Conflicts Description: The current property cannot be set if any of the listed properties are set. Required: No List Items Type: <code>string</code> default (<code>string</code>) Name: Default Description: Default value for this property in JSON encoding. The value must be unserializable by the type specified in the type field. Required: No display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display examples (<code>list[string]</code>) Name: Examples Description: Example values for this property, encoded as JSON. Required: No List Items Type: <code>string</code> required (<code>bool</code>) Name: Required Description: When set to true, the value for this field must be provided under all circumstances. Required: No Default<pre><code>true\n</code></pre> required_if (<code>list[string]</code>) Name: Required if Description: Sets the current property to required if any of the properties in this list are set. Required: No List Items Type: <code>string</code> required_if_not (<code>list[string]</code>) Name: Required if not Description: Sets the current property to be required if none of the properties in this list are set. Required: No List Items Type: <code>string</code> type (<code>one of[string]</code>) Name: Type Description: Type definition for this field. Required: Yes Ref (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display id (<code>string</code>) Name: ID Description: Referenced object ID. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Schema (<code>object</code>) Type: <code>object</code> Properties steps (<code>map[string, reference[Step]]</code>) Name: Steps Description: Steps this schema supports. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Step]</code> Referenced object: Step Scope (<code>object</code>) Type: <code>object</code> Properties objects (<code>map[string, reference[Object]]</code>) Name: Objects Description: A set of referencable objects. These objects may contain references themselves. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Object]</code> Referenced object: Object root (<code>string</code>) Name: Root object Description: ID of the root object of the scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Step (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display id (<code>string</code>) Name: ID Description: Machine identifier for this step. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> input (<code>reference[Scope]</code>) Name: Input Description: Input data schema. Required: Yes Referenced object: Scope outputs (<code>map[string, reference[StepOutput]]</code>) Name: Input Description: Input data schema. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[StepOutput]</code> Referenced object: StepOutput StepOutput (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display error (<code>bool</code>) Name: Error Description: If set to true, this output will be treated as an error output. Required: No Default<pre><code>false\n</code></pre> schema (<code>reference[Scope]</code>) Name: Schema Description: Data schema for this particular output. Required: Yes Referenced object: Scope String (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>5\n</code></pre> pattern (<code>pattern</code>) Name: Pattern Description: Regular expression this string must match. Required: No Examples <pre><code>\"^[a-zA-Z]+$\"\n</code></pre> StringEnum (<code>object</code>) Type: <code>object</code> Properties values (<code>map[string, reference[Display]]</code>) Name: Values Description: Mapping where the left side of the map holds the possible value and the right side holds the display value for forms, etc. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>string</code> Value type Type: <code>reference[Display]</code> Referenced object: Display Examples <pre><code>{\n\"apple\": {\n\"name\": \"Apple\"\n},\n\"orange\": {\n\"name\": \"Orange\"\n}\n}\n</code></pre> Unit (<code>object</code>) Type: <code>object</code> Properties name_long_plural (<code>string</code>) Name: Name long (plural) Description: Longer name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"bytes\",\"characters\"\n</code></pre> name_long_singular (<code>string</code>) Name: Name long (singular) Description: Longer name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"byte\",\"character\"\n</code></pre> name_short_plural (<code>string</code>) Name: Name short (plural) Description: Shorter name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"B\",\"chars\"\n</code></pre> name_short_singular (<code>string</code>) Name: Name short (singular) Description: Shorter name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"B\",\"char\"\n</code></pre> Units (<code>object</code>) Type: <code>object</code> Properties base_unit (<code>reference[Unit]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: Yes Referenced object: Unit Examples <pre><code>{\n\"name_short_singular\": \"B\",\n\"name_short_plural\": \"B\",\n\"name_long_singular\": \"byte\",\n\"name_long_plural\": \"bytes\"\n}\n</code></pre> multipliers (<code>map[int, reference[Unit]]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: No Key type Type: <code>int</code> Value type Type: <code>reference[Unit]</code> Referenced object: Unit Examples <pre><code>{\n\"1024\": {\n\"name_short_singular\": \"kB\",\n\"name_short_plural\": \"kB\",\n\"name_long_singular\": \"kilobyte\",\n\"name_long_plural\": \"kilobytes\"\n},\n\"1048576\": {\n\"name_short_singular\": \"MB\",\n\"name_short_plural\": \"MB\",\n\"name_long_singular\": \"megabyte\",\n\"name_long_plural\": \"megabytes\"\n}\n}\n</code></pre>"},{"location":"arcaflow/concepts/typing/","title":"The Arcaflow type system","text":"<p>Work in Progress</p> <p>This document is work in progress and may change until the final release!</p> <p>Arcaflow takes a departure from the classic run-and-pray approach of running workloads and validates workflows for validity before executing them. To do this, Arcaflow starts the plugins as needed before the workflow is run and queries them for their schema. This schema will contain information about what kind of input a plugin requests and what kind of outputs it can produce.</p> <p>A plugin can support multiple workflow steps and must provide information about the data types in its input and output for each step. A step can have exactly one input format, but may declare more than one output.</p> <p>The typesystem is inspired by JSON schema and OpenAPI, but it is more restrictive due to the need to efficiently serialize workloads over various formats.</p>"},{"location":"arcaflow/concepts/typing/#types","title":"Types","text":"<p>The typing system supports the following data types.</p> <ul> <li>Objects are key-value pairs where the keys are always a fixed set of strings and values are of various types declared for each key. They are similar to classes in most programming languages. Fields in objects can be optional, which means they will have no value (commonly known as <code>null</code>, <code>nil</code>, or <code>None</code>), or a default value.</li> <li>OneOf are a special type that is a union of multiple objects, distinguished by a special field called the discriminator.</li> <li>Lists are a sequence of values of the same type. The value type can be any of the other types described in this section. List items must always have a value and cannot be empty (<code>null</code>, <code>nil</code>, or <code>None</code>).</li> <li>Maps are key-value pairs that always have fixed types for both keys and values. Maps with mixed keys or values are not supported. Map keys can only be strings, integers, or enums. Map keys and values must always have a value and cannot be empty (<code>null</code>, <code>nil</code>, or <code>None</code>).</li> <li>Enums are either strings or integers that can take only a fixed set of values. Enums with mixed value types are not supported.</li> <li>Strings are a sequence of bytes.</li> <li>Patterns are regular expressions.</li> <li>Integers are 64-bit numbers that can take both positive and negative values.</li> <li>Floats are 64-bit floating point numbers that can take both positive and negative values.</li> <li>Booleans are values of <code>true</code> or <code>false</code> and cannot take any other values.</li> <li>Scopes and Refs are object-like types that allow you to create circular references (see below).</li> </ul>"},{"location":"arcaflow/concepts/typing/#planned-future-types","title":"Planned future types","text":"<ul> <li>Timestamps are nanosecond-scale timestamp values for a fixed time in UTC. They are stored and transported as integers, but may be unserialized from strings too.</li> <li>Dates are calendar dates without timezone information.</li> <li>Times are the time of a day denominated as hours, minutes, seconds, etc. on a nanosecond scale.</li> <li>Datetimes are date and times together in one field.</li> <li>Durations are nanosecond-scale timespan values.</li> <li>UUIDs are UUID-formatted strings.</li> <li>Sets are an unordered collection of items that can only contain unique items.</li> </ul>"},{"location":"arcaflow/concepts/typing/#validation","title":"Validation","text":"<p>The typing system also contains more in-depth validation than just simple types:</p>"},{"location":"arcaflow/concepts/typing/#strings","title":"Strings","text":"<p>Strings can have a minimum or maximum length, as well as validation against a regular expression.</p>"},{"location":"arcaflow/concepts/typing/#ints-floats","title":"Ints, floats","text":"<p>Number types can have a minimum and maximum value (inclusive).</p>"},{"location":"arcaflow/concepts/typing/#booleans","title":"Booleans","text":"<p>Boolean types can take a value of either <code>true</code> or <code>false</code>, but when unserializing from YAML or JSON formats, strings or int values of <code>true</code>, <code>yes</code>, <code>on</code>, <code>enable</code>, <code>enabled</code>, <code>1</code>, <code>false</code>, <code>no</code>, <code>off</code>, <code>disable</code>, <code>disabled</code> or <code>0</code> are also accepted.</p>"},{"location":"arcaflow/concepts/typing/#lists-maps","title":"Lists, maps","text":"<p>Lists a7nd maps can have constraints on the minimum or maximum number of items in them (inclusive).</p>"},{"location":"arcaflow/concepts/typing/#objects","title":"Objects","text":"<p>Object fields can have several constraints:</p> <ul> <li><code>required_if</code> has a list of other fields that, if set, make the current field required.</li> <li><code>required_if_not</code> has a list of other fields that, if none are set, make the current field required.</li> <li><code>conflicts</code> has a list of other fields that cannot be set together with the current field.</li> </ul>"},{"location":"arcaflow/concepts/typing/#oneof","title":"OneOf","text":"<p>When you need to create a list of multiple object types, or simply have an either-or choice between two object types, you can use the OneOf type. This field uses an already existing field of the underlying objects, or adds an extra field to the schema to distinguish between the different types. Translated to JSON, you might see something like this:</p> <pre><code>{\n\"_type\": \"Greeter\",\n\"message\": \"Hello world!\"\n}\n</code></pre>"},{"location":"arcaflow/concepts/typing/#scopes-and-refs","title":"Scopes and refs","text":"<p>Objects, on their own, cannot create circular references. It is not possible to create two objects that refer to each other. That\u2019s where scopes and refs come into play. Scopes hold a list of objects, identified by an ID. Refs inside the scope (for example, in an object property) can refer to these IDs. Every scope has a root object, which will be used to provide its \u201cobject-like\u201d features, such as a list of fields.</p> <p>For example:</p> <pre><code>objects:\nmy_root_object:\nid: my_root_object\nproperties:\n...\nroot: my_root_object\n</code></pre> <p>Multiple scopes can be nested into each other. The ref always refers to the closest scope up the tree. Multiple scopes can be used when combining objects from several sources (e.g. several plugins) into one schema to avoid conflicting ID assignments.</p>"},{"location":"arcaflow/concepts/typing/#metadata","title":"Metadata","text":"<p>Object fields can also declare metadata that will help with creating user interfaces for the object. These fields are:</p> <ul> <li>name: A user-readable name for the field.</li> <li>description: A user-readable description for the field. It may contain newlines, but no other formatting is allowed.</li> <li>icon: SVG icon</li> </ul>"},{"location":"arcaflow/concepts/typing/#intent-inference","title":"Intent inference","text":"<p>For display purposes, the type system is designed so that it can infer the intent of the data. We wish to communicate the following intents:</p> <ul> <li>Graphs are x-y values of timestamps mapped to one or more values.</li> <li>Log lines are timestamps associated with text.</li> <li>Events are timestamps associated with other structured data.</li> </ul> <p>We explicitly document the following inference rules, which will probably change in the future.</p> <ul> <li>A map with keys of timestamps and values of integers or floats is rendered as a graph.</li> <li>A map with keys of timestamps and values of objects consisting only of integers and floats is rendered as a graph.</li> <li>A map with keys of timestamps and values of strings is considered a log line.</li> <li>A map with keys of timestamps and objects that don\u2019t match the rules above are considered an event.</li> <li>A map with keys of short strings and integer or float values is considered a pie chart.</li> <li>A list of objects consisting of a single timestamp and otherwise only integers and floats is rendered as a graph.</li> <li>A list of objects with a single timestamp and a single string are considered a log line.</li> <li>A list of objects with a single short string and a single integer or float is considered a pie chart.</li> <li>A list of objects consisting of no more than one timestamp and multiple other fields not matching the rules above is considered an event.</li> <li>If an object has a field called \u201ctitle\u201d, \u201cname\u201d, or \u201clabel\u201d, it will be used as a label for the current data set in a chart, or as a title for the wrapping box for the user interface elements.</li> </ul>"},{"location":"arcaflow/concepts/typing/#reference-manual","title":"Reference Manual","text":"<p>This section explains how a scope object looks like. The plugin protocol contains a few more types that are used when communicating a schema.</p> Type: <code>scope</code> Root object: Scope Properties objects (<code>map[string, reference[Object]]</code>) Name: Objects Description: A set of referencable objects. These objects may contain references themselves. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Object]</code> Referenced object: Object root (<code>string</code>) Name: Root object Description: ID of the root object of the scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Objects AnySchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> BoolSchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Display (<code>object</code>) Type: <code>object</code> Properties description (<code>string</code>) Name: Description Description: Description for this item if needed. Required: No Minimum: 1 Examples <pre><code>\"Please select the fruit you would like.\"\n</code></pre> icon (<code>string</code>) Name: Icon Description: SVG icon for this item. Must have the declared size of 64x64, must not include additional namespaces, and must not reference external resources. Required: No Minimum: 1 Examples <pre><code>\"&lt;svg ...&gt;&lt;/svg&gt;\"\n</code></pre> name (<code>string</code>) Name: Name Description: Short text serving as a name or title for this item. Required: No Minimum: 1 Examples <pre><code>\"Fruit\"\n</code></pre> Float (<code>object</code>) Type: <code>object</code> Properties max (<code>float</code>) Name: Maximum Description: Maximum value for this float (inclusive). Required: No Examples <pre><code>16.0\n</code></pre> min (<code>float</code>) Name: Minimum Description: Minimum value for this float (inclusive). Required: No Examples <pre><code>5.0\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> Int (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> IntEnum (<code>object</code>) Type: <code>object</code> Properties units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> values (<code>map[int, reference[Display]]</code>) Name: Values Description: Possible values for this field. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>int</code> Value type Type: <code>reference[Display]</code> Referenced object: Display Examples <pre><code>{\"1024\": {\"name\": \"kB\"}, \"1048576\": {\"name\": \"MB\"}}\n</code></pre> List (<code>object</code>) Type: <code>object</code> Properties items (<code>one of[string]</code>) Name: Items Description: ReflectedType definition for items in this list. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> Map (<code>object</code>) Type: <code>object</code> Properties keys (<code>one of[string]</code>) Name: Keys Description: ReflectedType definition for keys in this map. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> values (<code>one of[string]</code>) Name: Values Description: ReflectedType definition for values in this map. Required: No Object (<code>object</code>) Type: <code>object</code> Properties id (<code>string</code>) Name: ID Description: Unique identifier for this object within the current scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> properties (<code>map[string, reference[Property]]</code>) Name: Properties Description: Properties of this object. Required: Yes Key type Type: <code>string</code> Minimum: 1 Value type Type: <code>reference[Property]</code> Referenced object: Property OneOfIntSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[int, one of[string]]</code>) Name: Types Required: No Key type Type: <code>int</code> Value type Type: <code>one of[string]</code> OneOfStringSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[string, one of[string]]</code>) Name: Types Required: No Key type Type: <code>string</code> Value type Type: <code>one of[string]</code> Pattern (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Property (<code>object</code>) Type: <code>object</code> Properties conflicts (<code>list[string]</code>) Name: Conflicts Description: The current property cannot be set if any of the listed properties are set. Required: No List Items Type: <code>string</code> default (<code>string</code>) Name: Default Description: Default value for this property in JSON encoding. The value must be unserializable by the type specified in the type field. Required: No display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display examples (<code>list[string]</code>) Name: Examples Description: Example values for this property, encoded as JSON. Required: No List Items Type: <code>string</code> required (<code>bool</code>) Name: Required Description: When set to true, the value for this field must be provided under all circumstances. Required: No Default<pre><code>true\n</code></pre> required_if (<code>list[string]</code>) Name: Required if Description: Sets the current property to required if any of the properties in this list are set. Required: No List Items Type: <code>string</code> required_if_not (<code>list[string]</code>) Name: Required if not Description: Sets the current property to be required if none of the properties in this list are set. Required: No List Items Type: <code>string</code> type (<code>one of[string]</code>) Name: Type Description: Type definition for this field. Required: Yes Ref (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display id (<code>string</code>) Name: ID Description: Referenced object ID. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Scope (<code>object</code>) Type: <code>object</code> Properties objects (<code>map[string, reference[Object]]</code>) Name: Objects Description: A set of referencable objects. These objects may contain references themselves. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Object]</code> Referenced object: Object root (<code>string</code>) Name: Root object Description: ID of the root object of the scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> String (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>5\n</code></pre> pattern (<code>pattern</code>) Name: Pattern Description: Regular expression this string must match. Required: No Examples <pre><code>\"^[a-zA-Z]+$\"\n</code></pre> StringEnum (<code>object</code>) Type: <code>object</code> Properties values (<code>map[string, reference[Display]]</code>) Name: Values Description: Mapping where the left side of the map holds the possible value and the right side holds the display value for forms, etc. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>string</code> Value type Type: <code>reference[Display]</code> Referenced object: Display Examples <pre><code>{\n\"apple\": {\n\"name\": \"Apple\"\n},\n\"orange\": {\n\"name\": \"Orange\"\n}\n}\n</code></pre> Unit (<code>object</code>) Type: <code>object</code> Properties name_long_plural (<code>string</code>) Name: Name long (plural) Description: Longer name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"bytes\",\"characters\"\n</code></pre> name_long_singular (<code>string</code>) Name: Name long (singular) Description: Longer name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"byte\",\"character\"\n</code></pre> name_short_plural (<code>string</code>) Name: Name short (plural) Description: Shorter name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"B\",\"chars\"\n</code></pre> name_short_singular (<code>string</code>) Name: Name short (singular) Description: Shorter name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"B\",\"char\"\n</code></pre> Units (<code>object</code>) Type: <code>object</code> Properties base_unit (<code>reference[Unit]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: Yes Referenced object: Unit Examples <pre><code>{\n\"name_short_singular\": \"B\",\n\"name_short_plural\": \"B\",\n\"name_long_singular\": \"byte\",\n\"name_long_plural\": \"bytes\"\n}\n</code></pre> multipliers (<code>map[int, reference[Unit]]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: No Key type Type: <code>int</code> Value type Type: <code>reference[Unit]</code> Referenced object: Unit Examples <pre><code>{\n\"1024\": {\n\"name_short_singular\": \"kB\",\n\"name_short_plural\": \"kB\",\n\"name_long_singular\": \"kilobyte\",\n\"name_long_plural\": \"kilobytes\"\n},\n\"1048576\": {\n\"name_short_singular\": \"MB\",\n\"name_short_plural\": \"MB\",\n\"name_long_singular\": \"megabyte\",\n\"name_long_plural\": \"megabytes\"\n}\n}\n</code></pre>"},{"location":"arcaflow/concepts/workflows/","title":"Arcaflow Workflows","text":"<p>Work in Progress</p> <p>This document is work in progress and may change until the final release!</p>"},{"location":"arcaflow/concepts/workflows/#steps","title":"Steps","text":"<p>Workflows are a way to describe a sequence or parallel execution of individual steps. The steps are provided exclusively by plugins. The simplest workflow looks like this:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]</code></pre> <p>However, this is only true if the step only has one output. Most steps will at least have two possible outputs, for success and error states:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]: yes\n  Step --&gt; [*]: no</code></pre> <p>Plugins can declare as many outputs as needed, with custom names. The workflow engine doesn\u2019t make a distinction based on the names, all outputs are treated equal for execution. However, a few names are treated special for display purposes only:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]: success\n  Step --&gt; [*]: warning\n  Step --&gt; [*]: error</code></pre> <p>These three output names (<code>success</code>, <code>warning</code>, and <code>error</code>) will be colored accordingly in the user interfaces. Other names may be used, but will not be colored.</p> <p>An important rule is that one step must always end in exactly one output. No step must end without an output, and no step can end in more than one output. This provides a mechanism to direct the flow of the workflow execution.</p> <p>Plugins must also explicitly declare what parameters they expect as input for the step, and the data types of these and what parameters they will produce as output. For more detaisl about this see the Type system page.</p>"},{"location":"arcaflow/concepts/workflows/#background-processes","title":"Background processes","text":"<p>Each plugin will only be invoked once, allowing plugins to run background processes, such as server applications. The plugins must handle SIGINT and SIGTERM events properly.</p>"},{"location":"arcaflow/concepts/workflows/#interconnecting-steps","title":"Interconnecting steps","text":"<p>When two steps are connected, they will be executed after each other:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  Step1 --&gt; Step2\n  Step2 --&gt; [*]</code></pre> <p>Similarly, when two steps are not directly connected, they may be executed in parallel:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  [*] --&gt; Step2\n  Step1 --&gt; [*]\n  Step2 --&gt; [*]</code></pre> <p>You can use the interconnection to direct the flow of step outputs:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  Step3: Step 3\n  [*] --&gt; Step1\n  Step1 --&gt; Step2: success\n  Step1 --&gt; Step3: error\n  Step2 --&gt; [*]\n  Step3 --&gt; [*]</code></pre>"},{"location":"arcaflow/concepts/workflows/#unconnected-steps","title":"Unconnected steps","text":"<p>If you leave outputs unconnected, the workflow will be a failure and the engine will exit with a non-zero exit code. However, the engine will still attempt to finish whatever steps it can.</p>"},{"location":"arcaflow/concepts/workflows/#passing-data-between-steps","title":"Passing data between steps","text":"<p>When two steps are connected, you have the ability to pass data between them. Emblematically described:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  Step1 --&gt; Step2: input_1 = $.step1.output_1\n  Step2 --&gt; [*]</code></pre> <p>The data type of the input on Step 2 in this case must match the result of the expression. If the data type does not match, the workflow will not be executed.</p>"},{"location":"arcaflow/concepts/workflows/#undefined-inputs","title":"Undefined inputs","text":"<p>Step inputs can either be required or optional. When a step input is required, it must be configured or the workflow will fail to execute. However, there are cases when the inputs cannot be determined from previous steps. In this case, the workflow start can be connected and the required inputs can be obtained from the user when running the workflow:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  [*] --&gt; Step2: input_1 = $.start.option_1\n  Step1 --&gt; Step2: input_2 = $.step1.output_1\n  Step2 --&gt; [*]</code></pre> <p>This is typically the case when credentials, such as database access, etc. are required.</p>"},{"location":"arcaflow/concepts/workflows/#outputs","title":"Outputs","text":"<p>The output for each step is preserved for later inspection. However, the workflow can explicitly declare outputs. These outputs are usable in scripted environments as a direct output of the workflow:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]: output_1 = $.step1.output_1</code></pre>"},{"location":"arcaflow/concepts/workflows/#execution-environment","title":"Execution environment","text":"<p>Workflow plugins will always run in containers. You can configure these containers to run locally, or you can connect a remote execution environment. At this time the two environments that are supported are Docker (or Podman using the Docker compatibility API) and Kubernetes. Later on we plan to add container execution via SSH.</p> <p>A local Docker (or Docker-like) environment is always required. The workflow engine needs this to obtain schema information from the plugins, as well as for mirroring plugins to a network-disconnected environment.</p> <p>Plugins must also make sure that they can execute in an unprivileged container, even when they later on need to be executed in a privileged environment. This is needed to obtain the schema before executing it in the target environment.</p> <p>You can configure any step to run in a remote environment as long as the remote environment can pull the container image. The engine provides the facilities to mirror the required plugins into a disconnected environment. Plugins must not make network calls during startup, and they should come with everything they need to run built in, unless their specific purpose is to install something on step execution. The engine will execute the plugin container image in a network-disconnected environment at startup to obtain its schema. If it fails to execute without internet, the workflow will not run.</p> <p>The execution environment has further parameters. For Docker, these options are specific to Docker, for Kubernetes they are specific to Kubernetes. For Kubernetes, you can also specify constraints on where the step is executed.</p>"},{"location":"arcaflow/concepts/workflows/#flow-control","title":"Flow control","text":"<p>The workflow contains several flow control operations. These flow control operations are not implemented by plugins, but are part of the workflow engine itself.</p>"},{"location":"arcaflow/concepts/workflows/#abort","title":"Abort","text":"<p>The abort flow control is a quick way to exit out of a workflow. This is useful when entering a terminal error state and the workflow output data would be useless anyway.</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step1\n  Step1 --&gt; Abort: Output 1\n  Step1 --&gt; Step2: Output 2\n  Step2 --&gt; [*]</code></pre> <p>However, this is only required if you want to abort the workflow immediately. If you want an error case to result in the workflow failing, but whatever steps can be finished being finished, you can leave error outputs unconnected.</p>"},{"location":"arcaflow/concepts/workflows/#do-while","title":"Do-while","text":"<p>A do-while block will execute the steps in it as long as a certain condition is met. The condition is derived from the output of the step or steps executed inside the loop:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; DoWhile\n  state DoWhile {\n    [*] --&gt; Step1\n    Step1 --&gt; [*]: output_1_condition=$.step1.output_1.finished == false   \n  }\n  DoWhile --&gt; [*]</code></pre> <p>If the step declares multiple outputs, multiple conditions are possible. The do-while block will also have multiple outputs:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; DoWhile\n  state DoWhile {\n    [*] --&gt; Step1\n    Step1 --&gt; [*]: Output 1 condition\n    Step1 --&gt; [*]: Output 2 condition   \n  }\n  DoWhile --&gt; [*]: Output 1\n  DoWhile --&gt; [*]: Output 2</code></pre> <p>You may decide to only allow exit from a loop if one of the two outputs is satisfied:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; DoWhile\n  state DoWhile {\n    [*] --&gt; Step1\n    Step1 --&gt; Step1: Output 1\n    Step1 --&gt; [*]: Output 2\n  }\n  DoWhile --&gt; [*]: Output 1</code></pre>"},{"location":"arcaflow/concepts/workflows/#condition","title":"Condition","text":"<p>A condition is a flow control operation that redirects the flow one way or another based on an expression. You can also create multiple branches to create a switch-case effect.</p> <pre><code>stateDiagram-v2\n  state if_state &lt;&lt;choice&gt;&gt;\n  Step1: Step 1\n  [*] --&gt; Step1\n  Step1 --&gt; if_state\n  Step2: Step 2\n  Step3: Step 3\n  if_state --&gt; Step2: $.step1.output_1 == true\n  if_state --&gt; Step3: $.step1.output_1 == false</code></pre>"},{"location":"arcaflow/concepts/workflows/#multiply","title":"Multiply","text":"<p>The multiply flow control operation is useful when you need to dynamically execute sub-workflows in parallel based on an input condition. You can, for example, use this to run a workflow step on multiple or all Kubernetes nodes.</p> <pre><code>stateDiagram-v2\n  Lookup: Lookup Kubernetes hosts\n  [*] --&gt; Lookup\n  Lookup --&gt; Multiply\n  state Multiply {\n    [*] --&gt; Stresstest\n    Stresstest --&gt; [*]\n  }\n  Multiply --&gt; [*]</code></pre> <p>The output of a Multiply operation will be a map, keyed with a string that is configured from the input.</p> <p>Tip</p> <p>You can think of a Multiply step like a for-each loop, but the steps being executed in parallel.</p>"},{"location":"arcaflow/concepts/workflows/#synchronize","title":"Synchronize","text":"<p>The synchronize step attempts to synchronize the execution of subsequent steps for a specified key. The key must be a constant and cannot be obtained from an input expression.</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step1\n  [*] --&gt; Step2\n  Synchronize1: Synchronize (key=a)\n  Synchronize2: Synchronize (key=a)\n  Step1 --&gt; Synchronize1\n  Step2 --&gt; Synchronize2\n  Synchronize1 --&gt; Step3\n  Synchronize2 --&gt; Step4\n  Step3 --&gt; [*]\n  Step4 --&gt; [*]</code></pre>"},{"location":"arcaflow/creating-plugins/python/","title":"Creating plugins with Python","text":"<p>If you want to create an Arcaflow plugin in Python, you will need tree things:</p> <ol> <li>A container engine that can build images</li> <li>Python 3.9+ (PyPy is supported)</li> <li>The Python SDK for Arcaflow plugins</li> </ol> <p>The easiest way is to start from the template repository for Python plugins, but starting from scratch is also fully supported.</p> <p>Before you start please familiarize yourself with the Arcaflow type system.</p>"},{"location":"arcaflow/creating-plugins/python/#poetry-quickstart","title":"Poetry Quickstart","text":""},{"location":"arcaflow/creating-plugins/python/#installation","title":"Installation","text":"<ol> <li> <p>Ensure your <code>python3</code> executable is at least version 3.9.</p> <pre><code>$ python3 --version\nPython 3.9.15\n</code></pre> </li> <li> <p>If it is not, install Python 3.9.</p> RHEL, CentOS, FedoraUbuntu <pre><code>$ dnf -y install python3.9\n</code></pre> <pre><code>$ apt-get -y install python3.9\n</code></pre> </li> <li> <p>Alias the Python 3.9 executable to <code>python3</code> installed by your system package manager.</p> <pre><code>$ alias python3=\"python3.9\"\n</code></pre> </li> <li> <p>Install Poetry using one of their supported methods for your environment.</p> <p>For example, on a Linux distribution <pre><code>$ curl -sSL https://install.python-poetry.org | python3 -\n</code></pre></p> <p>Make sure to install Poetry into exactly one Python executable on your system. If something goes wrong with your package\u2019s Python virtual environment, you do not want to also spend time figuring out which Poetry executable is responsible for it.</p> </li> <li> <p>Verify your Poetry version.</p> <pre><code>$ poetry --version\nPoetry (version 1.2.2)\n</code></pre> </li> </ol>"},{"location":"arcaflow/creating-plugins/python/#python-project-setup","title":"Python Project Setup","text":""},{"location":"arcaflow/creating-plugins/python/#new-project","title":"New Project","text":"<p>Create your Python Project, <code>plugin-project</code>, and change directory into the project root. You should see a directory structure similar to this with the following files.</p> <pre><code>$ poetry new plugin-project\nCreated package plugin_project in plugin-project\n\n$ tree plugin-project\nplugin-project\n\u251c\u2500\u2500 plugin_project\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 __init__.py\n\n2 directories, 4 files\n\n$ cd plugin-project\n</code></pre> <p>Ensure <code>python3</code> is at least 3.9.</p> <pre><code>$ python3 --version\nPython 3.9.15\n</code></pre> <p>If <code>python3</code> is at least version 3.9, then determine its path.</p> <pre><code>$ which python3\n/usr/bin/python3\n</code></pre> <p>Set Poetry to use your Python that is at least 3.9.</p> <pre><code>poetry env use /usr/bin/python3\n</code></pre> <p>Alternativley,</p> <pre><code>poetry env use $(which python3)\n</code></pre> <p>Check that your <code>pyproject.toml</code> is using at least Python 3.9 by looking for the following line.</p> <pre><code>[tool.poetry.dependencies]\npython = \"^3.9\"\n</code></pre> <p>Add the arcaflow plugin sdk for python as a software dependency for your Python project.</p> <pre><code>poetry add arcaflow-plugin-sdk-python\n</code></pre> <p>You should now have a <code>poetry.lock</code> file in your project root. Poetry maintains the state of your <code>pyproject.toml</code>, and its exact software dependencies as hashes in the <code>poetry.lock</code> file.</p>"},{"location":"arcaflow/creating-plugins/python/#initializing-a-pre-existing-project","title":"Initializing a pre-existing project","text":"<p>Assuming your source repository is named <code>plugin-project</code>, clone your repository onto your local file system.</p> <p>Change directory into your project, and create the plugin module directory, <code>plugin_project</code>, and the <code>tests</code> directory.</p> <pre><code>$ cd plugin-project\n$ mkdir {plugin_project,tests}\n</code></pre> <p>Follow Poetry\u2019s command line interface wizard\u2019s prompts to create your <code>pyproject.toml</code> by adding configuration metadata, build system requirements, module dependencies, and development dependencies. Don\u2019t forget to add the Arcaflow Python Plugin SDK as a software dependency, <code>arcaflow-plugin-sdk</code>.</p> <pre><code>$ poetry init\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#validate-your-poetry-environment","title":"Validate your Poetry environment","text":"<p>Change into the root directory of your plugin project.</p> <p>Start your project\u2019s Python virtual environment with Poetry.</p> <pre><code>$ poetry shell\nSpawning shell within ~/.cache/pypoetry/virtualenvs/plugin-project-8vZa8fhA-py3.9\n</code></pre> <p>Start an interactive Python session, and import <code>arcaflow_plugin_sdk</code>.</p> <pre><code>$ python3\nPython 3.9.15 (main, Aug  9 2022, 13:32:42) [GCC 12.1.1 20220507 (Red Hat 12.1.1-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import arcaflow_plugin_sdk\n</code></pre> <p>If there are no errors, then the plugin sdk has been successfully imported.</p>"},{"location":"arcaflow/creating-plugins/python/#setting-up-your-environment","title":"Setting up your environment","text":"<p>First, you will have to set up your environment.</p>"},{"location":"arcaflow/creating-plugins/python/#create-the-plugin-package","title":"Create the Plugin Package","text":""},{"location":"arcaflow/creating-plugins/python/#get-template-code","title":"Get Template Code","text":"<ol> <li>Fulfill requirements.<ol> <li>Python 3.9</li> </ol> </li> <li>Fork, then clone the template repository.</li> <li>Change into the template repository directory.</li> <li> <p>Plugin starting directory structure.</p> <p><pre><code>$ tree .\n.\n\u2514\u2500\u2500 arcaflow-plugin-template-python        &lt;- GitHub repo\n\u251c\u2500\u2500 arcaflow_plugin_template_python    &lt;- Python module\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 example_plugin.py\n\u251c\u2500\u2500 docker-compose.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 example.yaml\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 poetry.lock\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 test_example_plugin.py\n</code></pre> 5. Rename the following with your desired package name.</p> <ol> <li>GitHub repo</li> <li>README title</li> <li> <p>Python module</p> </li> <li> <p><code>package</code> variable in <code>Dockerfile</code> <pre><code>ENV package arcaflow_plugin_template_python\n</code></pre></p> </li> <li> <p>Image source label in <code>Dockerfile</code> with your repository\u2019s URL.   <pre><code>LABEL org.opencontainers.image.source=\"https://github.com/arcalot/arcaflow-plugin-template-python\"\n</code></pre></p> </li> <li> <p>Image name in <code>docker-compose.yaml</code> <pre><code>version: '3.2'\nservices:\nplugin:\nimage: arcaflow-plugin-template    &lt;-\nbuild: .\nvolumes:\n- source: ./example.yaml\ntarget: /config/example.yaml\ntype: bind\n</code></pre></p> </li> <li> <p>Plugin module import in your <code>tests</code>.   <pre><code>#!/usr/bin/env python3\nimport unittest\nfrom arcaflow_plugin_template_python import example_plugin\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n</code></pre></p> </li> </ol> </li> </ol>"},{"location":"arcaflow/creating-plugins/python/#create-virtual-environment","title":"Create Virtual Environment","text":"PoetryWithout Poetry <ol> <li> <p>Fulfill requirements.</p> <ol> <li>Poetry 1.2</li> </ol> </li> <li> <p>Rename the following with your desired package name.</p> <ol> <li>Python package in <code>pyproject.toml</code></li> </ol> <pre><code>[tool.poetry]\nname = \"arcaflow-plugin-template-python\"        &lt;-\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"Arcalot\"]\nlicense = \"Apache-2.0+GPL-2.0-only\"\n...\n</code></pre> </li> <li> <p>Set this package\u2019s Python virtual environment to use your Python 3.9.</p> <pre><code>$ poetry env use $(which python3)\n</code></pre> </li> <li> <p>Install the software dependencies from <code>poetry.lock</code>.</p> <pre><code>$ poetry install\n</code></pre> </li> <li> <p>Activate the Python virtual environment.</p> <pre><code>$ poetry shell\n</code></pre> </li> </ol> <ol> <li> <p>Create pyproject.toml.</p> </li> <li> <p>Configure <code>pyproject.toml</code> metadata</p> <pre><code>[build-system]\nrequires = [\"setuptools&gt;=61.0\", \"setuptools-scm\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"arcaflow-plugin-template-python\"              &lt;-\ndescription = \"My plugin description\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.9\"\nkeywords = [\"one\", \"two\"]\nlicense = {text = \"Apache-2.0+GPL-2.0-only\"}\nclassifiers = [\n\"Programming Language :: Python :: 3\",\n]\ndependencies = [\n\"arcaflow-plugin-sdk\"\n'importlib-metadata; python_version&lt;\"3.8\"',\n]\ndynamic = [\"version\", \"readme\"]\n\n[tool.setuptools.dynamic]\nversion = { attr = \"arcaflow-plugin-template-python.0.1.0}\nreadme = {file = [\"REAMDE.md\"]}\n</code></pre> </li> <li> <p>Rename the Python project by changing the value of <code>pyproject.project.name</code></p> <p>For example,     <pre><code>[project]\nname = \"moonshot-plugin-project\"\n</code></pre></p> </li> <li> <p>Create a virtualenv in your project directory using the following command, replacing your Python call.</p> <pre><code>$ python -m venv .venv\n</code></pre> </li> <li> <p>Activate the Python virtual environment.</p> <pre><code>$ source .venv/bin/activate\n</code></pre> </li> <li> <p>Install Python project dependencies.</p> <pre><code>$ pip install -r requirements.txt\n</code></pre> </li> </ol>"},{"location":"arcaflow/creating-plugins/python/#validate-working-environment","title":"Validate Working Environment","text":"<ol> <li> <p>Run the test plugin.</p> <pre><code>$ python3 example_plugin.py -f example.yaml\n</code></pre> </li> <li> <p>Run the unit tests.</p> <pre><code>$ python3 test_example_plugin.py\n</code></pre> </li> <li> <p>Generate a JSON schema.</p> <pre><code>$ python3 example_plugin.py --json-schema input &gt;example.schema.json\n</code></pre> <p>If you are using the YAML plugin for VSCode, add the following line to the top of your config file for code completion.</p> <pre><code># yaml-language-server: $schema=example.schema.json\n</code></pre> </li> <li> <p>Copy and customize the Dockerfile from the example repository.</p> </li> <li> <p>Set up your CI/CD system as you see fit.</p> </li> </ol> Using pip <ol> <li>Create an empty folder.</li> <li>Create a <code>requirements.txt</code> with the following content:        <pre><code>arcaflow-plugin-sdk\n</code></pre></li> <li>Figure out the right command to call your Python version:        <pre><code>python3.10 --version\npython3.9 --version\npython3 --version\npython --version\n</code></pre>    Make sure you have at least Python 3.9.</li> <li>Create a virtualenv in your project directory using the following command, replacing your Python call:        <pre><code>python -m venv venv\n</code></pre></li> <li>Activate the venv:        <pre><code>source venv/bin/activate\n</code></pre></li> <li>Install the dependencies:        <pre><code>pip install -r requirements.txt\n</code></pre></li> <li>Copy the example plugin, example config and the [tests]https://github.com/arcalot/arcaflow-plugin-template-python/blob/main/tests/test_example_plugin.py) to your directory.</li> <li>Run the test plugin:        <pre><code>./example_plugin.py -f example.yaml\n</code></pre></li> <li>Run the unit tests:        <pre><code>./test_example_plugin.py\n</code></pre></li> <li>Generate a JSON schema:        <pre><code>./example_plugin.py --json-schema input &gt;example.schema.json\n</code></pre>   If you are using the YAML plugin for VSCode, add the following line to the top of your config file for code completion:        <pre><code># yaml-language-server: $schema=example.schema.json\n</code></pre></li> <li>Copy and customize the Dockerfile from the example repository.</li> <li>Set up your CI/CD system as you see fit.</li> </ol> <p>Now you are ready to start hacking away at your plugin!</p>"},{"location":"arcaflow/creating-plugins/python/#publishing-your-plugin-package","title":"Publishing your Plugin Package","text":"<p>Create an API token with your PyPi user account, and save it in your favorite secrets manager.</p> <p>Test PyPi is intended for trying out process of publishing your package. Register an account, and save your username and password to the following environment variables.</p> <pre><code>export TESTPYPI_USERNAME=&lt;test pypi username&gt;\nexport TESTPYPI_PASSWORD=&lt;test pypi password&gt;\n</code></pre> Poetry <p>Add your PyPi token to the Poetry configuration file.</p> <pre><code>$ poetry config pypi-token.&lt;any name&gt; &lt;PYPI API TOKEN&gt;\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#creating-your-plugin-the-easy-way","title":"Creating your plugin the easy way","text":"<p>A plugin is nothing but a list of functions with type-annotated parameters and decorators. For example, let\u2019s create a function:</p> <pre><code>def pod_scenario(input_parameter):\n    # Do pod scenario magic here\n</code></pre> <p>However, this SDK uses Python type hints and decorators to automatically generate the schema required for Arcaflow. Alternatively, you can also build a schema by hand. The current section describes the automated way, the section below describes the manual way.</p>"},{"location":"arcaflow/creating-plugins/python/#input-parameters","title":"Input parameters","text":"<p>Your step function must take exactly one input parameter. This parameter must be a dataclass. For example:</p> <pre><code>import dataclasses\nimport re\n\n@dataclasses.dataclass\nclass PodScenarioParams:\n    namespace_pattern: re.Pattern = re.compile(\".*\")\n    pod_name_pattern: re.Pattern = re.compile(\".*\")\n</code></pre> <p>As you can see, our dataclass has two fields, each of which is a <code>re.Pattern</code>. This SDK automatically reads the types of the fields to construct the schema. See the Types section below for supported type patterns.</p>"},{"location":"arcaflow/creating-plugins/python/#output-parameters","title":"Output parameters","text":"<p>Now that you have your input parameter class, you must create one or more output classes in a similar fashion:</p> <pre><code>import dataclasses\nimport typing\n\n@dataclasses.dataclass\nclass Pod:\n    namespace: str\n    name: str\n\n@dataclasses.dataclass\nclass PodScenarioResults:\n    pods_killed: typing.List[Pod]\n</code></pre> <p>As you can see, your input may incorporate other classes, which themselves have to be dataclasses. Read on for more information on types.</p>"},{"location":"arcaflow/creating-plugins/python/#creating-a-step-function","title":"Creating a step function","text":"<p>Now that we have both our input and output(s), let\u2019s go back to our initial <code>pod_scenario</code> function. Here we need to add a decorator to tell the SDK about metadata, and more importantly, what the return types are. (This is needed because Python does not support reading return types to an adequate level.)</p> <pre><code>from arcaflow_plugin_sdk import plugin\n\n\n@plugin.step(\n    id=\"pod\",\n    name=\"Pod scenario\",\n    description=\"Kill one or more pods matching the criteria\",\n    outputs={\"success\": PodScenarioResults, \"error\": PodScenarioError},\n)\ndef pod_scenario(params: PodScenarioParams):\n    # Fail for now\n    return \"error\", PodScenarioError(\"Not implemented\")\n</code></pre> <p>As you can see, apart from the metadata, we also declare the type of the parameter object so the SDK can read it.</p> <p>Let\u2019s go through the <code>@plugin.step</code> decorator parameters one by one:</p> <ul> <li><code>id</code> indicates the identifier of this step. This must be globally unique</li> <li><code>name</code> indicates a human-readable name for this step</li> <li><code>description</code> indicates a longer description for this step</li> <li><code>outputs</code> indicates which possible outputs the step can have, with their output identifiers as keys</li> </ul> <p>The function must return the output identifier, along with the output object.</p>"},{"location":"arcaflow/creating-plugins/python/#running-the-plugin","title":"Running the plugin","text":"<p>Finally, we need to call <code>plugin.run()</code> in order to actually run the plugin:</p> <pre><code>if __name__ == \"__main__\":\n    sys.exit(plugin.run(plugin.build_schema(\n        # Pass one or more scenario functions here\n        pod_scenario,\n    )))\n</code></pre> <p>You can now call your plugin using <code>./yourscript.py -f path-to-parameters.yaml</code>. If you have defined more than one step, you also need to pass the <code>-s step-id</code> parameter.</p> <p>Keep in mind, you should always test your plugin. See Testing your plugin below for details.</p> <p>Tip</p> <p>To prevent output from breaking the functionality when attached to the Arcaflow Engine, the SDK hides any output your step function writes to the standard output or standard error. You can use the <code>--debug</code> flag to show any output on the standard error in standalone mode.</p>"},{"location":"arcaflow/creating-plugins/python/#types","title":"Types","text":"<p>The SDK supports a wide range of types. Let\u2019s start with the basics:</p> <ul> <li><code>str</code></li> <li><code>int</code></li> <li><code>float</code></li> <li><code>bool</code></li> <li>Enums</li> <li><code>re.Pattern</code></li> <li><code>typing.List[othertype]</code> (you must specify the type for the contents of the list)</li> <li><code>typing.Dict[keytype, valuetype]</code> (you must specify the type for the keys and values)</li> <li>Any dataclass</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#optional-parameters","title":"Optional parameters","text":"<p>You can also declare any parameter as optional like this:</p> <pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Optional[int] = None\n</code></pre> <p>Note that adding <code>typing.Optional</code> is not enough, you must specify the default value.</p>"},{"location":"arcaflow/creating-plugins/python/#union-types","title":"Union types","text":"<p>Union types are supported as long as all members are dataclasses. For example:</p> <pre><code>@dataclasses.dataclass\nclass A:\n    a: str\n\n@dataclasses.dataclass\nclass B:\n    b: str\n\n@dataclasses.dataclass\nclass MyParams:\n    items: typing.List[typing.Union[A, B]]\n</code></pre> <p>In the underlying transport a field name <code>_type</code> will be added to act as a serialization discriminator. You can also customize the discriminator field:</p> <pre><code>@dataclasses.dataclass\nclass A:\n    a: str\n\n@dataclasses.dataclass\nclass B:\n    b: str\n\n@dataclasses.dataclass\nclass MyParams:\n    items: typing.List[\n        typing.Annotated[\n            typing.Union[A, B],\n            annotations.discriminator(\"foo\")\n        ]\n    ]\n</code></pre> <p>If you intend to use a non-string descriminator field, or you want to manually specify the discriminator value, you can do so by adding a <code>discriminator_value</code> annotation:</p> <pre><code>@dataclasses.dataclass\nclass MyParams:\n    items: typing.List[\n        typing.Annotated[\n            typing.Union[\n                typing.Annotated[A, annotations.discriminator_value(\"first\")],\n                typing.Annotated[B, annotations.discriminator_value(\"second\")]\n            ],\n            annotations.discriminator(\"foo\")\n        ]\n    ]\n</code></pre> <p>Tip</p> <p>You can add the discriminator field to your underlying dataclasses, but when present, their schema must match exactly.</p>"},{"location":"arcaflow/creating-plugins/python/#validation","title":"Validation","text":"<p>You can also validate the values by using <code>typing.Annotated</code>, such as this:</p> <pre><code>class MyClass:\n    param: typing.Annotated[int, schema.min(5)]\n</code></pre> <p>This will create a minimum-value validation for the parameter of 5. The following annotations are supported for validation:</p> <ul> <li><code>schema.min()</code> for strings, ints, floats, lists, and maps</li> <li><code>schema.max()</code> for strings, ints, floats, lists, and maps</li> <li><code>schema.pattern()</code> for strings</li> <li><code>schema.required_if()</code> for any field on an object</li> <li><code>schema.required_if_not()</code> for any field on an object</li> <li><code>schema.conflicts()</code> for any field on an object</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#metadata","title":"Metadata","text":"<p>You can add metadata to your schema by using annotations</p> <pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Annotated[\n           str,\n           schema.id(\"my-param\"),\n           schema.name(\"Parameter 1\"),\n           schema.description(\"This is a parameter\"),\n           schema.icon(\"&lt;svg...&gt;Add a 64x64 SVG here&lt;/svg&gt;\")\n    ]\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#default-values","title":"Default values","text":"<p>You can add default values for your dataclass members like this:</p> <pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: str = \"this is the default value\"\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#units","title":"Units","text":"<p>You can also include unit information in your schema. This will allow a user interface to treat your values accordingly:</p> <pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Annotated[\n        int,\n        schema.units(schema.UNIT_BYTE),\n    ]\n</code></pre> <p>You can also define your own unit. For that, you have to define your base unit (e.g. \u201cbytes\u201d) and then the multipliers:</p> <pre><code>UNIT_BYTE = schema.Units(\n    schema.Unit(\n        # Short, singular form:\n        \"B\",\n        # Short, plural form:\n        \"B\",\n        # Long, singular form:\n        \"byte\",\n        # Long, plural form:\n        \"bytes\"\n    ),\n    {\n        1024: schema.Unit(\n            \"kB\",\n            \"kB\",\n            \"kilobyte\",\n            \"kilobytes\"\n        ),\n        1048576: schema.Unit(\n            \"MB\",\n            \"MB\",\n            \"megabyte\",\n            \"megabytes\"\n        ),\n    }\n)\n</code></pre> <p>This also allows you to parse strings like <code>5MB 4kB</code>:</p> <pre><code>parsed_unit: int = UNIT_BYTE.parse(\"5MB 4 kB\")\n</code></pre> <p>Conversely, you can also render the units:</p> <pre><code>print(UNIT_BYTE.format_short(5246976))\n</code></pre> <p>Check the code completion for your units for more options.</p>"},{"location":"arcaflow/creating-plugins/python/#examples","title":"Examples","text":"<p>You can also provide example values for your fields to help people providing the data:</p> <pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Annotated[\n        int,\n        schema.example(1024),\n    ]\n</code></pre> <p>You can, of course, provide multiple examples too. Note, the example must be provided in its raw form (as dicts, lists, and scalars), not as dataclasses!</p>"},{"location":"arcaflow/creating-plugins/python/#creating-your-plugin-the-hard-way-not-recommended","title":"Creating your plugin the hard way (not recommended)","text":"<p>For performance reasons, or for the purposes of separation of concerns, you may want to create a schema by hand. This section walks you through declaring a schema by hand and then using it to call a function. Keep in mind, the SDK still primarily operates with dataclasses to transport structured data.</p> <p>However, we do not recommend this approach because it results in a lot of boilerplate code, and the real-world benefits are marginal at best. Also keep in mind, that your plugin will need more frequent updates if Arcaflow is extending the schema system and you want to switch to new versions.</p> <p>We start by defining a schema:</p> <pre><code>from arcaflow_plugin_sdk import schema\nfrom typing import Dict\n\nsteps: Dict[str, schema.StepSchema]\n\ns = schema.Schema(\n    steps,\n)\n</code></pre> <p>The <code>steps</code> parameter here must be a dict, where the key is the step ID and the value is the step schema. So, let\u2019s create a step schema:</p> <pre><code>from arcaflow_plugin_sdk import schema\n\nstep_schema = schema.StepSchema(\n    id = \"pod\",\n    name = \"Pod scenario\",\n    description = \"Kills pods\",\n    input = input_schema,\n    outputs = outputs,\n    handler = my_handler_func\n)\n</code></pre> <p>Let\u2019s go in order:</p> <ul> <li>The <code>input</code> must be a schema of the type <code>schema.ObjectType</code>. This describes the single parameter that will be passed to <code>my_handler_func</code>.</li> <li>The <code>outputs</code> describe a <code>Dict[str, schema.ObjectType]</code>, where the key is the ID for the returned output type, while the value describes the output schema.</li> <li>The <code>handler</code> function takes one parameter, the object described in <code>input</code> and must return a tuple of a string and the output object. Here the ID uniquely identifies which output is intended, for example <code>success</code> and <code>error</code>, while  the second parameter in the tuple must match the <code>outputs</code> declaration.</li> </ul> <p>That\u2019s it! Now all that\u2019s left is to define the <code>ObjectType</code> and any subobjects.</p>"},{"location":"arcaflow/creating-plugins/python/#objecttype","title":"ObjectType","text":"<p>The ObjectType is intended as a backing type for dataclasses. For example:</p> <pre><code>t = schema.ObjectType(\n    TestClass,\n    {\n        \"a\": schema.Field(\n            type=schema.StringType(),\n            required=True,\n        ),\n        \"b\": schema.Field(\n            type=schema.IntType(),\n            required=True,\n        )\n    }\n)\n</code></pre> <p>The fields support the following parameters:</p> <ul> <li><code>type</code>: underlying type schema for the field (required)</li> <li><code>name</code>: name for the current field</li> <li><code>description</code>: description for the current field</li> <li><code>required</code>: marks the field as required</li> <li><code>required_if</code>: a list of other fields that, if filled, will also cause the current field to be required</li> <li><code>required_if_not</code>: a list of other fields that, if not set, will cause the current field to be required</li> <li><code>conflicts</code>: a list of other fields that cannot be set together with the current field</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#scopetype-and-reftype","title":"ScopeType and RefType","text":"<p>Sometimes it is necessary to create circular references. This is where the <code>ScopeType</code> and the <code>RefType</code> comes into play. Scopes contain a list of objects that can be referenced by their ID, but one object is special: the root object of the scope. The RefType, on the other hand, is there to reference objects in a scope.</p> <p>Currently, the Python implementation passes the scope to the ref type directly, but the important rule is that ref types always reference their nearest scope up the tree. Do not create references that aim at scopes not directly above the ref!</p> <p>For example:</p> <pre><code>@dataclasses.dataclass\nclass OneOfData1:\n    a: str\n\n@dataclasses.dataclass\nclass OneOfData2:\n    b: OneOfData1\n\nscope = schema.ScopeType(\n    {\n        \"OneOfData1\": schema.ObjectType(\n            OneOfData1,\n            {\n                \"a\": schema.Field(\n                    schema.StringType()\n                )\n            }\n        ),\n    },\n    # Root object of scopes\n    \"OneOfData2\",\n)\n\nscope.objects[\"OneOfData2\"] = schema.ObjectType(\n    OneOfData2,\n    {\n        \"b\": schema.Field(\n            schema.RefType(\"OneOfData1\", scope)\n        )\n    }\n)\n</code></pre> <p>As you can see, this API is not easy to use and is likely to change in the future.</p>"},{"location":"arcaflow/creating-plugins/python/#oneoftype","title":"OneOfType","text":"<p>The OneOfType allows you to create a type that is a combination of other ObjectTypes. When a value is deserialized, a special discriminator field is consulted to figure out which type is actually being sent.</p> <p>This discriminator field may be present in the underlying type. If it is, the type must match the declaration in the AnyOfType.</p> <p>For example:</p> <pre><code>@dataclasses.dataclass\nclass OneOfData1:\n    type: str\n    a: str\n\n@dataclasses.dataclass\nclass OneOfData2:\n    b: int\n\nscope = schema.ScopeType(\n    {\n        \"OneOfData1\": schema.ObjectType(\n            OneOfData1,\n            {\n                # Here the discriminator field is also present in the underlying type\n                \"type\": schema.Field(\n                    schema.StringType(),\n                ),\n                \"a\": schema.Field(\n                    schema.StringType()\n                )\n            }\n        ),\n        \"OneOfData2\": schema.ObjectType(\n            OneOfData2,\n            {\n                \"b\": schema.Field(\n                    schema.IntType()\n                )\n            }\n        )\n    },\n    # Root object of scopes\n    \"OneOfData1\",\n)\n\ns = schema.OneOfStringType(\n    {\n        # Option 1\n        \"a\": schema.RefType(\n            # The RefType resolves against the scope.\n            \"OneOfData1\",\n            scope\n        ),\n        # Option 2\n        \"b\": schema.RefType(\n            \"OneOfData2\",\n            scope\n        ),\n    },\n    # Pass the scope this type belongs do\n    scope,\n    # Discriminator field\n    \"type\",\n)\n\nserialized_data = s.serialize(OneOfData1(\n    \"a\",\n    \"Hello world!\"\n))\npprint.pprint(serialized_data)\n</code></pre> <p>Note, that the OneOfTypes take all object-like elements, such as refs, objects, or scopes.</p>"},{"location":"arcaflow/creating-plugins/python/#stringtype","title":"StringType","text":"<p>String types indicate that the underlying type is a string.</p> <pre><code>t = schema.StringType()\n</code></pre> <p>The string type supports the following parameters:</p> <ul> <li><code>min_length</code>: minimum length for the string (inclusive)</li> <li><code>max_length</code>: maximum length for the string (inclusive)</li> <li><code>pattern</code>: regular expression the string must match</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#patterntype","title":"PatternType","text":"<p>The pattern type indicates that the field must contain a regular expression. It will be decoded as <code>re.Pattern</code>.</p> <pre><code>t = schema.PatternType()\n</code></pre> <p>The pattern type has no parameters.</p>"},{"location":"arcaflow/creating-plugins/python/#inttype","title":"IntType","text":"<p>The int type indicates that the underlying type is an integer.</p> <pre><code>t = schema.IntType()\n</code></pre> <p>The int type supports the following parameters:</p> <ul> <li><code>min</code>: minimum value for the number (inclusive).</li> <li><code>max</code>: minimum value for the number (inclusive).</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#floattype","title":"FloatType","text":"<p>The float type indicates that the underlying type is a floating point number.</p> <pre><code>t = schema.FloatType()\n</code></pre> <p>The float type supports the following parameters:</p> <ul> <li><code>min</code>: minimum value for the number (inclusive).</li> <li><code>max</code>: minimum value for the number (inclusive).</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#booltype","title":"BoolType","text":"<p>The bool type indicates that the underlying value is a boolean. When unserializing, this type also supports string and integer values of <code>true</code>, <code>yes</code>, <code>on</code>, <code>enable</code>, <code>enabled</code>, <code>1</code>, <code>false</code>, <code>no</code>, <code>off</code>, <code>disable</code>, <code>disabled</code> or <code>0</code>.</p>"},{"location":"arcaflow/creating-plugins/python/#enumtype","title":"EnumType","text":"<p>The enum type creates a type from an existing enum:</p> <pre><code>class MyEnum(Enum):\n    A = \"a\"\n    B = \"b\"\n\nt = schema.EnumType(MyEnum)\n</code></pre> <p>The enum type has no further parameters.</p>"},{"location":"arcaflow/creating-plugins/python/#listtype","title":"ListType","text":"<p>The list type describes a list of items. The item type must be described:</p> <pre><code>t = schema.ListType(\n    schema.StringType()\n)\n</code></pre> <p>The list type supports the following extra parameters:</p> <ul> <li><code>min</code>: The minimum number of items in the list (inclusive)</li> <li><code>max</code>: The maximum number of items in the list (inclusive)</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#maptype","title":"MapType","text":"<p>The map type describes a key-value type (dict). You must specify both the key and the value type:</p> <pre><code>t = schema.MapType(\n    schema.StringType(),\n    schema.StringType()\n)\n</code></pre> <p>The map type supports the following extra parameters:</p> <ul> <li><code>min</code>: The minimum number of items in the map (inclusive)</li> <li><code>max</code>: The maximum number of items in the map (inclusive)</li> </ul>"},{"location":"arcaflow/creating-plugins/python/#running-the-plugin_1","title":"Running the plugin","text":"<p>If you create the schema by hand, you can add the following code to your plugin:</p> <pre><code>if __name__ == \"__main__\":\n    sys.exit(plugin.run(your_schema))\n</code></pre> <p>You can then run your plugin as described before.</p>"},{"location":"arcaflow/creating-plugins/python/#testing-your-plugin","title":"Testing your plugin","text":"<p>You should always make sure you have enough test coverage to prevent your plugin from breaking. To help you with testing, this SDK provides some tools for testing:</p> <ol> <li>Serialization tests for your input and output to make sure your classes can be serialized for transport</li> <li>Functional tests that call your plugin and make sure it works correctly</li> </ol>"},{"location":"arcaflow/creating-plugins/python/#writing-a-serialization-test","title":"Writing a serialization test","text":"<p>You can use any test framework you like for your serialization test, we\u2019ll demonstrate with unittest as it is included directly in Python. The key to this test is to call <code>plugin.test_object_serialization()</code> with an instance of your dataclass that you want to test:</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_serialization(self):\n        self.assertTrue(plugin.test_object_serialization(\n            example_plugin.PodScenarioResults(\n                [\n                    example_plugin.Pod(\n                        namespace=\"default\",\n                        name=\"nginx-asdf\"\n                    )\n                ]\n            )\n        ))\n</code></pre> <p>Remember, you need to call this function with an instance containing actual data, not just the class name.</p> <p>The test function will first serialize, then unserialize your data and check if it\u2019s the same. If you want to use a manually created schema, you can do so, too:</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_serialization(self):\n        plugin.test_object_serialization(\n            example_plugin.PodScenarioResults(\n                #...\n            ),\n            schema.ObjectType(\n                #...\n            )\n        )\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#functional-tests","title":"Functional tests","text":"<p>Functional tests don\u2019t have anything special about them. You can directly call your code with your dataclasses as parameters, and check the return. This works best on auto-generated schemas with the <code>@plugin.step</code> decorator. See below for manually created schemas.</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_functional(self):\n        input = example_plugin.PodScenarioParams()\n\n        output_id, output_data = example_plugin.pod_scenario(input)\n\n        # Check if the output is always an error, as it is the case for the example plugin.\n        self.assertEqual(\"error\", output_id)\n        self.assertEqual(\n            output_data,\n            example_plugin.PodScenarioError(\n                \"Cannot kill pod .* in namespace .*, function not implemented\"\n            )\n        )\n</code></pre> <p>If you created your schema manually, the best way to write your tests is to include the schema in your test. This will automatically validate both the input and the output, making sure they conform to your schema. For example:</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_functional(self):\n        step_schema = schema.StepSchema(\n            #...\n            handler = example_plugin.pod_scenario,\n        )\n        input = example_plugin.PodScenarioParams()\n\n        output_id, output_data = step_schema(input)\n\n        # Check if the output is always an error, as it is the case for the example plugin.\n        self.assertEqual(\"error\", output_id)\n        self.assertEqual(\n            output_data,\n            example_plugin.PodScenarioError(\n                \"Cannot kill pod .* in namespace .*, function not implemented\"\n            )\n        )\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#embedding-your-plugin","title":"Embedding your plugin","text":"<p>Instead of using your plugin as a standalone tool or in conjunction with Arcaflow, you can also embed your plugin into your existing Python application. To do that you simply build a schema using one of the methods described above and then call the schema yourself. You can pass raw data as an input, and you\u2019ll get the benefit of schema validation.</p> <pre><code># Build your schema using the schema builder from above with the step functions passed.\nschema = plugin.build_schema(pod_scenario)\n\n# Which step we want to execute\nstep_id = \"pod\"\n# Input parameters. Note, these must be a dict, not a dataclass\nstep_params = {\n    \"pod_name_pattern\": \".*\",\n    \"pod_namespace_pattern\": \".*\",\n}\n\n# Execute the step\noutput_id, output_data = schema(step_id, step_params)\n\n# Print which kind of result we have\npprint.pprint(output_id)\n# Print the result data\npprint.pprint(output_data)\n</code></pre> <p>However, the example above requires you to provide the data as a <code>dict</code>, not a <code>dataclass</code>, and it will also return a <code>dict</code> as an output object. Sometimes, you may want to use a partial approach, where you only use part of the SDK. In this case, you can change your code to run any of the following functions, in order:</p> <ul> <li><code>serialization.load_from_file()</code> to load a YAML or JSON file into a dict</li> <li><code>yourschema.unserialize_input()</code> to turn a <code>dict</code> into a <code>dataclass</code> needed for your steps</li> <li><code>yourschema.call_step()</code> to run a step with the unserialized <code>dataclass</code></li> <li><code>yourschema.serialize_output()</code> to turn the output <code>dataclass</code> into a <code>dict</code></li> </ul>"},{"location":"arcaflow/creating-plugins/python/#faq","title":"FAQ","text":""},{"location":"arcaflow/creating-plugins/python/#how-can-i-add-a-field-with-dashes-such-as-my-field","title":"How can I add a field with dashes, such as <code>my-field</code>?","text":"<p>Dataclasses don\u2019t support dashes in parameters. You can work around this by defining the <code>id</code> annotation:</p> <pre><code>@dataclasses.dataclass\nclass MyData:\n    my_field: typing.Annotated[\n        str,\n        schema.id(\"my-field\"),\n    ]\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#how-can-i-write-a-dataclass-from-a-schema-to-a-yaml-or-json-file","title":"How can I write a dataclass from a schema to a YAML or JSON file?","text":"<p>You can extend Pythons JSON encoder to support dataclasses. If that doesn\u2019t suit your needs, you can use this SDK to convert the dataclasses to their basic representations and then write that to your JSON or YAML file. First, add this outside of your step:</p> <pre><code>my_object_schema = plugin.build_object_schema(YourDataclass)\n</code></pre> <p>Inside your step function you can then dump the data from your input</p> <pre><code>def your_step(params: YourParams)\n    yaml_contents = yaml.dump(my_object_schema.serialize(params.some_param))\n</code></pre>"},{"location":"arcaflow/creating-plugins/python/#how-can-i-easily-load-a-list-from-a-yaml-or-json-into-a-list-of-dataclasses","title":"How can I easily load a list from a YAML or JSON into a list of dataclasses?","text":"<p>This requires a bit of trickery. First, we build a schema from the dataclass representing the row or entry in the list:</p> <pre><code>my_row_schema = plugin.build_object_schema(MyRow)\n</code></pre> <p>Then you can create a list schema:</p> <pre><code>my_list_schema = schema.ListType(my_row_schema)\n</code></pre> <p>You can now unserialize a list obtained from the YAML or JSON file:</p> <pre><code>my_data = my_list_schema.unserialize(json.loads(...))\n</code></pre>"},{"location":"arcaflow/creating-plugins/release/","title":"Releasing Your Python Plugin","text":"<p>Turning your plugin into a Python package is one requirement for it to become an official Arcaflow Python Plugin.</p>"},{"location":"arcaflow/creating-plugins/release/#python-project-without-plugin-template","title":"Python Project without Plugin Template","text":""},{"location":"arcaflow/creating-plugins/release/#new-project","title":"New Project","text":"PoetryWithout Poetry <p>Create your Python Project with Poetry, <code>plugin-project</code>1, and change directory into the project root. You should see a directory structure similar to this with the following files.</p> <pre><code>$ poetry new plugin-project\nCreated package plugin_project in plugin-project\n\n$ tree plugin-project\nplugin-project\n\u251c\u2500\u2500 plugin_project\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 __init__.py\n\n2 directories, 4 files\n\n$ cd plugin-project\n</code></pre> <p>Ensure <code>python3</code> is at least 3.9.</p> <pre><code>$ python3 --version\nPython 3.9.15\n</code></pre> <p>If <code>python3</code> is at least version 3.9, then determine its path.</p> <pre><code>$ which python3\n/usr/bin/python3\n</code></pre> <p>Set Poetry to use your Python that is at least 3.9.</p> <pre><code>poetry env use /usr/bin/python3\n</code></pre> <p>Alternativley,</p> <pre><code>poetry env use $(which python3)\n</code></pre> <p>Check that your <code>pyproject.toml</code> is using at least Python 3.9 by looking for the following line.</p> <pre><code>[tool.poetry.dependencies]\npython = \"^3.9\"\n</code></pre> <p>Add the arcaflow plugin sdk for python as a software dependency for your Python project.</p> <pre><code>poetry add arcaflow-plugin-sdk-python\n</code></pre> <p>You should now have a <code>poetry.lock</code> file in your project root. Poetry maintains the state of your <code>pyproject.toml</code>, and its exact software dependencies as hashes in the <code>poetry.lock</code> file.</p> <p>Create your Python Project, <code>plugin-project</code>, and its sub-directories, the package\u2019s main module directory, <code>plugin_project</code>1, and the <code>tests</code> directory, and then change directory into the project root.</p> <pre><code>$ mkdir --parent plugin-project/{plugin_project,tests}\n$ cd plugin-project\n</code></pre> <p>Turn your sub-directories into Python modules.</p> <pre><code>touch {plugin-project,tests}/__init__.py\n</code></pre> <p>Create your <code>pyproject.toml</code> to track your project\u2019s software dependencies and build system dependencies.</p> <pre><code>touch pyproject.toml\n</code></pre> <p>Ensure you have at least Python 3.9.</p> <pre><code>python --version\nPython 3.9.15\n</code></pre> <p>Create a Python virtual environment named <code>.venv</code>.</p> <pre><code>python -m venv .venv\n</code></pre> <p>Activate the Python virtual environment, <code>.venv</code>.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Install the minimum plugin dependencies.</p> <pre><code>pip install arcaflow-plugin-sdk\n</code></pre>"},{"location":"arcaflow/creating-plugins/release/#initializing-a-pre-existing-project","title":"Initializing a Pre-Existing Project","text":"<p>Assuming your pre-existing project is named <code>plugin-project</code>, and contains the sub-directories <code>plugin_project</code>, and <code>tests</code>, on your local file system.</p> PoetryWithout Poetry <p>Follow Poetry\u2019s command line interface wizard\u2019s prompts to create your <code>pyproject.toml</code>. Don\u2019t forget to add the Arcaflow Python Plugin SDK as a software dependency, <code>arcaflow-plugin-sdk</code>. At the time of writing, the progressing through the wizard should look approximately like this.</p> <pre><code>$ poetry init\n\nThis command will guide you through creating your pyproject.toml config.\n\nPackage name [my-first-plugin]:\nVersion [0.1.0]:\nDescription []:\nAuthor:  A. Robot Programmer\nLicense []:\nCompatible Python versions [^3.9]:\n\nWould you like to define your main dependencies interactively? (yes/no) [yes] yes\n...\n\nPackage to add or search for (leave blank to skip): arcaflow-plugin-sdk\nFound 20 packages matching arcaflow-plugin-sdk\nShowing the first 10 matches\n\nEnter package # to add, or the complete package name if it is not listed []:\n[ 0] arcaflow-plugin-sdk\n[ 1] arcaflow\n[ 2] arcaflow-lib-kubernetes\n[ 3] plugin-sdk-automation\n[ 4] tracardi-plugin-sdk\n[ 5] laniakea-plugin-sdk\n[ 6] dce-plugin-sdk\n[ 7] python-plugin-sdk\n[ 8] ayx-plugin-sdk\n[ 9] PlugSy\n[10]\n&gt; 0\nEnter the version constraint to require (or leave blank to use the latest version):\nUsing version ^0.10.1 for arcaflow-plugin-sdk\n</code></pre> <p>Create your <code>pyproject.toml</code> to track your project\u2019s software dependencies and build system dependencies.</p> <pre><code>touch pyproject.toml\n</code></pre> <p>Manually fill out your <code>pyproject.toml</code>. Use PyPa\u2019s guide to configuring pyproject.toml for setuptools.</p>"},{"location":"arcaflow/creating-plugins/release/#validate-dependencies-in-virtual-environment","title":"Validate Dependencies in Virtual Environment","text":"<p>Change into the root directory of your plugin project.</p> PoetryWithout Poetry <p>Start your project\u2019s Python virtual environment.</p> <pre><code>$ poetry shell\nSpawning shell within ~/.cache/pypoetry/virtualenvs/plugin-project-8vZa8fhA-py3.9\n</code></pre> <p>Start an interactive Python session, and import <code>arcaflow_plugin_sdk</code>.</p> <pre><code>$ python3\nPython 3.9.15 (main, Aug  9 2022, 13:32:42) [GCC 12.1.1 20220507 (Red Hat 12.1.1-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import arcaflow_plugin_sdk\n</code></pre> <p>If there are no errors, then the plugin sdk has been successfully imported.</p> <p>Start your project\u2019s Python virtual environment.</p> <pre><code>$ source .venv/bin/activate\n</code></pre> <p>Start an interactive Python session, and import <code>arcaflow_plugin_sdk</code>.</p> <pre><code>$ python3\nPython 3.9.15 (main, Aug  9 2022, 13:32:42) [GCC 12.1.1 20220507 (Red Hat 12.1.1-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import arcaflow_plugin_sdk\n</code></pre> <p>If there are no errors, then the plugin sdk has been successfully imported.</p>"},{"location":"arcaflow/creating-plugins/release/#python-project-from-plugin-template","title":"Python Project from Plugin Template","text":""},{"location":"arcaflow/creating-plugins/release/#create-the-plugin-package","title":"Create the Plugin Package","text":"<ol> <li>Fulfill requirements.<ol> <li>Python 3.9</li> </ol> </li> <li>Fork, then clone the template repository.</li> <li>Change into the template repository directory.</li> <li> <p>Plugin starting directory structure.</p> <p><pre><code>$ tree .\n.\n\u2514\u2500\u2500 arcaflow-plugin-template-python        &lt;- GitHub repo\n\u251c\u2500\u2500 arcaflow_plugin_template_python    &lt;- Python module\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 example_plugin.py\n\u251c\u2500\u2500 docker-compose.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 example.yaml\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 poetry.lock\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 test_example_plugin.py\n</code></pre> 5. Rename the following with your desired package name1.</p> <ol> <li>GitHub repo</li> <li>README title</li> <li> <p>Python module</p> </li> <li> <p><code>package</code> variable in <code>Dockerfile</code> <pre><code>ENV package arcaflow_plugin_template_python\n</code></pre></p> </li> <li> <p>Image source label in <code>Dockerfile</code> with your repository\u2019s URL.   <pre><code>LABEL org.opencontainers.image.source=\"https://github.com/arcalot/arcaflow-plugin-template-python\"\n</code></pre></p> </li> <li> <p>Image name in <code>docker-compose.yaml</code> <pre><code>version: '3.2'\nservices:\nplugin:\nimage: arcaflow-plugin-template    &lt;-\nbuild: .\nvolumes:\n- source: ./example.yaml\ntarget: /config/example.yaml\ntype: bind\n</code></pre></p> </li> <li> <p>Plugin module import in your <code>tests</code>.   <pre><code>#!/usr/bin/env python3\nimport unittest\nfrom arcaflow_plugin_template_python import example_plugin\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n</code></pre></p> </li> </ol> </li> </ol>"},{"location":"arcaflow/creating-plugins/release/#create-package-virtual-environment","title":"Create Package Virtual Environment","text":"PoetryWithout Poetry <ol> <li> <p>Fulfill requirements.</p> <ol> <li>Poetry 1.2</li> </ol> </li> <li> <p>Rename the Python package in your <code>pyproject.toml</code> with your desired package name1.</p> <pre><code>[tool.poetry]\nname = \"arcaflow-plugin-template-python\"        &lt;-\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"Arcalot\"]\nlicense = \"Apache-2.0+GPL-2.0-only\"\n...\n</code></pre> </li> <li> <p>Set this package\u2019s Python virtual environment to use your Python 3.9.</p> <pre><code>$ poetry env use $(which python3)\n</code></pre> </li> <li> <p>Install the software dependencies from <code>poetry.lock</code>.</p> <pre><code>$ poetry install\n</code></pre> </li> <li> <p>Activate the Python virtual environment.</p> <pre><code>$ poetry shell\n</code></pre> </li> </ol> <ol> <li> <p>Create pyproject.toml.</p> </li> <li> <p>Configure <code>pyproject.toml</code> metadata</p> <pre><code>[build-system]\nrequires = [\"setuptools&gt;=61.0\", \"setuptools-scm\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"arcaflow-plugin-template-python\"              &lt;-\ndescription = \"My plugin description\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.9\"\nkeywords = [\"one\", \"two\"]\nlicense = {text = \"Apache-2.0+GPL-2.0-only\"}\nclassifiers = [\n\"Programming Language :: Python :: 3\",\n]\ndependencies = [\n\"arcaflow-plugin-sdk\"\n'importlib-metadata; python_version&lt;\"3.8\"',\n]\ndynamic = [\"version\", \"readme\"]\n\n[tool.setuptools.dynamic]\nversion = { attr = \"arcaflow-plugin-template-python.0.1.0}\nreadme = {file = [\"REAMDE.md\"]}\n</code></pre> </li> <li> <p>Rename the Python project by changing the value of <code>pyproject.project.name</code></p> <p>For example,     <pre><code>[project]\nname = \"moonshot-plugin-project\"\n</code></pre></p> </li> <li> <p>Create a virtualenv in your project directory using the following command, replacing your Python call.</p> <pre><code>$ python -m venv .venv\n</code></pre> </li> <li> <p>Activate the Python virtual environment.</p> <pre><code>$ source .venv/bin/activate\n</code></pre> </li> <li> <p>Install Python project dependencies.</p> <pre><code>$ pip install -r requirements.txt\n</code></pre> </li> </ol>"},{"location":"arcaflow/creating-plugins/release/#validate-working-environment","title":"Validate Working Environment","text":"<ol> <li> <p>Run the test plugin.</p> <pre><code>$ python3 example_plugin.py -f example.yaml\n</code></pre> </li> <li> <p>Run the unit tests.</p> <pre><code>$ python3 test_example_plugin.py\n</code></pre> </li> <li> <p>Generate a JSON schema.</p> <pre><code>$ python3 example_plugin.py --json-schema input &gt;example.schema.json\n</code></pre> <p>If you are using the YAML plugin for VSCode, add the following line to the top of your config file for code completion.</p> <pre><code># yaml-language-server: $schema=example.schema.json\n</code></pre> </li> <li> <p>Copy and customize the Dockerfile from the example repository.</p> </li> <li> <p>Set up your CI/CD system as you see fit.</p> </li> </ol> <p>Now you are ready to start hacking away at your plugin!</p>"},{"location":"arcaflow/creating-plugins/release/#publishing-your-plugin-package","title":"Publishing Your Plugin Package","text":"<p>Create an API token with your PyPi user account, and save it in your favorite secrets manager.</p> <p>Test PyPi is intended for trying out process of publishing your package. Register an account, and save your username and password to the following environment variables.</p> <pre><code>export TESTPYPI_USERNAME=&lt;test pypi username&gt;\nexport TESTPYPI_PASSWORD=&lt;test pypi password&gt;\n</code></pre> PoetryWithout Poetry <p>Add your PyPi token to the Poetry configuration file.</p> <pre><code>$ poetry config pypi-token.&lt;any name&gt; &lt;PYPI API TOKEN&gt;\n</code></pre> <p>Alternatively, you can use environment variables to provide your PyPi credentials.</p> <pre><code>$ export POETRY_PYPI_TOKEN_PYPI=my-token\n$ export POETRY_HTTP_BASIC_PYPI_USERNAME=&lt;username&gt;\n$ export POETRY_HTTP_BASIC_PYPI_PASSWORD=&lt;password&gt;\n</code></pre> <p>Generate distribution archives (build) (at the moment, only pure python wheels are supported).</p> <pre><code>$ poetry build\n</code></pre> <p>Check the results of a publish dry run are successful.</p> <pre><code>$ poetry publish --dry-run\n\nPublishing arcaflow-plugin-template-python (0.1.0) to PyPI\n- Uploading arcaflow_plugin_template_python-0.1.0-py3-none-any.whl 100%\n- Uploading arcaflow_plugin_template_python-0.1.0.tar.gz 100%\n</code></pre> <p>Upload the distribution archives (publish)!</p> <pre><code>$ poetry publish\n\nPublishing arcaflow-plugin-template-python (0.1.0) to PyPI\n- Uploading arcaflow_plugin_template_python-0.1.0-py3-none-any.whl 100%\n- Uploading arcaflow_plugin_template_python-0.1.0.tar.gz 100%\n</code></pre> <p>Alternatively, build and publish in one command.</p> <pre><code>$ poetry publish --build\n</code></pre> <p>Change into the project\u2019s root directory.</p> <p>Install build and twine.</p> <pre><code>$ python3 -m pip install --upgrade build twine\n</code></pre> <p>Generate distribution archives.</p> <pre><code>$ python3 -m build\n</code></pre> <p>You should see the <code>dist</code> directory at your project\u2019s root, with archive files.</p> <pre><code>dist/\n\u251c\u2500\u2500 example_package_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl\n\u2514\u2500\u2500 example_package_YOUR_USERNAME_HERE-0.0.1.tar.gz\n</code></pre> <p>Upload distribution archives.</p> <pre><code>$ python3 -m twine upload --repository testpypi --username=$TESTPYPI_USERNAME --password=$TESTPYPI_PASSWORD dist/*\n\nUploading distributions to\nhttps://test.pypi.org/legacy/\nUploading\narcaflow_plugin_template_python-0.1.0-py3-none-any.whl\n100% \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.1/9.1 kB \u2022 00:00 \u2022 3.7 MB/s\nUploading\narcaflow_plugin_template_python-0.1.0.tar.gz\n100% \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 8.5/8.5 kB \u2022 00:00 \u2022 1.5 MB/s\n\nView at:\nhttps://test.pypi.org/project/arcaflow-plugin-template-python/0.1.0/\n</code></pre>"},{"location":"arcaflow/creating-plugins/release/#poetry-installation","title":"Poetry Installation","text":"<ol> <li> <p>Ensure your <code>python3</code> is at least version 3.9.</p> <pre><code>$ python3 --version\nPython 3.9.15\n</code></pre> </li> <li> <p>Install Poetry using one of their supported methods for your environment.</p> <p>For example, on a Linux distribution <pre><code>$ curl -sSL https://install.python-poetry.org | python3 -\n</code></pre> Make sure to install Poetry into the Python you found above2</p> </li> <li> <p>Verify your Poetry version.</p> <pre><code>$ poetry --version\nPoetry (version 1.2.2)\n</code></pre> </li> </ol> <ol> <li> <p>Naming your module directory the same as its encompassing project directory is a common convention for Python projects. Module directories must also be valid Python identifiers (i.e. variable names). The directory name of your Python module must match the name in your pyproject.toml, allowing for <code>-</code> substituting for <code>_</code> (i.e <code>arcaflow-plugin-template-python</code> ~= <code>arcaflow_plugin_template_python</code>), so that the directory name transforms into a module name that is a valid Python identifier.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>You want to ensure that Poetry is installed into exactly one Python executable on your system. If something goes wrong with your package\u2019s Python virtual environment, you do not want to spend additional time figuring out which Poetry executable is responsible for managing that specific Python virtual environment.\u00a0\u21a9</p> </li> </ol>"},{"location":"arcaflow/engine/","title":"Configuring the Arcaflow Engine","text":"<p>All of these changes require specifying the config when you run the arcaflow-engine. To do so, create a config YAML file, and run the engine with the <code>-config your-arcaflow-config.yaml</code> flag.</p>"},{"location":"arcaflow/engine/#logging","title":"Logging","text":"<p>Logging is useful when you need more information about what is happening while you run a workload.</p>"},{"location":"arcaflow/engine/#basic-logging","title":"Basic logging","text":"<p>Here is the syntax for setting the log level: <pre><code>log:\nlevel: info\n</code></pre></p> <p>Options are: - Debug: Info useful to the developers - Info: General info - Warning: Something went wrong, and you should know about it - Error: Something failed. This info should help you figure out why</p> <p>This sets which types of log output are shown or hidden. <code>debug</code> shows everything, while <code>error</code> shows the least, only showing <code>error</code> output. Each output shows more, rather than just its type, so <code>debug</code>, <code>info</code>, and <code>warning</code> still show <code>error</code> output.</p>"},{"location":"arcaflow/engine/#step-logging","title":"Step logging","text":"<p>Step logging is useful for getting output from failed steps, or general debugging. It is not recommended that you rely on this long term, as there may be better methods of debugging failed workflows.</p> <p>To make it output just error logs when a step fails, set it as shown: <pre><code>logged_outputs:\nerror:\nlevel: error\n</code></pre></p> <p>You can specify multiple types of output and their log levels. For example, if you also want to output success steps as debug, set it as shown: <pre><code>logged_outputs:\nerror:\nlevel: error\nsuccess:\nlevel: debug\n</code></pre></p> <p>Note: If you set the level lower than the general log level shown above, it will not show up in the output.</p>"},{"location":"arcaflow/engine/#deployers","title":"Deployers","text":"<p>If you want to change the default deployer from Docker to Podman or Kubernetes, you will need to set up a configuration YAML file and pass it to the engine with the <code>-config your-arcaflow-config.yaml</code> flag.</p> <p>You can then change the deployer type like this:</p> <pre><code>deployer:\ntype: podman\n# Deployer-specific options \n</code></pre> DockerKubernetesPodman <p>The docker deployer is the default. You can configure it like this:</p> <pre><code>deployer:\ntype: docker\nconnection:\n# Change this to point to a TCP-based Docker socket\nhost: host-to-docker # Add a certificates here. This is usually needed in TCP mode.\ncacert: |\nAdd your CA cert PEM here\ncert: |\nAdd your client cert PEM here.\nkey: |\nAdd your client key PEM here.\ndeployment:\n# For more options here see: https://docs.docker.com/engine/api/v1.42/#tag/Container/operation/ContainerCreate\ncontainer:\n# Add your container config here.\nhost:\n# Add your host config here.\nnetwork:\n# Add your network config here\nplatform:\n# Add your platform config here\nimagePullPolicy: Always|IfNotPresent|Never\ntimeouts:\n# HTTP timeout\nhttp: 5s\n</code></pre> All options for the Docker deployer Type: <code>scope</code> Root object: Config Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts Objects Config (<code>object</code>) Type: <code>object</code> Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts Connection (<code>object</code>) Type: <code>object</code> Properties cacert (<code>string</code>) Name: CA certificate Description: CA certificate in PEM format to verify the Dockerd server certificate against. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> cert (<code>string</code>) Name: Client certificate Description: Client certificate in PEM format to authenticate against the Dockerd with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> host (<code>string</code>) Name: Host Description: Host name for Dockerd. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z0-9./:_-]&amp;#43;$</code> Default<pre><code>\"unix:///var/run/docker.sock\"\n</code></pre> Examples <pre><code>'unix:///var/run/docker.sock'\n</code></pre> <p>\u201d     <pre><code>'npipe:////./pipe/docker_engine'\n</code></pre></p> key (<code>string</code>) Name: Client key Description: Client private key in PEM format to authenticate against the Dockerd with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN ([A-Z]&amp;#43;) PRIVATE KEY-----(\\s*.*\\s*)*-----END ([A-Z]&amp;#43;) PRIVATE KEY-----\\s*$</code> Examples <pre><code>\"-----BEGIN PRIVATE KEY-----\\nMIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEArr89f2kggSO/yaCB\\n6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1nEiPnLbzDDgMU8KCPAMhI7JpYRlH\\nnipxWwIDAQABAkBybu/x0MElcGi2u/J2UdwScsV7je5Tt12z82l7TJmZFFJ8RLmc\\nrh00Gveb4VpGhd1+c3lZbO1mIT6v3vHM9A0hAiEA14EW6b+99XYza7+5uwIDuiM+\\nBz3pkK+9tlfVXE7JyKsCIQDPlYJ5xtbuT+VvB3XOdD/VWiEqEmvE3flV0417Rqha\\nEQIgbyxwNpwtEgEtW8untBrA83iU2kWNRY/z7ap4LkuS+0sCIGe2E+0RmfqQsllp\\nicMvM2E92YnykCNYn6TwwCQSJjRxAiEAo9MmaVlK7YdhSMPo52uJYzd9MQZJqhq+\\nlB1ZGDx/ARE=\\n-----END PRIVATE KEY-----\\n\"\n</code></pre> ContainerConfig (<code>object</code>) Type: <code>object</code> Properties Domainname (<code>string</code>) Name: Domain name Description: Domain name for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> Env (<code>map[string, string]</code>) Name: Environment variables Description: Environment variables to set on the plugin container. Required: No Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[A-Z0-9_]&amp;#43;$</code> Value type Type: <code>string</code> Maximum: 32760 Hostname (<code>string</code>) Name: Hostname Description: Hostname for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> MacAddress (<code>string</code>) Name: MAC address Description: Media Access Control address for the container. Required: No Must match pattern: <code>^[a-fA-F0-9]{2}(:[a-fA-F0-9]{2}){5}$</code> NetworkDisabled (<code>bool</code>) Name: Disable network Description: Disable container networking completely. Required: No User (<code>string</code>) Name: Username Description: User that will run the command inside the container. Optionally, a group can be specified in the user:group format. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z_][a-z0-9_-]*[$]?(:[a-z_][a-z0-9_-]*[$]?)$</code> Deployment (<code>object</code>) Type: <code>object</code> Properties container (<code>reference[ContainerConfig]</code>) Name: Container configuration Description: Provides information about the container for the plugin. Required: No Referenced object: ContainerConfig host (<code>reference[HostConfig]</code>) Name: Host configuration Description: Provides information about the container host for the plugin. Required: No Referenced object: HostConfig imagePullPolicy (<code>enum[string]</code>) Name: Image pull policy Description: When to pull the plugin image. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> network (<code>reference[NetworkConfig]</code>) Name: Network configuration Description: Provides information about the container networking for the plugin. Required: No Referenced object: NetworkConfig platform (<code>reference[PlatformConfig]</code>) Name: Platform configuration Description: Provides information about the container host platform for the plugin. Required: No Referenced object: PlatformConfig HostConfig (<code>object</code>) Type: <code>object</code> Properties CapAdd (<code>list[string]</code>) Name: Add capabilities Description: Add capabilities to the container. Required: No List Items Type: <code>string</code> CapDrop (<code>list[string]</code>) Name: Drop capabilities Description: Drop capabilities from the container. Required: No List Items Type: <code>string</code> CgroupnsMode (<code>enum[string]</code>) Name: CGroup namespace mode Description: CGroup namespace mode to use for the container. Required: No Values <ul> <li>`` Empty</li> <li><code>host</code> Host</li> <li><code>private</code> Private</li> </ul> Dns (<code>list[string]</code>) Name: DNS servers Description: DNS servers to use for lookup. Required: No List Items Type: <code>string</code> DnsOptions (<code>list[string]</code>) Name: DNS options Description: DNS options to look for. Required: No List Items Type: <code>string</code> DnsSearch (<code>list[string]</code>) Name: DNS search Description: DNS search domain. Required: No List Items Type: <code>string</code> ExtraHosts (<code>list[string]</code>) Name: Extra hosts Description: Extra hosts entries to add Required: No List Items Type: <code>string</code> NetworkMode (<code>string</code>) Name: Network mode Description: Specifies either the network mode, the container network to attach to, or a name of a Docker network to use. Required: No Must match pattern: <code>^(none|bridge|host|container:[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;|[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;)$</code> Examples <pre><code>\"none\"\n</code></pre> <p>\u201d     <pre><code>\"bridge\"\n</code></pre> \u201d     <pre><code>\"host\"\n</code></pre> \u201d     <pre><code>\"container:container-name\"\n</code></pre> \u201d     <pre><code>\"network-name\"\n</code></pre></p> PortBindings (<code>map[string, list[reference[PortBinding]]]</code>) Name: Port bindings Description: Ports to expose on the host machine. Ports are specified in the format of portnumber/protocol. Required: No Key type Type: <code>string</code> Must match pattern: <code>^[0-9]&amp;#43;(/[a-zA-Z0-9]&amp;#43;)$</code> Value type Type: <code>list[reference[PortBinding]]</code> List Items Type: <code>reference[PortBinding]</code> Referenced object: PortBinding NetworkConfig (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PlatformConfig (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PortBinding (<code>object</code>) Type: <code>object</code> Properties HostIP (<code>string</code>) Name: Host IP Required: No HostPort (<code>string</code>) Name: Host port Required: No Must match pattern: <code>^0-9&amp;#43;$</code> Timeouts (<code>object</code>) Type: <code>object</code> Properties http (<code>int</code>) Name: HTTP Description: HTTP timeout for the Docker API. Required: No Minimum: 100000000 Units: nanoseconds Default<pre><code>\"15s\"\n</code></pre> <p>The Kubernetes deployer deploys on top of Kubernetes. You can set up the deployer like this:</p> <pre><code>deployer:\ntype: kubernetes\nconnection:\nhost: localhost:6443\ncert: |\nAdd your client cert in PEM format here.\nkey: |\nAdd your client key in PEM format here.\ncacert: |\nAdd the server CA cert in PEM format here.\n</code></pre> All options for the Kubernetes deployer Type: <code>scope</code> Root object: Config Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection pod (<code>reference[Pod]</code>) Name: Pod Description: Pod configuration for the plugin. Required: No Referenced object: Pod timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts Objects AWSElasticBlockStoreVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> AzureDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> AzureFileVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CSIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CephFSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CinderVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Config (<code>object</code>) Type: <code>object</code> Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection pod (<code>reference[Pod]</code>) Name: Pod Description: Pod configuration for the plugin. Required: No Referenced object: Pod timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts ConfigMapVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Connection (<code>object</code>) Type: <code>object</code> Properties bearerToken (<code>string</code>) Name: Bearer token Description: Bearer token to authenticate against the Kubernetes API with. Required: No burst (<code>int</code>) Name: Burst Description: Burst value for query throttling. Required: No Minimum: 0 Default<pre><code>10\n</code></pre> cacert (<code>string</code>) Name: CA certificate Description: CA certificate in PEM format to verify Kubernetes server certificate against. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> cert (<code>string</code>) Name: Client certificate Description: Client certificate in PEM format to authenticate against Kubernetes with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> host (<code>string</code>) Name: Host Description: Host name and port of the Kubernetes server Required: No Default<pre><code>\"kubernetes.default.svc\"\n</code></pre> key (<code>string</code>) Name: Client key Description: Client private key in PEM format to authenticate against Kubernetes with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN ([A-Z]&amp;#43;) PRIVATE KEY-----(\\s*.*\\s*)*-----END ([A-Z]&amp;#43;) PRIVATE KEY-----\\s*$</code> Examples <pre><code>\"-----BEGIN PRIVATE KEY-----\\nMIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEArr89f2kggSO/yaCB\\n6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1nEiPnLbzDDgMU8KCPAMhI7JpYRlH\\nnipxWwIDAQABAkBybu/x0MElcGi2u/J2UdwScsV7je5Tt12z82l7TJmZFFJ8RLmc\\nrh00Gveb4VpGhd1+c3lZbO1mIT6v3vHM9A0hAiEA14EW6b+99XYza7+5uwIDuiM+\\nBz3pkK+9tlfVXE7JyKsCIQDPlYJ5xtbuT+VvB3XOdD/VWiEqEmvE3flV0417Rqha\\nEQIgbyxwNpwtEgEtW8untBrA83iU2kWNRY/z7ap4LkuS+0sCIGe2E+0RmfqQsllp\\nicMvM2E92YnykCNYn6TwwCQSJjRxAiEAo9MmaVlK7YdhSMPo52uJYzd9MQZJqhq+\\nlB1ZGDx/ARE=\\n-----END PRIVATE KEY-----\\n\"\n</code></pre> password (<code>string</code>) Name: Password Description: Password for basic authentication. Required: No path (<code>string</code>) Name: Path Description: Path to the API server. Required: No Default<pre><code>\"/api\"\n</code></pre> qps (<code>float</code>) Name: QPS Description: Queries Per Second allowed against the API. Required: No Minimum: 0 Units: queries Default<pre><code>5.0\n</code></pre> serverName (<code>string</code>) Name: TLS server name Description: Expected TLS server name to verify in the certificate. Required: No username (<code>string</code>) Name: Username Description: Username for basic authentication. Required: No Container (<code>object</code>) Type: <code>object</code> Properties args (<code>list[string]</code>) Name: Arguments Description: Arguments to the entypoint (command). Required: No List Items Type: <code>string</code> command (<code>list[string]</code>) Name: Command Description: Override container entry point. Not executed with a shell. Required: No Minimum items: 1 List Items Type: <code>string</code> env (<code>list[object]</code>) Name: Environment Description: Environment variables for this container. Required: No List Items Type: <code>object</code> Properties name (<code>string</code>) Name: Name Description: Environment variables name. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> value (<code>string</code>) Name: Value Description: Value for the environment variable. Required: No valueFrom (<code>reference[EnvFromSource]</code>) Name: Value source Description: Load the environment variable from a secret or config map. Required: No Referenced object: EnvFromSource envFrom (<code>list[reference[EnvFromSource]]</code>) Name: Environment sources Description: List of sources to populate the environment variables from. Required: No List Items Type: <code>reference[EnvFromSource]</code> Referenced object: EnvFromSource image (<code>string</code>) Name: Image Description: Container image to use for this container. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9_\\-:./]&amp;#43;$</code> imagePullPolicy (<code>enum[string]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> name (<code>string</code>) Name: Name Description: Name for the container. Each container in a pod must have a unique name. Required: Yes Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> securityContext (<code>object</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Properties capabilities (<code>object</code>) Name: Capabilities Description: Add or drop POSIX capabilities. Required: No Properties add (<code>list[string]</code>) Name: Add Description: Add POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> drop (<code>list[string]</code>) Name: Drop Description: Drop POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> privileged (<code>bool</code>) Name: Privileged Description: Run the container in privileged mode. Required: No volumeDevices (<code>list[object]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No List Items Type: <code>object</code> Properties devicePath (<code>string</code>) Name: Device path Description: Path inside the container the device will be mapped to. Required: Yes Minimum: 1 name (<code>string</code>) Name: Name Description: Must match the persistent volume claim in the pod. Required: Yes Minimum: 1 volumeMounts (<code>list[object]</code>) Name: Volume mounts Description: Pod volumes to mount on this container. Required: No List Items Type: <code>object</code> Properties mountPath (<code>string</code>) Name: Mount path Description: Path to mount the volume on inside the container. Required: Yes Minimum: 1 name (<code>string</code>) Name: Volume name Description: Must match the pod volume to mount. Required: Yes Minimum: 1 readOnly (<code>bool</code>) Name: Read only Description: Mount volume as read-only. Required: No Default<pre><code>false\n</code></pre> subPath (<code>string</code>) Name: Subpath Description: Path from the volume to mount. Required: No Minimum: 1 workingDir (<code>string</code>) Name: Working directory Description: Override the container working directory. Required: No DownwardAPIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> EmptyDirVolumeSource (<code>object</code>) Type: <code>object</code> Properties medium (<code>string</code>) Name: Medium Description: How to store the empty directory Required: No Minimum: 1 Must match pattern: <code>^(|Memory|HugePages|HugePages-.*)$</code> EnvFromSource (<code>object</code>) Type: <code>object</code> Properties configMapRef (<code>object</code>) Name: Config map source Description: Populates the source from a config map. Required: No Properties name (<code>string</code>) Name: Name Description: Name of the referenced config map. Required: Yes Minimum: 1 optional (<code>bool</code>) Name: Optional Description: Specify whether the config map must be defined. Required: No prefix (<code>string</code>) Name: Prefix Description: An optional identifier to prepend to each key in the ConfigMap. Required: No Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> secretRef (<code>object</code>) Name: Secret source Description: Populates the source from a secret. Required: No Properties name (<code>string</code>) Name: Name Description: Name of the referenced secret. Required: Yes Minimum: 1 optional (<code>bool</code>) Name: Optional Description: Specify whether the secret must be defined. Required: No EphemeralVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FCVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FlexVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FlockerVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> GCEPersistentDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> GlusterfsVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> HostPathVolumeSource (<code>object</code>) Type: <code>object</code> Properties path (<code>string</code>) Name: Path Description: Path to the directory on the host. Required: Yes Minimum: 1 Examples <pre><code>\"/srv/volume1\"\n</code></pre> type (<code>enum[string]</code>) Name: Type Description: Type of the host path. Required: No Values <ul> <li>`` Unset</li> <li><code>BlockDevice</code> Block device</li> <li><code>CharDevice</code> Character device</li> <li><code>Directory</code> Directory</li> <li><code>DirectoryOrCreate</code> Create directory if not found</li> <li><code>File</code> File</li> <li><code>FileOrCreate</code> Create file if not found</li> <li><code>Socket</code> Socket</li> </ul> ISCSIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> NFSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ObjectMeta (<code>object</code>) Type: <code>object</code> Properties annotations (<code>map[string, string]</code>) Name: Annotations Description: Kubernetes annotations to appy. See https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/ for details. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> generateName (<code>string</code>) Name: Name prefix Description: Name prefix to generate pod names from. Required: No labels (<code>map[string, string]</code>) Name: Labels Description: Kubernetes labels to appy. See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ for details. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> name (<code>string</code>) Name: Name Description: Pod name. Required: No namespace (<code>string</code>) Name: Namespace Description: Kubernetes namespace to deploy in. Required: No Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> Default<pre><code>\"default\"\n</code></pre> PersistentVolumeClaimVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PhotonPersistentDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Pod (<code>object</code>) Type: <code>object</code> Properties metadata (<code>reference[ObjectMeta]</code>) Name: Metadata Description: Pod metadata. Required: No Referenced object: ObjectMeta spec (<code>reference[PodSpec]</code>) Name: Specification Description: Pod specification. Required: No Referenced object: PodSpec PodSpec (<code>object</code>) Type: <code>object</code> Properties affinity (<code>object</code>) Name: Affinity rules Description: Affinity rules. Required: No Properties podAffinity (<code>object</code>) Name: Pod Affinity Description: The pod affinity rules. Required: No Properties requiredDuringSchedulingIgnoredDuringExecution (<code>list[object]</code>) Name: Required During Scheduling Ignored During Execution Description: Hard pod affinity rules. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties labelSelector (<code>object</code>) Name: MatchExpressions Description: Expressions for the label selector. Required: No Properties matchExpressions (<code>list[object]</code>) Name: MatchExpression Description: Expression for the label selector. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties key (<code>string</code>) Name: Key Description: Key for the label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> operator (<code>string</code>) Name: Operator Description: Logical operator for Kubernetes to use when interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt. Required: No Maximum: 253 Must match pattern: <code>In|NotIn|Exists|DoesNotExist|Gt|Lt</code> values (<code>list[string]</code>) Name: Values Description: Values for the label that the system uses to denote the domain. Required: No Minimum items: 1 List Items Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> topologyKey (<code>string</code>) Name: TopologyKey Description: Key for the node label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_./][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> podAntiAffinity (<code>object</code>) Name: Pod Affinity Description: The pod affinity rules. Required: No Properties requiredDuringSchedulingIgnoredDuringExecution (<code>list[object]</code>) Name: Required During Scheduling Ignored During Execution Description: Hard pod affinity rules. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties labelSelector (<code>object</code>) Name: MatchExpressions Description: Expressions for the label selector. Required: No Properties matchExpressions (<code>list[object]</code>) Name: MatchExpression Description: Expression for the label selector. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties key (<code>string</code>) Name: Key Description: Key for the label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> operator (<code>string</code>) Name: Operator Description: Logical operator for Kubernetes to use when interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt. Required: No Maximum: 253 Must match pattern: <code>In|NotIn|Exists|DoesNotExist|Gt|Lt</code> values (<code>list[string]</code>) Name: Values Description: Values for the label that the system uses to denote the domain. Required: No Minimum items: 1 List Items Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> topologyKey (<code>string</code>) Name: TopologyKey Description: Key for the node label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_./][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> containers (<code>list[reference[Container]]</code>) Name: Containers Description: A list of containers belonging to the pod. Required: No List Items Type: <code>reference[Container]</code> Referenced object: Container initContainers (<code>list[reference[Container]]</code>) Name: Init containers Description: A list of initialization containers belonging to the pod. Required: No List Items Type: <code>reference[Container]</code> Referenced object: Container nodeSelector (<code>map[string, string]</code>) Name: Labels Description: Node labels you want the target node to have. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> pluginContainer (<code>object</code>) Name: Plugin container Description: The container to run the plugin in. Required: Yes Properties env (<code>list[object]</code>) Name: Environment Description: Environment variables for this container. Required: No List Items Type: <code>object</code> Properties name (<code>string</code>) Name: Name Description: Environment variables name. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> value (<code>string</code>) Name: Value Description: Value for the environment variable. Required: No valueFrom (<code>reference[EnvFromSource]</code>) Name: Value source Description: Load the environment variable from a secret or config map. Required: No Referenced object: EnvFromSource envFrom (<code>list[reference[EnvFromSource]]</code>) Name: Environment sources Description: List of sources to populate the environment variables from. Required: No List Items Type: <code>reference[EnvFromSource]</code> Referenced object: EnvFromSource imagePullPolicy (<code>enum[string]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> name (<code>string</code>) Name: Name Description: Name for the container. Each container in a pod must have a unique name. Required: No Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> Default<pre><code>\"arcaflow-plugin-container\"\n</code></pre> securityContext (<code>object</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Properties capabilities (<code>object</code>) Name: Capabilities Description: Add or drop POSIX capabilities. Required: No Properties add (<code>list[string]</code>) Name: Add Description: Add POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> drop (<code>list[string]</code>) Name: Drop Description: Drop POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> privileged (<code>bool</code>) Name: Privileged Description: Run the container in privileged mode. Required: No volumeDevices (<code>list[object]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No List Items Type: <code>object</code> Properties devicePath (<code>string</code>) Name: Device path Description: Path inside the container the device will be mapped to. Required: Yes Minimum: 1 name (<code>string</code>) Name: Name Description: Must match the persistent volume claim in the pod. Required: Yes Minimum: 1 volumeMounts (<code>list[object]</code>) Name: Volume mounts Description: Pod volumes to mount on this container. Required: No List Items Type: <code>object</code> Properties mountPath (<code>string</code>) Name: Mount path Description: Path to mount the volume on inside the container. Required: Yes Minimum: 1 name (<code>string</code>) Name: Volume name Description: Must match the pod volume to mount. Required: Yes Minimum: 1 readOnly (<code>bool</code>) Name: Read only Description: Mount volume as read-only. Required: No Default<pre><code>false\n</code></pre> subPath (<code>string</code>) Name: Subpath Description: Path from the volume to mount. Required: No Minimum: 1 volumes (<code>list[reference[Volume]]</code>) Name: Volumes Description: A list of volumes that can be mounted by containers belonging to the pod. Required: No List Items Type: <code>reference[Volume]</code> Referenced object: Volume PortworxVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ProjectedVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> QuobyteVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> RBDVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ScaleIOVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> SecretVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> StorageOSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Timeouts (<code>object</code>) Type: <code>object</code> Properties http (<code>int</code>) Name: HTTP Description: HTTP timeout for the Docker API. Required: No Minimum: 100000000 Units: nanoseconds Default<pre><code>\"15s\"\n</code></pre> Volume (<code>object</code>) Type: <code>object</code> Properties awsElasticBlockStore (<code>reference[AWSElasticBlockStoreVolumeSource]</code>) Name: AWS EBS Description: AWS Elastic Block Storage. Required: No Referenced object: AWSElasticBlockStoreVolumeSource azureDisk (<code>reference[AzureDiskVolumeSource]</code>) Name: Azure Data Disk Description: Mount an Azure Data Disk as a volume. Required: No Referenced object: AzureDiskVolumeSource azureFile (<code>reference[AzureFileVolumeSource]</code>) Name: Azure File Description: Mount an Azure File Service mount. Required: No Referenced object: AzureFileVolumeSource cephfs (<code>reference[CephFSVolumeSource]</code>) Name: CephFS Description: Mount a CephFS volume. Required: No Referenced object: CephFSVolumeSource cinder (<code>reference[CinderVolumeSource]</code>) Name: Cinder Description: Mount a cinder volume attached and mounted on the host machine. Required: No Referenced object: CinderVolumeSource configMap (<code>reference[ConfigMapVolumeSource]</code>) Name: ConfigMap Description: Mount a ConfigMap as a volume. Required: No Referenced object: ConfigMapVolumeSource csi (<code>reference[CSIVolumeSource]</code>) Name: CSI Volume Description: Mount a volume using a CSI driver. Required: No Referenced object: CSIVolumeSource downwardAPI (<code>reference[DownwardAPIVolumeSource]</code>) Name: Downward API Description: Specify a volume that the pod should mount itself. Required: No Referenced object: DownwardAPIVolumeSource emptyDir (<code>reference[EmptyDirVolumeSource]</code>) Name: Empty directory Description: Temporary empty directory. Required: No Referenced object: EmptyDirVolumeSource ephemeral (<code>reference[EphemeralVolumeSource]</code>) Name: Ephemeral Description: Mount a volume that is handled by a cluster storage driver. Required: No Referenced object: EphemeralVolumeSource fc (<code>reference[FCVolumeSource]</code>) Name: Fibre Channel Description: Mount a Fibre Channel volume that's attached to the host machine. Required: No Referenced object: FCVolumeSource flexVolume (<code>reference[FlexVolumeSource]</code>) Name: Flex Description: Mount a generic volume provisioned/attached using an exec based plugin. Required: No Referenced object: FlexVolumeSource flocker (<code>reference[FlockerVolumeSource]</code>) Name: Flocker Description: Mount a Flocker volume. Required: No Referenced object: FlockerVolumeSource gcePersistentDisk (<code>reference[GCEPersistentDiskVolumeSource]</code>) Name: GCE disk Description: Google Cloud disk. Required: No Referenced object: GCEPersistentDiskVolumeSource glusterfs (<code>reference[GlusterfsVolumeSource]</code>) Name: GlusterFS Description: Mount a Gluster volume. Required: No Referenced object: GlusterfsVolumeSource hostPath (<code>reference[HostPathVolumeSource]</code>) Name: Host path Description: Mount volume from the host. Required: No Referenced object: HostPathVolumeSource iscsi (<code>reference[ISCSIVolumeSource]</code>) Name: iSCSI Description: Mount an iSCSI volume. Required: No Referenced object: ISCSIVolumeSource name (<code>string</code>) Name: Name Description: The name this volume can be referenced by. Required: Yes Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> nfs (<code>reference[NFSVolumeSource]</code>) Name: NFS Description: Mount an NFS share. Required: No Referenced object: NFSVolumeSource persistentVolumeClaim (<code>reference[PersistentVolumeClaimVolumeSource]</code>) Name: Persistent Volume Claim Description: Mount a Persistent Volume Claim. Required: No Referenced object: PersistentVolumeClaimVolumeSource photonPersistentDisk (<code>reference[PhotonPersistentDiskVolumeSource]</code>) Name: PhotonController persistent disk Description: Mount a PhotonController persistent disk as a volume. Required: No Referenced object: PhotonPersistentDiskVolumeSource portworxVolume (<code>reference[PortworxVolumeSource]</code>) Name: Portworx Volume Description: Mount a Portworx volume. Required: No Referenced object: PortworxVolumeSource projected (<code>reference[ProjectedVolumeSource]</code>) Name: Projected Description: Projected items for all in one resources secrets, configmaps, and downward API. Required: No Referenced object: ProjectedVolumeSource quobyte (<code>reference[QuobyteVolumeSource]</code>) Name: quobyte Description: Mount Quobyte volume from the host. Required: No Referenced object: QuobyteVolumeSource rbd (<code>reference[RBDVolumeSource]</code>) Name: Rados Block Device Description: Mount a Rados Block Device. Required: No Referenced object: RBDVolumeSource scaleIO (<code>reference[ScaleIOVolumeSource]</code>) Name: ScaleIO Persistent Volume Description: Mount a ScaleIO persistent volume. Required: No Referenced object: ScaleIOVolumeSource secret (<code>reference[SecretVolumeSource]</code>) Name: Secret Description: Mount a Kubernetes secret. Required: No Referenced object: SecretVolumeSource storageos (<code>reference[StorageOSVolumeSource]</code>) Name: StorageOS Volume Description: Mount a StorageOS volume. Required: No Referenced object: StorageOSVolumeSource vsphereVolume (<code>reference[VsphereVirtualDiskVolumeSource]</code>) Name: vSphere Virtual Disk Description: Mount a vSphere Virtual Disk as a volume. Required: No Referenced object: VsphereVirtualDiskVolumeSource VsphereVirtualDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> <p>If you want to use Podman as your local deployer instead of Docker, you can do so like this:</p> <pre><code>deployer:\ntype: podman\npodman:\n# Change where Podman is. (You can use this to point to a shell script\npath: /path/to/your/podman\n# Change the network mode\nnetworkMode: host\ndeployment:\n# For more options here see: https://docs.docker.com/engine/api/v1.42/#tag/Container/operation/ContainerCreate\ncontainer:\n# Add your container config here.\nhost:\n# Add your host config here.\nimagePullPolicy: Always|IfNotPresent|Never\ntimeouts:\n# HTTP timeout\nhttp: 5s\n</code></pre> All options for the Podman deployer Type: <code>scope</code> Root object: Config Properties deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment podman (<code>reference[Podman]</code>) Name: Podman Description: Podman CLI configuration Required: No Referenced object: Podman Objects Config (<code>object</code>) Type: <code>object</code> Properties deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment podman (<code>reference[Podman]</code>) Name: Podman Description: Podman CLI configuration Required: No Referenced object: Podman ContainerConfig (<code>object</code>) Type: <code>object</code> Properties Domainname (<code>string</code>) Name: Domain name Description: Domain name for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> Env (<code>list[string]</code>) Name: Environment variables Description: Environment variables to set on the plugin container. Required: No List Items Type: <code>string</code> Minimum: 1 Maximum: 32760 Must match pattern: <code>^.&amp;#43;=.&amp;#43;$</code> Hostname (<code>string</code>) Name: Hostname Description: Hostname for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> MacAddress (<code>string</code>) Name: MAC address Description: Media Access Control address for the container. Required: No Must match pattern: <code>^[a-fA-F0-9]{2}(:[a-fA-F0-9]{2}){5}$</code> NetworkDisabled (<code>bool</code>) Name: Disable network Description: Disable container networking completely. Required: No User (<code>string</code>) Name: Username Description: User that will run the command inside the container. Optionally, a group can be specified in the user:group format. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z_][a-z0-9_-]*[$]?(:[a-z_][a-z0-9_-]*[$]?)$</code> Deployment (<code>object</code>) Type: <code>object</code> Properties container (<code>reference[ContainerConfig]</code>) Name: Container configuration Description: Provides information about the container for the plugin. Required: No Referenced object: ContainerConfig host (<code>reference[HostConfig]</code>) Name: Host configuration Description: Provides information about the container host for the plugin. Required: No Referenced object: HostConfig imagePullPolicy (<code>enum[string]</code>) Name: Image pull policy Description: When to pull the plugin image. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> HostConfig (<code>object</code>) Type: <code>object</code> Properties Binds (<code>list[string]</code>) Name: Volume Bindings Description: Volumes Required: No List Items Type: <code>string</code> Minimum: 1 Maximum: 32760 Must match pattern: <code>^.&amp;#43;:.&amp;#43;$</code> CapAdd (<code>list[string]</code>) Name: Add capabilities Description: Add capabilities to the container. Required: No List Items Type: <code>string</code> CapDrop (<code>list[string]</code>) Name: Drop capabilities Description: Drop capabilities from the container. Required: No List Items Type: <code>string</code> CgroupnsMode (<code>enum[string]</code>) Name: CGroup namespace mode Description: CGroup namespace mode to use for the container. Required: No Values <ul> <li>`` Empty</li> <li><code>host</code> Host</li> <li><code>private</code> Private</li> </ul> Dns (<code>list[string]</code>) Name: DNS servers Description: DNS servers to use for lookup. Required: No List Items Type: <code>string</code> DnsOptions (<code>list[string]</code>) Name: DNS options Description: DNS options to look for. Required: No List Items Type: <code>string</code> DnsSearch (<code>list[string]</code>) Name: DNS search Description: DNS search domain. Required: No List Items Type: <code>string</code> ExtraHosts (<code>list[string]</code>) Name: Extra hosts Description: Extra hosts entries to add Required: No List Items Type: <code>string</code> NetworkMode (<code>string</code>) Name: Network mode Description: Specifies either the network mode, the container network to attach to, or a name of a Docker network to use. Required: No Must match pattern: <code>^(none|bridge|host|container:[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;|[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;)$</code> Examples <pre><code>\"none\"\n</code></pre> <p>\u201d     <pre><code>\"bridge\"\n</code></pre> \u201d     <pre><code>\"host\"\n</code></pre> \u201d     <pre><code>\"container:container-name\"\n</code></pre> \u201d     <pre><code>\"network-name\"\n</code></pre></p> PortBindings (<code>map[string, list[reference[PortBinding]]]</code>) Name: Port bindings Description: Ports to expose on the host machine. Ports are specified in the format of portnumber/protocol. Required: No Key type Type: <code>string</code> Must match pattern: <code>^[0-9]&amp;#43;(/[a-zA-Z0-9]&amp;#43;)$</code> Value type Type: <code>list[reference[PortBinding]]</code> List Items Type: <code>reference[PortBinding]</code> Referenced object: PortBinding Podman (<code>object</code>) Type: <code>object</code> Properties cgroupNs (<code>string</code>) Name: CGroup namespace Description: Provides the Cgroup Namespace settings for the container Required: No Must match pattern: <code>^host|ns:/proc/\\d&amp;#43;/ns/cgroup|container:.&amp;#43;|private$</code> containerName (<code>string</code>) Name: Container Name Description: Provides name of the container Required: No Must match pattern: <code>^.*$</code> imageArchitecture (<code>string</code>) Name: Podman image Architecture Description: Provides Podman Image Architecture Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"amd64\"\n</code></pre> imageOS (<code>string</code>) Name: Podman Image OS Description: Provides Podman Image Operating System Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"linux\"\n</code></pre> networkMode (<code>string</code>) Name: Network Mode Description: Provides network settings for the container Required: No Must match pattern: <code>^bridge:.*|host|none$</code> path (<code>string</code>) Name: Podman path Description: Provides the path of podman executable Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"/usr/bin/podman\"\n</code></pre> PortBinding (<code>object</code>) Type: <code>object</code> Properties HostIP (<code>string</code>) Name: Host IP Required: No HostPort (<code>string</code>) Name: Host port Required: No Must match pattern: <code>^0-9&amp;#43;$</code>"},{"location":"arcalog/","title":"Arcalog: Assisted Root Cause Analysis for Your Logs","text":"<p>Arcalog is still in early development. A scientific paper describing the project is available as a preprint.</p> <p>The README contains a guide on how to use Arcalog to gather data as well as how to use the <code>--http</code> flag to run a minimal user interface for downloading individual build IDs from Prow.</p> <p>Pre-release developer documentation is also available if you want to use the early pre-release version of Arcalog to embed the data gathering steps into your own application.</p>"}]}