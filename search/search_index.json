{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Arcalot: Another Repository Containing A Lot Of Things","text":"<p>The Arcalot community develops tools, plugins, and libraries that you can use either standalone as a library, and/or via a user interface or CLI. You can run the tools locally, remotely, or as part of a bigger system. Arcalot:</p> <ul> <li>Helps you create workflows with normalized input and output schemas</li> <li>Provides you with assisted and automated root cause analysis for the workflows you create as well as CI and other log systems</li> <li>Provides stable plugins for several workloads</li> </ul>"},{"location":"#arcaflow","title":"Arcaflow","text":"<p>Arcaflow is a workflow engine consisting of three main components:</p> <ul> <li>Core engine</li> <li>UI (planned)</li> <li>Plugins (including SDKs for Go and Python to write your own plugins)</li> </ul> <p>It allows you to connect plugins into workflows of parallel and serial tasks for your target systems. The engine is run as a single portable binary and therefore does not require installation of its components onto the target systems. A future UI will allow you to click and drag plugins into a workflow and, if needed, feed the resulting data back into the UI for further analysis. There is a range of supported plugins, written either in Go or Python.</p> <p>Read more</p>"},{"location":"#arcalog","title":"Arcalog","text":"<p>Arcalog can assist you with or automate your root cause analysis in CI or other log systems either as a standalone tool or by embedding it into your applications.</p> <p>It also provides additional tooling to download jobs from various log systems or add your own log files for analysis.</p> <p>Read more</p>"},{"location":"#community","title":"Community","text":"<p>You can find our general community health files like our code of conduct and contribution guidelines in the .github repository. If you have any questions or suggestions, please use the issues in the respective repository or contribute to the discussions.</p> <p>If you would like to contribute, check out the issues in the individual repositories and our project boards where we organize our work.</p> <p>If you want to participate in our bi-weekly meeting you can add our recurring meeting to your calendar: Arcalot Project Community meeting (iCal)</p>"},{"location":"arcaflow/","title":"Arcaflow: The noble workflow engine","text":"<p>Arcaflow is a workflow engine that lets you run individual steps and pass data between them. The data is validated according to a schema along the way to make sure there is no corrupt data. Arcaflow runs on your laptop, a jump host, or in a CI system and deploys plugins as containers on target systems via Docker, Podman, or Kubernetes.</p> <p>Did you know?</p> <p>In Docker/Kubernetes, Arcaflow only needs network access to the API, not the plugin container itself. You can safely place a restrictive firewall on most plugins.</p> Use cases <p>Arcaflow is a good fit to:</p> <ul> <li>Run ad-hoc tasks across container systems</li> <li>Pass data between them</li> <li>Make sure your data is correct</li> <li>Make workflows portable with minimal dependencies</li> </ul> <p>You can use Arcaflow for many things. We use it for:</p> <ul> <li>Performance and chaos testing</li> <li>Ad-hoc workflows without previous deployment</li> <li>Vendor-independent CI workflows</li> </ul> <p>Get started \u00bb Contribute \u00bb</p> Shipping expertise <p>Good workflows take time and expertise to develop. Often these workflows evolve organically into bespoke scripts and/or application stacks, and knowledge transfer or the ability to run the workflows in new environments can be very difficult. Arcaflow addresses this problem by focusing on being the plumbing for the workflow, standardizing on a plugin architecture for all actions, minimizing dependencies, focusing on quality, and enforcing strong typing for data passing.</p> <p>Arcaflow\u2019s design can drastically simplify much of the workflow creation process, and it allows the workflow author to ensure the workflow is locked in end-to-end. A complete workflow can be version-controlled as a simple YAML file and in most cases can be expected to run in exactly the same way in any compatible environment.</p> Not a CI system <p>Arcaflow is not designed to run as a persistent service nor to record workflow histories, and in most cases it is probably not the best tool to setup or manage infrastructure. For end-to-end CI needs, you should leverage a system that provdes these and other features (possibly something from the Alternatives list below).</p> <p>Arcaflow is, however, an excellent companion to a CI system. In many cases, building complex workflows completely within a CI environment can effectively lock you into that system because the workflow may not be easily portable outside of it or run independently by a user. An Arcaflow workflow can be easily integrated into most CI systems, so a workflow that you define once may be moved in most cases without modification to different environments or run directly by users.</p> Alternatives <p>It\u2019s important that you pick the right tool for the job. Sometimes, you need something simple. Sometimes, you want something persistent that keeps track of the workflows you run over time. We have collected some common and well-known open source workflow and workflow-like engines into this list and have provided some comparisons to help you find the right tool for your needs.</p> <p>Here are some of the features that make Arcaflow a unique solution to the below alternatives:</p> <ul> <li>Designed for complex branching-action workflows and parallelization</li> <li>Prioritizes data passing and management via strong typing and schemas to ensure machine readabilitly, workflow validation, and data integrity</li> <li>Runs actions as plugins via container orchestrator APIs</li> <li>Engine is deployed as a single Golang binary, and plugins are run as containers, minimizing dependencies and maximizing portability</li> <li>Workflows are designed to be explicitly version controlled to ensure portability to other environments without code or feature drift</li> <li>Plugins can be written in a variety of languages, and plugins from different languages can be mixed into the same workflow (SDKs provided currently for Python and Golang)</li> </ul> Ansible <p>Ansible is an IT automation and configuration management system. It handles configuration management, application deployment, cloud provisioning, ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex changes like zero-downtime rolling updates with load balancers easy.</p> <p>How are Arcaflow and Ansible similar?</p> <ul> <li>They both perform actions on local and remote systems using modular architectures.</li> <li>Their core engines can both run on your laptop and don\u2019t need a large server.</li> <li>You don\u2019t need to deploy them on target hosts or run them permanently.</li> <li>They both allow for passing of data between steps.</li> <li>They both use YAML to define their workflows.</li> <li>Their plugins and modules can be written in a variety of languages.</li> </ul> <p>How is Ansible different?</p> <ul> <li>Ansible is well-established with a wide range of available plugins.</li> <li>Ansible runs its tasks typically as commands over remote shells.</li> <li>Ansible\u2019s approach to parallelization is in terms of executing the same tasks against different hosts in parallel (see \u201cforks\u201d and \u201cstrategy\u201d). Defining different tasks to perform in parallel is more challenging.</li> <li>Ansible is written in Python and has many dependencies on the control host, though it can be run as a container to simplify this.</li> <li>Some modules may have system requirements for python or other dependencies on the target hosts/containers. (See Ansible documentation)</li> <li>Ansible workflows may not be consistent or portable across bare metal and Kubernetes environments.</li> </ul> Apache Airflow <p>Airflow is a platform to programmatically author, schedule, and monitor workflows. It is a deployed workflow engine written in Python. </p> <p>How are Arcaflow and Airflow similar?</p> <ul> <li>They both run workflows that allow you to pass data between individual steps.</li> <li>They are both good a parallelizing tasks.</li> <li>They both allow you to write workflow steps in Python.</li> </ul> <p>How is Airflow different?</p> <ul> <li>Airflow must be deployed and run continuously.</li> <li>Airflow needs a persistence engine (database) to store data long-term.</li> <li>Airflow workflows and operators can only be written in Python.</li> <li>Operator code is tightly coupled to Airflow.</li> <li>Operators have to explicitly consider container engines if you want to run things in a container.</li> </ul> Argo Workflows <p>Argo Workflows is a container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).</p> <p>How are Arcaflow and Argo Workflows similar?</p> <ul> <li>They can both run several steps.</li> <li>They can both run containers as workflow steps.</li> <li>They both allow for passing of data between steps.</li> </ul> <p>How is Argo Workflows different?</p> <ul> <li>Argo Workflows allows you to define workflows directly in Kubernetes custom resources.</li> <li>Argo Workflows allows you to run any container image as a step.</li> <li>Argo Workflows only runs as a Kubernetes operator and cannot run outside of it.</li> <li>Argo Workflows only supports a single Kubernetes cluster.</li> <li>In order to run things in parallel, you need to hand-write a DAG</li> </ul> Netflix Conductor <p>Conductor is a platform created by Netflix to orchestrate workflows that span across microservices.</p> <p>How are Arcaflow and Conductor similar?</p> <ul> <li>They both allow for passing of data between steps.</li> <li>They are both good a parallelizing tasks.</li> </ul> <p>How is Conductor different?</p> <ul> <li>Conductor has a user interface.</li> <li>Conductor keeps a history of jobs that have run in the past.</li> <li>Conductor must be deployed and run continuously.</li> <li>Conductor needs a persistence engine (database) to store data long-term.</li> <li>Conductor requires at least 16 GB of RAM to run everything.</li> <li>Workers must reach Conductor over HTTP and must be explicitly deployed.</li> </ul> Tekton <p>Tekton is a framework for creating CI/CD systems, allowing developers to build, test, and deploy across cloud providers and on-premise systems.</p> <p>How are Arcaflow and Tekton similar?</p> <ul> <li>They both have tasks and pipelines to run steps in sequence.</li> <li>They both allow for passing of data between steps.</li> </ul> <p>How is Tekton different?</p> <ul> <li>Tekton is a full CI/CD system that can be coupled to your version control system without additional tools.</li> <li>Tekton has built-in supply chain security.</li> <li>Tekton allows you to run any container image without additional integrations.</li> <li>Tekton is deployed inside a Kubernetes cluster and cannot exist without it.</li> <li>Tekton has no officially-supported integrations with other platforms and tools.</li> </ul> qDup <p>qDup allows shell commands to be queued up across multiple servers to coordinate performance tests. It is designed to follow the same workflow as a user at a terminal so that commands can be performed with or without qDup. Commands are grouped into re-usable scripts that are mapped to different hosts by roles.</p> <p>How are Arcaflow and qDup similar?</p> <ul> <li>They are both workflow systems.</li> <li>They both run on your laptop and don\u2019t need a large server.</li> <li>You don\u2019t need to deploy them on target hosts or run them permanently.</li> <li>They can both run things on remote systems out of the box.</li> </ul> <p>How is qDup different?</p> <ul> <li>qDup has advanced controls for creating loops, signaling, waiting for events, etc.</li> <li>qDup makes it very simple to run scripts in a parallelized way.</li> <li>qDup runs commands over SSH locally, or integrates with podman. There are plans to support Docker and Kubernetes in the future.</li> <li>qDup is written in Java.</li> </ul>"},{"location":"arcaflow/getting-started/","title":"Arcaflow Getting Started Guide","text":""},{"location":"arcaflow/getting-started/#step-1-get-a-container-engine","title":"Step 1: Get a container engine","text":"<p>In order to use Arcaflow, you will need a container engine on your computer. For the purposes of this guide, we\u2019ll assume you are using Docker or Podman.</p>"},{"location":"arcaflow/getting-started/#step-2-get-the-engine","title":"Step 2: Get the engine","text":"<p>Head on over to the GitHub releases page and download the latest release.</p>"},{"location":"arcaflow/getting-started/#step-3-create-your-first-plugin","title":"Step 3: Create your first plugin","text":"<p>Let\u2019s create a simple hello-world plugin in Python. We\u2019ll publish the code here, you can find the details in the Python plugin guide.</p> plugin.py<pre><code>#!/usr/local/bin/python3\nimport dataclasses\nimport sys\nfrom arcaflow_plugin_sdk import plugin\n\n\n@dataclasses.dataclass\nclass InputParams:\n    name: str\n\n\n@dataclasses.dataclass\nclass SuccessOutput:\n    message: str\n\n\n@plugin.step(\n    id=\"hello-world\",\n    name=\"Hello world!\",\n    description=\"Says hello :)\",\n    outputs={\"success\": SuccessOutput},\n)\ndef hello_world(params: InputParams):\n    return \"success\", SuccessOutput(f\"Hello, {params.name}\")\n\n\nif __name__ == \"__main__\":\n    sys.exit(\n        plugin.run(\n            plugin.build_schema(\n                hello_world,\n            )\n        )\n    )\n</code></pre> <p>Tip</p> <p>Further reading: Creating your first Python plugin</p>"},{"location":"arcaflow/getting-started/#step-4-build-the-plugin","title":"Step 4: Build the plugin","text":"<p>Next, let\u2019s create a <code>Dockerfile</code> and build a container image:</p> <p>Dockerfile<pre><code>FROM python:alpine\n\nADD plugin.py /\nRUN chmod +x /plugin.py &amp;&amp; pip install arcaflow_plugin_sdk\n\nENTRYPOINT [\"/plugin.py\"]\nCMD []\n</code></pre> You can now build the plugin container.</p> DockerPodman <pre><code>docker build -t example-plugin .\n</code></pre> <pre><code>podman build -t example-plugin .\n</code></pre> <p>Tip</p> <p>Further reading: Packaging plugins</p> <p>Did you know?</p> <p>While Arcaflow is a workflow engine, plugins can be run independentily via the command line. Try running your containerized helo-world plugin directly.</p> DockerPodman <pre><code>echo \"name: Arca Lot\" | docker run -i --rm example-plugin -f -\n</code></pre> <pre><code>echo \"name: Arca Lot\" | podman run -i --rm example-plugin -f -\n</code></pre>"},{"location":"arcaflow/getting-started/#step-5-create-a-simple-workflow","title":"Step 5: Create a simple workflow","text":"<p>Let\u2019s start with something simple: we\u2019ll incorporate the plugin above into a workflow. Let\u2019s create a <code>workflow.yaml</code> in an empty directory</p> workflow.yaml<pre><code>input:\n  root: RootObject\n  objects:\n    RootObject:\n      id: RootObject\n      properties:\n        name:\n          type:\n            type_id: string\nsteps:\n  greet:\n    plugin: example-plugin\n    input:\n      name: !expr $.input.name\noutput:\n  message: !expr $.steps.greet.outputs.success.message\n</code></pre> <p>Tip</p> <p>Further reading: Creating workflows</p>"},{"location":"arcaflow/getting-started/#step-6-create-an-input-file","title":"Step 6: Create an input file","text":"<p>Now, let\u2019s create an input file for our workflow named <code>input.yaml</code>:</p> input.yaml<pre><code>name: Arca Lot\n</code></pre>"},{"location":"arcaflow/getting-started/#step-7-create-an-engine-configuration","title":"Step 7: Create an engine configuration","text":"<p>You will need an Arcaflow <code>config.yaml</code> file to prevent Arcaflow from trying to pull the container image.</p> <p>Tip</p> <p>Without a config file, the default behavior of Arcaflow is to run with docker and to always pull plugin container images for the workflow.</p> DockerPodman config.yaml<pre><code>deployer:\n  type: docker\n  deployment:\n    # Make sure we don't try to pull the image we have locally\n    imagePullPolicy: Never\n</code></pre> config.yaml<pre><code>deployer:\n  type: podman\n  deployment:\n    # Make sure we don't try to pull the image we have locally\n    imagePullPolicy: Never\n</code></pre> <p>Tip</p> <p>Further reading: Setting up Arcaflow</p>"},{"location":"arcaflow/getting-started/#step-7-run-the-workflow","title":"Step 7: Run the workflow","text":"<p>Finally, let\u2019s run our workflow. Make sure you are in the directory where the workflow is located.</p> Linux/MacOSWindows <pre><code>/path/to/arcaflow -input input.yaml -config config.yaml\n</code></pre> <pre><code>C:\\path\\to\\arcaflow.exe -input input.yaml -config config.yaml\n</code></pre> <p>If everything went well, after a few seconds you should see logs messages similar to the ones shown below:</p> <pre><code>2023-03-22T11:25:58+01:00       info            Loading plugins locally to determine schemas...\n2023-03-22T11:25:58+01:00       info            Deploying example-plugin...\n2023-03-22T11:25:58+01:00       info            Creating container from image example-plugin...\n2023-03-22T11:25:59+01:00       info            Container started.\n2023-03-22T11:25:59+01:00       info            Schema for example-plugin obtained.\n2023-03-22T11:25:59+01:00       info            Schema loading complete.\n2023-03-22T11:25:59+01:00       info            Building dependency tree...\n2023-03-22T11:25:59+01:00       info            Dependency tree complete.\n2023-03-22T11:25:59+01:00       info            Dependency tree Mermaid:\nflowchart TD\nsubgraph input\ninput.name\nend\ninput.name--&gt;steps.greet\nsteps.greet--&gt;steps.greet.outputs.success\nsteps.greet.outputs.success--&gt;output\n2023-03-22T11:25:59+01:00       info            Starting step greet...\n2023-03-22T11:25:59+01:00       info            Creating container from image example-plugin...\n2023-03-22T11:26:00+01:00       info            Container started.\n2023-03-22T11:26:00+01:00       info            Step greet is now running...\n2023-03-22T11:26:00+01:00       info            Step greet is now executing ATP...\n2023-03-22T11:26:00+01:00       info            Step \"greet\" has finished with output success.\nmessage: Hello, Arca Lot\n</code></pre> <p>As you can see, the last line of the output is the output data from the workflow.</p> <p>Did you know?</p> <p>Arcaflow provides Mermaid markdown in the workflow output that allows you to quickly visualize the workflow in a graphic format. You can grab the Mermaid graph you see in the output and put it into the Mermaid editor.</p> Mermaid markdownMermaid rendered flowchart <pre><code>flowchart TD\nsubgraph input\ninput.name\nend\ninput.name--&gt;steps.greet\nsteps.greet--&gt;steps.greet.outputs.success\nsteps.greet.outputs.success--&gt;output\n</code></pre> <pre><code>flowchart TD\nsubgraph input\ninput.name\nend\ninput.name--&gt;steps.greet\nsteps.greet--&gt;steps.greet.outputs.success\nsteps.greet.outputs.success--&gt;output</code></pre> <p>Tip</p> <p>Further reading: Running Arcaflow</p>"},{"location":"arcaflow/getting-started/#next-steps","title":"Next steps","text":"<p>Congratulations, you are now an Arcaflow user! Here are some things you can do next to start working with plugins and workflows:</p> <ul> <li>See our repostories of community-supported plugins \u00bb</li> <li>Get our latest plugin container builds from quay.io \u00bb</li> <li>Experiment with more advanced example workflows \u00bb</li> </ul>"},{"location":"arcaflow/getting-started/#keep-learning","title":"Keep learning","text":"<p>Hungry for more? Keep digging into our docs::</p> <ul> <li>Learn more about the concepts behind Arcaflow \u00bb</li> <li>Learn how to set up Arcaflow \u00bb</li> <li>Learn how to create plugins \u00bb</li> <li>Learn how to create workflows \u00bb</li> </ul> <p>Contribute to Arcaflow \u00bb</p>"},{"location":"arcaflow/concepts/","title":"Concepts","text":"<p>This section of the documentation deals with theoretical concepts around Arcaflow. Fear not, it\u2019s not a university exam, but simply a description on how we designed Arcaflow the way we did and why we did so.</p> Architecture <p>Get started with a primer on the core architecture of Arcaflow.</p> <p>Read more about architecture \u00bb</p> Typing <p>We believe in strong and static typing to avoid bugs, so Arcaflow has its own typing system.</p> <p>Read more about typing \u00bb</p> Plugins <p>Arcaflow is interoperable between several programming languages. Currently we provide SDKs for Python and Go.</p> <p>Read more about plugins \u00bb</p> Workflows <p>Arcaflow runs several steps and connects them together into a workflow.</p> <p>Read more about workflows \u00bb</p> Flow control (WIP) <p>In the future, we want to add the ability to perform loops, dynamic parallelization, etc.</p> <p>Read more about flow control \u00bb</p>"},{"location":"arcaflow/concepts/architecture/","title":"Arcaflow architecture","text":"<p>The Arcaflow architecture consists of the following 2 keys elements:</p> <ol> <li>Plugins</li> <li>The Engine</li> </ol>"},{"location":"arcaflow/concepts/architecture/#engine","title":"Engine","text":"<p>The engine is responsible for the orchestration of the workflow steps. It has several duties:</p> <ol> <li>Provide schemas for workflow files, read workflows and construct execution graphs.</li> <li>Type-check the execution graphs to make sure that the data transfers between steps are type-safe.</li> <li>Orchestrate plugin execution with Docker, Podman and Kubernetes.</li> <li>Execute the workflow, following the workflow rules.</li> </ol> <p>The engine itself is designed to be run from a command line interface, possibly as a webserver, but is not designed to run in a redundant fashion. Instead of implementing redundancy itself, the engine will receive support to execute workflows in third party systems, such as Kafka.</p> <p>A stretch goal for the engine is to make it fully embeddable, possibly with in-binary workflows and execution images to make them easily to ship in network-restricted environments.</p>"},{"location":"arcaflow/concepts/architecture/#plugins","title":"Plugins","text":"<p>Plugins provide execution for one or more steps for a workflow. The job of a plugin is to do one thing and do it well. A plugin provides a thin layer over third party tools, or its own implementation of features. Its main job is to provide accurate input and output schema information to the engine and transform the data as needed.</p> <p>For example, a plugin may output unformatted text, which a plugin has to parse and build a machine-readable data structure for that information. This reformatting of data allows the engine to pipe data between steps and reliably check the data for faults.</p> <p>The current plan is to provide plugin SDKs for Python, GO, and Rust (in that order).</p>"},{"location":"arcaflow/concepts/architecture/#typing","title":"Typing","text":"<p>A core element of the Arcaflow system is the typing system. Each plugin and the engine itself will provide a machine-readable data structure that describes what inputs are expected and what outputs may be produced. If you are familiar with JSON schema or OpenAPI, this is similar, and Arcaflow can produce those schema documents. However, the Arcaflow system is stricter than those industry standards to optimize for performance and simpler implementation in all supported programming languages.</p>"},{"location":"arcaflow/concepts/architecture/#executing-workflows","title":"Executing workflows","text":"<p>Arcaflow workflows are orchestrated in the Engine, while plugins can be run locally or remotely on container engines. This lends itself to a Git-based workflow:</p> <pre><code>flowchart LR\n    subgraph laptop[Your laptop]\n        direction LR\n\n        ui(UI)\n        engine(Engine)\n        git(Git)\n\n        ui -- Workflow --&gt; engine\n        ui -- Workflow --&gt; git -- Workflow --&gt; engine\n        engine -- Execution results --&gt; ui\n    end\n\n    subgraph docker[Docker/Podman&lt;br&gt;on your laptop]\n        direction LR\n\n        plugins1(Plugin)\n\n        engine -- Step execution --&gt; plugins1\n    end\n    engine -- Launch plugin --&gt; docker\n\n    subgraph k8s[Kubernetes]\n        direction LR\n\n        plugins2(Plugin)\n\n        engine -- Step execution --&gt; plugins2\n    end\n    engine -- Launch plugin --&gt; k8s\n\n    apis(Other APIs)\n    plugins1 --&gt; apis\n    plugins2 --&gt; apis    </code></pre>"},{"location":"arcaflow/concepts/plugins/","title":"Arcaflow plugins","text":"<p>Arcaflow is designed as an interoperable system between programming languages. Therefore, plugins are started as external processes and the communication with the plugin takes place over its standard input and output. The Arcaflow Engine passes data between the plugins as required by the workflow file. </p> <p>In the vast majority of cases, plugins run inside a container, while the Arcaflow Engine itself does not. This allows Arcaflow to pass data between several Kubernetes clusters, local plugins, or even run plugins via Podman over SSH. These capabilities are built into the Arcaflow Engine with the help of deployers.</p> <p>Since Arcaflow has an internal typing system, each plugin must declare at the start what input data it requires and what outputs it produces. This allows the Engine to verify that the workflow can be run, and that no invalid data is being used. If invalid data is detected, the workflow is aborted to prevent latent defects in the data.</p> <p>In summary, you can think of Arcaflow as a strongly (and at some time in the future possibly statically) typed system for executing workflows, where individual plugins run in containers across several systems.</p>"},{"location":"arcaflow/concepts/typing/","title":"Typing system","text":"<p>Let\u2019s say you are creating a system that measures performance. But, uh-oh! A bug has struck! Instead of returning a number, a plugin returns an empty string. Would you want that converted to a numeric <code>0</code> for a metric? Or worse yet, would you want a negative number resulting from a bug to make it into your metrics? Would you want to collect metrics for years just to find out they are all wrong?</p> <p>If the answer is no, then the typing system is here to help. Each plugin or workflow in Arcaflow is required to explicitly state what data types it accepts for its fields, and what their boundaries are. When a plugin then violates its own rules, the engine makes sure that corrupt data isn\u2019t used any further.</p> <p>For example, let\u2019s look at the definition of an integer:</p> <pre><code>type_id: integer\nmin: 10\nmax: 128\n</code></pre> <p>It\u2019s so simple, but it already prevents a lot of bugs: non-integers, numbers out of range.</p> <p>But wait! A typing system can do more for you. For example, we can automatically generate a nice documentation from it. Let\u2019s take this object as an example:</p> <pre><code>type_id: object\nid: name\nproperties:\n  name:\n    type:\n      type_id: string\n      min: 1\n      max: 256\n    display:\n      name: \"Name\"\n      description: \"The name of the user.\"\n      icon: |\n        &lt;svg ...&gt;&lt;/svg&gt;\n</code></pre> <p>That\u2019s all it takes to render a nice form field or automatic documentation. You can read more about creating types in the plugins section or the workflows section, or see the complete typing reference in the Contributing guide.</p>"},{"location":"arcaflow/concepts/workflows/","title":"Arcaflow Workflows (concept)","text":"<p>Tip</p> <p>This document describes the concept of Arcaflow Workflows. We describe the process of writing a workflow in this section</p>"},{"location":"arcaflow/concepts/workflows/#steps","title":"Steps","text":"<p>Workflows are a way to describe a sequence or parallel execution of individual steps. The steps are provided exclusively by plugins. The simplest workflow looks like this:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]</code></pre> <p>However, this is only true if the step only has one output. Most steps will at least have two possible outputs, for success and error states:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]: yes\n  Step --&gt; [*]: no</code></pre> <p>Plugins can declare as many outputs as needed, with custom names. The workflow engine doesn\u2019t make a distinction based on the names, all outputs are treated equal for execution.</p> <p>An important rule is that one step must always end in exactly one output. No step must end without an output, and no step can end in more than one output. This provides a mechanism to direct the flow of the workflow execution.</p> <p>Plugins must also explicitly declare what parameters they expect as input for the step, and the data types of these and what parameters they will produce as output.</p>"},{"location":"arcaflow/concepts/workflows/#interconnecting-steps","title":"Interconnecting steps","text":"<p>When two steps are connected, they will be executed after each other:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  Step1 --&gt; Step2\n  Step2 --&gt; [*]</code></pre> <p>Similarly, when two steps are not directly connected, they may be executed in parallel:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  [*] --&gt; Step2\n  Step1 --&gt; [*]\n  Step2 --&gt; [*]</code></pre> <p>You can use the interconnection to direct the flow of step outputs:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  Step3: Step 3\n  [*] --&gt; Step1\n  Step1 --&gt; Step2: success\n  Step1 --&gt; Step3: error\n  Step2 --&gt; [*]\n  Step3 --&gt; [*]</code></pre>"},{"location":"arcaflow/concepts/workflows/#passing-data-between-steps","title":"Passing data between steps","text":"<p>When two steps are connected, you have the ability to pass data between them. Emblematically described:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  Step1 --&gt; Step2: input_1 = $.steps.step1.outputs.success\n  Step2 --&gt; [*]</code></pre> <p>The data type of the input on Step 2 in this case must match the result of the expression. If the data type does not match, the workflow will not be executed.</p>"},{"location":"arcaflow/concepts/workflows/#undefined-inputs","title":"Undefined inputs","text":"<p>Step inputs can either be required or optional. When a step input is required, it must be configured or the workflow will fail to execute. However, there are cases when the inputs cannot be determined from previous steps. In this case, the workflow start can be connected and the required inputs can be obtained from the user when running the workflow:</p> <pre><code>stateDiagram-v2\n  Step1: Step 1\n  Step2: Step 2\n  [*] --&gt; Step1\n  [*] --&gt; Step2: input_1 = $.input.option_1\n  Step1 --&gt; Step2: input_2 = $.steps.step1.outputs.success\n  Step2 --&gt; [*]</code></pre> <p>This is typically the case when credentials, such as database access, etc. are required.</p>"},{"location":"arcaflow/concepts/workflows/#outputs","title":"Outputs","text":"<p>The output for each step is preserved for later inspection. However, the workflow can explicitly declare outputs. These outputs are usable in scripted environments as a direct output of the workflow:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step\n  Step --&gt; [*]: output_1 = $.steps.step1.outputs.success</code></pre> <p>Background processes</p> <p>Each plugin will only be invoked once, allowing plugins to run background processes, such as server applications. The plugins must handle SIGINT and SIGTERM events properly.</p>"},{"location":"arcaflow/concepts/workflows/#flow-control-wip","title":"Flow control (WIP)","text":"<p>The workflow contains several flow control operations. These flow control operations are not implemented by plugins, but are part of the workflow engine itself.</p>"},{"location":"arcaflow/concepts/workflows/#foreach","title":"Foreach","text":"<p>The foreach flow control allows you to loop over a sub-workflow with a list of input objects.</p> <pre><code>stateDiagram-v2\n  [*] --&gt; ForEach\n  state ForEach {\n    [*] --&gt; loop_list_input\n    loop_list_input --&gt; sub_workflow\n    sub_workflow --&gt; loop_list_input\n    state sub_workflow {\n      [*] --&gt; Step1\n      Step1 --&gt; [*]\n    }\n    sub_workflow --&gt; [*]: Sub Output\n  }\n  ForEach --&gt; [*]: Output</code></pre> <p>Warning</p> <p>The features below are in-development and not yet implemented in the released codebase.</p>"},{"location":"arcaflow/concepts/workflows/#abort","title":"Abort","text":"<p>The abort flow control is a quick way to exit out of a workflow. This is useful when entering a terminal error state and the workflow output data would be useless anyway.</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step1\n  Step1 --&gt; Abort: Output 1\n  Step1 --&gt; Step2: Output 2\n  Step2 --&gt; [*]</code></pre> <p>However, this is only required if you want to abort the workflow immediately. If you want an error case to result in the workflow failing, but whatever steps can be finished being finished, you can leave error outputs unconnected.</p>"},{"location":"arcaflow/concepts/workflows/#do-while","title":"Do-while","text":"<p>A do-while block will execute the steps in it as long as a certain condition is met. The condition is derived from the output of the step or steps executed inside the loop:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; DoWhile\n  state DoWhile {\n    [*] --&gt; Step1\n    Step1 --&gt; [*]: output_1_condition=$.step1.output_1.finished == false   \n  }\n  DoWhile --&gt; [*]</code></pre> <p>If the step declares multiple outputs, multiple conditions are possible. The do-while block will also have multiple outputs:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; DoWhile\n  state DoWhile {\n    [*] --&gt; Step1\n    Step1 --&gt; [*]: Output 1 condition\n    Step1 --&gt; [*]: Output 2 condition   \n  }\n  DoWhile --&gt; [*]: Output 1\n  DoWhile --&gt; [*]: Output 2</code></pre> <p>You may decide to only allow exit from a loop if one of the two outputs is satisfied:</p> <pre><code>stateDiagram-v2\n  [*] --&gt; DoWhile\n  state DoWhile {\n    [*] --&gt; Step1\n    Step1 --&gt; Step1: Output 1\n    Step1 --&gt; [*]: Output 2\n  }\n  DoWhile --&gt; [*]: Output 1</code></pre>"},{"location":"arcaflow/concepts/workflows/#condition","title":"Condition","text":"<p>A condition is a flow control operation that redirects the flow one way or another based on an expression. You can also create multiple branches to create a switch-case effect.</p> <pre><code>stateDiagram-v2\n  state if_state &lt;&lt;choice&gt;&gt;\n  Step1: Step 1\n  [*] --&gt; Step1\n  Step1 --&gt; if_state\n  Step2: Step 2\n  Step3: Step 3\n  if_state --&gt; Step2: $.step1.output_1 == true\n  if_state --&gt; Step3: $.step1.output_1 == false</code></pre>"},{"location":"arcaflow/concepts/workflows/#multiply","title":"Multiply","text":"<p>The multiply flow control operation is useful when you need to dynamically execute sub-workflows in parallel based on an input condition. You can, for example, use this to run a workflow step on multiple or all Kubernetes nodes.</p> <pre><code>stateDiagram-v2\n  Lookup: Lookup Kubernetes hosts\n  [*] --&gt; Lookup\n  Lookup --&gt; Multiply\n  state Multiply {\n    [*] --&gt; Stresstest\n    Stresstest --&gt; [*]\n  }\n  Multiply --&gt; [*]</code></pre> <p>The output of a Multiply operation will be a map, keyed with a string that is configured from the input.</p> <p>Tip</p> <p>You can think of a Multiply step like a for-each loop, but the steps being executed in parallel.</p>"},{"location":"arcaflow/concepts/workflows/#synchronize","title":"Synchronize","text":"<p>The synchronize step attempts to synchronize the execution of subsequent steps for a specified key. The key must be a constant and cannot be obtained from an input expression.</p> <pre><code>stateDiagram-v2\n  [*] --&gt; Step1\n  [*] --&gt; Step2\n  Synchronize1: Synchronize (key=a)\n  Synchronize2: Synchronize (key=a)\n  Step1 --&gt; Synchronize1\n  Step2 --&gt; Synchronize2\n  Synchronize1 --&gt; Step3\n  Synchronize2 --&gt; Step4\n  Step3 --&gt; [*]\n  Step4 --&gt; [*]</code></pre>"},{"location":"arcaflow/contributing/","title":"Contributing to Arcaflow","text":"<p>First of all, welcome to the Arca Lot! Whether you are a beginner or a seasoned veteran, your contributions are most appreciated. Thank you!</p> <p>Now, let\u2019s get you started. There are a number of ways you can contribute on GitHub, please check the Arcaflow project board for open issues. Additionally, here are a few repos you can contribute to:</p> Repository What you can do here arcalot.github.io Improve the documentation arcaflow-plugin-sdk-go Improve the Go SDK arcaflow-plugin-sdk-python Improve the Python SDK arcaflow-engine Improve the Arcaflow Engine arcaflow-engine-deployer-kubernetes Improve the Kubernetes deployment of plugins arcaflow-engine-deployer-docker Improve the Docker deployment of plugins arcaflow-engine-deployer-podman Improve the Podman deployment of plugins arcaflow-expressions Improve the Arcaflow expression language arcaflow-plugin-image-builder Improve the Arcaflow plugin packaging arcaflow-plugin-* Improve the officially supported plugins <p>If you want to contribute regularly, why not join the Arcalot Round Table by reading our charter and signing up as a member? That way you get a voice in the decisions we make!</p>"},{"location":"arcaflow/contributing/#license","title":"License","text":"<p>All code in Arcaflow is licensed under the Apache 2.0 license. The documentation is licensed under CC-BY-4.0. Please make sure you read and understand these licenses before contributing. If you are contributing on behalf of your employer, please make sure you have permission to do so.</p>"},{"location":"arcaflow/contributing/#principles","title":"Principles","text":"<p>While we don\u2019t deal in absolutes (only a sith would do that) we hold ourselves to a few key principles. There are plenty of things where we could do better in these areas, so if you find something, please open an issue. It\u2019s important!</p>"},{"location":"arcaflow/contributing/#the-principle-of-the-least-surprise","title":"The principle of the least surprise","text":"<p>Sometimes, things are just hard to make user-friendly. If presented with two choices, we will always pick the one that doesn\u2019t break expectations. What would an average user expect to happen without reading the documentation? If something surprised you, please open a bug.</p>"},{"location":"arcaflow/contributing/#the-principle-of-nice-error-messages","title":"The principle of nice error messages","text":"<p>When using Arcaflow, you should never be confronted with a stack trace. Error messages should always explain what went wrong and how to fix it. We know, this is a tall order, but if you see an error message that is not helpful, please open a bug.</p>"},{"location":"arcaflow/contributing/#the-principle-of-intern-friendliness","title":"The principle of intern-friendliness","text":"<p>There is enough software out in the wild that requires months of training and is really hard to get into. Arcaflow isn\u2019t the easiest to learn either, see the whole typing system thing, but nevertheless, the software should be written in such a way that an intern with minimal training can sit down and do something useful with it. If something is unnecessarily hard or undocumented, you guessed it, please open a bug.</p>"},{"location":"arcaflow/contributing/#the-principle-of-typing","title":"The principle of typing","text":"<p>We believe that strong and static typing can save us from bugs. This applies to programming languages just as much as it applies to workflows. We aim to make a system tell us that something is wrong before we spent several hours running it.</p>"},{"location":"arcaflow/contributing/#the-principle-of-testing","title":"The principle of testing","text":"<p>Bugs? Yeah, we have those, and we want fewer of them. Since we are a community effort, we can\u2019t afford a large QA team to test through everything manually before a release. Therefore, it\u2019s doubly important that we have automated tests that run on every change. Furthermore, we want our tests to run quickly and without additional setup time. You should be able to run <code>go test</code> or <code>python -m unittest discover</code> and get a result within a few seconds at most. This makes it more likely that a contributor will run the tests and contribute new tests instead of waiting for CI to sort it out.</p>"},{"location":"arcaflow/contributing/#the-principle-of-small-piles","title":"The principle of small piles","text":"<p>Every software is\u2026 pardon our French: crap. Ours is no exception. The difference is how big and how stinky the piles are. We aim to make the piles small, well-defined and as stink-less as possible. If we need to replace a pile with another pile, it should be easy to do so.</p> <p>Translated to software engineering, we create APIs between our piles components. These APIs can be in the form of code, or in the form of a GitHub Actions workflow. A non-leaky API helps us replace one side of the API without touching the other.</p>"},{"location":"arcaflow/contributing/#the-principle-of-kindness-to-our-future-self","title":"The principle of kindness to our future self","text":"<p>Writing code should be fun, most of us got into this industry because we enjoyed creating something. We want to keep this joy of creation. What kills the enthusiasm fastest is having to slog through endless pieces of obtuse code, spending hours and hours trying to accomplish a one-line change. When we write code, we want to be kind to our future selves. That\u2019s why we not only write documentation and tests for our users, we also create these for ourselves and our peers.</p>"},{"location":"arcaflow/contributing/deployers/","title":"Arcaflow Deployers Development Guide","text":"<p>The Arcaflow Engine relies on deployers to execute containers. Deployers provide a binary-safe transparent tunnel of communication between a plugin and the engine. (Typically, this will be done via standard input/output, but other deployers are possible.)</p> <p>The Engine and the plugin communicate via the Arcaflow Transport Protocol over this tunnel, but the deployer is unaware of the method of this communication.</p> <p>Deployers are written in Go and must implement the deployer interface. Deployers are not dynamically pluggable, they must also be added to the engine code to be usable.</p>"},{"location":"arcaflow/contributing/engine/","title":"Arcaflow Engine Development Guide","text":"<p>Warning</p> <p>The engine is currently undergoing a major refactor. This page describes the engine post-refactor.</p> <p>The Arcaflow engine is responsible for parsing a YAML workflow and executing it. It goes through several phases during execution.</p>"},{"location":"arcaflow/contributing/engine/#yaml-loading-phase","title":"YAML loading phase","text":"<p>During the YAML loading phase, the engine loads the workflow YAML as raw data containing YAML nodes. We need the raw YAML nodes to access the YAML tags, which we use to turn the structure into expressions. The resulting data structure of this phase is a structure consisting of maps, lists, strings, and expression objects.</p> <p>YAML</p> <p>YAML, at its core, only knows three data types: maps, lists, and strings. Additionally, each entry can have a tag in the form of <code>!foo</code> or <code>!!foo</code>.</p>"},{"location":"arcaflow/contributing/engine/#basic-workflow-parsing","title":"Basic workflow parsing","text":"<p>Once the YAML is loaded, we can take the data created and parse the workflow. This will validate the input definition and the basic step definitions and provide a more structured data. However, at this point the plugin schemas are not known yet, so any data structure related to steps is accepted as-is. </p>"},{"location":"arcaflow/contributing/engine/#schema-loading","title":"Schema loading","text":"<p>The engine has an API to provide step types. These step types have the ability to provide a lifecycle and load their schema. In case of plugins, this means that the plugin is fired up briefly and its schema is queried. (See Deployers.)</p>"},{"location":"arcaflow/contributing/engine/#dag-construction","title":"DAG construction","text":"<p>Once the schema is loaded, the Directed Acyclic Graph can be constructed from the expressions. Each lifecycle stage input is combed for expressions and a DAG is built.</p>"},{"location":"arcaflow/contributing/engine/#static-code-analysis-future","title":"Static code analysis (future)","text":"<p>The expression library already has the facilities to inspect types, which will, in the future, provide us the ability to perform a static code analysis on the workflow. This will guarantee users that a workflow can be executed without typing problems.</p>"},{"location":"arcaflow/contributing/engine/#workflow-execution","title":"Workflow execution","text":"<p>When the DAG is complete and contains no cycles, the workflow execution can proceed. The execution cycle queries lifecycle nodes that have no more inbound dependencies and runs the lifecycle. When a lifecycle stage finishes, the corresponding nodes are removed from the DAG, freeing up other nodes for execution.</p>"},{"location":"arcaflow/contributing/expressions/","title":"Arcaflow Expressions Development Guide","text":"<p>The expressions library provides the engine and other potential users with a simple way to compile expressions and provide typing information about an expression result.</p> <p>The library consists of two parts: the internal parser/AST and the API layer.</p>"},{"location":"arcaflow/contributing/expressions/#the-parser-ast","title":"The Parser / AST","text":"<p>The expressions parser constructs an Abstract Syntax Tree from the expression which can then be walked by the API layer. The AST consists of the following node types:</p>"},{"location":"arcaflow/contributing/expressions/#dot-notation","title":"Dot Notation","text":"<p>Let\u2019s say you have an expression <code>foo.bar</code>. The dot notation node is the dot in the middle. The left subtree of the dot will be the entire expression left of the dot, while the right subtree will be everything to the right.</p>"},{"location":"arcaflow/contributing/expressions/#bracket-expression","title":"Bracket Expression","text":"<p>Bracket expressions are expressions in the form of <code>foo[bar]</code>. The left subtree will represent the expression to the left of the brackets (<code>foo</code> in the example), while the right subtree will represent the subexpression within the brackets (<code>bar</code> in the example).</p>"},{"location":"arcaflow/contributing/expressions/#binary-operations","title":"Binary Operations","text":"<p>Binary operations include all of the operations that have a left and right subtree that do not have a special node representing them (dot notation and bracket expression are examples of special cases). Binary operations are represented by a node containing an operation and the subtrees to which the operation is applied.</p>"},{"location":"arcaflow/contributing/expressions/#unary-operations","title":"Unary Operations","text":"<p>Unary operations include boolean complement <code>!</code> and numeric negation <code>-</code>. Unary operations are represented by a node containing an operation and the subtree to which the operation is applied. Unlike binary operations, unary operations have only one subtree.</p>"},{"location":"arcaflow/contributing/expressions/#identifiers","title":"Identifiers","text":"<p>Identifiers come in two forms:</p> <ol> <li><code>$</code> references the root of the data structure.</li> <li>A plain string identifier from a token matching the regular expression <code>^\\w+$</code>. This may be used for accessing object fields or as function identifiers.</li> </ol>"},{"location":"arcaflow/contributing/expressions/#the-api-layer","title":"The API Layer","text":"<p>The API layer provides three functions:</p> <ol> <li>Evaluate an expression against a data structure without type checking</li> <li>Provide dependency information of an expression</li> <li>Return the resulting type info of an expression when given a schema</li> </ol> <p>All three functions walk the AST above and construct the required data.</p>"},{"location":"arcaflow/contributing/plugin-protocol/","title":"Arcaflow Plugin protocol specification (ATP)","text":"<p>Arcaflow runs plugins locally in a container using Docker or Podman, or remotely in Kubernetes. Each plugin must be containerized and communicates with the engine over standard input/output. This document outlines the protocol the engine and the plugins use to communicate.</p> <p>Hint</p> <p>You do not need this page if you only intend to implement a plugin with the SDK!</p>"},{"location":"arcaflow/contributing/plugin-protocol/#execution-model","title":"Execution model","text":"<p>A single plugin execution is intended to run a single task and not more. This simplifies the code since there is no need to try and clean up after each task. Each plugin is executed in a container and must communicate with the engine over standard input/output. Furthermore, the plugin must add a handler for <code>SIGTERM</code> and properly clean up if there are services running in the background.</p> <p>Each plugin is executed at the start of the workflow, or workflow block, and is terminated only at the end of the current workflow or workflow block. The plugin can safely rely on being able to start a service in the background and then keeping it running until the <code>SIGTERM</code> comes to shut down the container.</p> <p>However, the plugin must, under no circumstances, start doing work until the engine sends the command to do so. This includes starting any services inside the container or outside. This restriction is necessary to be able to launch the plugin with minimal resource consumption locally on the engine host to fetch the schema.</p> <p>The plugin execution is divided into three major steps.</p> <ol> <li>When the plugin is started, it must output the current plugin protocol version and its schema to the standard output. The engine will read this output from the container logs.</li> <li>When it is time to start the work, the engine will send the desired step ID with its input parameters over the standard input. The plugin acknowledges this and starts to work. When the work is complete, the plugin must automatically output the results to the standard output.</li> <li>When a shutdown is desired, the engine will send a <code>SIGTERM</code> to the plugin. The plugin has up to 30 seconds to shut down. The <code>SIGTERM</code> may come at any time, even while the work is still running, and the plugin must appropriately shut down. If the work is not complete, it is important that the plugin does not send error output to STDOUT. If the plugin fails to stop by itself within 30 seconds, the plugin container is forcefully stopped.</li> </ol>"},{"location":"arcaflow/contributing/plugin-protocol/#protocol","title":"Protocol","text":"<p>As a data transport protocol, we use CBOR messages RFC 8949 back to back due to their self-delimiting nature. This section provides the entire protocol as JSON schema below.</p>"},{"location":"arcaflow/contributing/plugin-protocol/#step-0-the-start-output-message","title":"Step 0: The \u201cstart output\u201d message","text":"<p>Because Kubernetes has no clean way of capturing an output right at the start, the initial step of the plugin execution involves the engine sending an empty CBOR message (<code>None</code> or <code>Nil</code>) to the plugin. This indicates, that the plugin may start its output now.</p>"},{"location":"arcaflow/contributing/plugin-protocol/#step-1-hello-message","title":"Step 1: Hello message","text":"<p>The \u201cHello\u201d message is a way for the plugin to introduce itself and present its steps and schema. Transcribed to JSON, a message of this kind would look as follows:</p> <pre><code>{\n  \"version\": 1,\n  \"steps\": {\n    \"step-id-1\": {\n      \"name\": \"Step 1\",\n      \"description\": \"This is the first step\",\n      \"input\": {\n        \"schema\": {\n          // Input schema\n        }\n      },\n      \"outputs\": {\n        \"output-id-1\": {\n          \"name\": \"Name for this output kind\",\n          \"description\": \"Description for this output\",\n          \"schema\": {\n            // Output schema\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>The schemas must describe the data structure the plugin expects. For a simple hello world input would look as follows:</p> <pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"name\": {\n      \"type\": \"string\"\n    }\n  }\n}\n</code></pre> <p>The full schema is described below in the Schema section.</p>"},{"location":"arcaflow/contributing/plugin-protocol/#step-2-start-work-message","title":"Step 2: Start work message","text":"<p>The \u201cstart work\u201d message has the following parameters in CBOR:</p> <pre><code>{\n  \"id\": \"id-of-the-step-to-execute\",\n  \"config\": {\n    // Input parameters according to schema here\n  }\n}\n</code></pre> <p>The plugin must respond with a CBOR message of the following format:</p> <pre><code>{\n  \"status\": \"started\"\n}\n</code></pre>"},{"location":"arcaflow/contributing/plugin-protocol/#step-3a-crash","title":"Step 3/a: Crash","text":"<p>If the plugin execution ended unexpectedly, the plugin should crash and output a reasonable error message to the standard error. The plugin must exit with a non-zero exit status to notify the engine that the execution failed.</p>"},{"location":"arcaflow/contributing/plugin-protocol/#step-3b-output","title":"Step 3/b: Output","text":"<p>When the plugin has executed successfully, it must emit a CBOR message to the standard output:</p> <pre><code>{\n  \"output_id\": \"id-of-the-declared-output\",\n  \"output_data\": {\n    // Result data of the plugin\n  },\n  \"debug_logs\": \"Unstructured logs here for debugging as a string.\"\n}\n</code></pre>"},{"location":"arcaflow/contributing/plugin-protocol/#schema","title":"Schema","text":"<p>This section contains the exact schema that the plugin sends to the engine.</p> Type: <code>scope</code> Root object: Schema Properties steps (<code>map[string, reference[Step]]</code>) Name: Steps Description: Steps this schema supports. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Step]</code> Referenced object: Step (see in the Objects section below) Objects AnySchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> BoolSchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Display (<code>object</code>) Type: <code>object</code> Properties description (<code>string</code>) Name: Description Description: Description for this item if needed. Required: No Minimum: 1 Examples <pre><code>\"Please select the fruit you would like.\"\n</code></pre> icon (<code>string</code>) Name: Icon Description: SVG icon for this item. Must have the declared size of 64x64, must not include additional namespaces, and must not reference external resources. Required: No Minimum: 1 Examples <pre><code>\"&lt;svg ...&gt;&lt;/svg&gt;\"\n</code></pre> name (<code>string</code>) Name: Name Description: Short text serving as a name or title for this item. Required: No Minimum: 1 Examples <pre><code>\"Fruit\"\n</code></pre> Float (<code>object</code>) Type: <code>object</code> Properties max (<code>float</code>) Name: Maximum Description: Maximum value for this float (inclusive). Required: No Examples <pre><code>16.0\n</code></pre> min (<code>float</code>) Name: Minimum Description: Minimum value for this float (inclusive). Required: No Examples <pre><code>5.0\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units (see in the Objects section below) Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> Int (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units (see in the Objects section below) Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> IntEnum (<code>object</code>) Type: <code>object</code> Properties units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units (see in the Objects section below) Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> values (<code>map[int, reference[Display]]</code>) Name: Values Description: Possible values for this field. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>int</code> Value type Type: <code>reference[Display]</code> Referenced object: Display (see in the Objects section below) Examples <pre><code>{\"1024\": {\"name\": \"kB\"}, \"1048576\": {\"name\": \"MB\"}}\n</code></pre> List (<code>object</code>) Type: <code>object</code> Properties items (<code>one of[string]</code>) Name: Items Description: ReflectedType definition for items in this list. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> Map (<code>object</code>) Type: <code>object</code> Properties keys (<code>one of[string]</code>) Name: Keys Description: ReflectedType definition for keys in this map. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> values (<code>one of[string]</code>) Name: Values Description: ReflectedType definition for values in this map. Required: No Object (<code>object</code>) Type: <code>object</code> Properties id (<code>string</code>) Name: ID Description: Unique identifier for this object within the current scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> properties (<code>map[string, reference[Property]]</code>) Name: Properties Description: Properties of this object. Required: Yes Key type Type: <code>string</code> Minimum: 1 Value type Type: <code>reference[Property]</code> Referenced object: Property (see in the Objects section below) OneOfIntSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[int, one of[string]]</code>) Name: Types Required: No Key type Type: <code>int</code> Value type Type: <code>one of[string]</code> OneOfStringSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[string, one of[string]]</code>) Name: Types Required: No Key type Type: <code>string</code> Value type Type: <code>one of[string]</code> Pattern (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Property (<code>object</code>) Type: <code>object</code> Properties conflicts (<code>list[string]</code>) Name: Conflicts Description: The current property cannot be set if any of the listed properties are set. Required: No List Items Type: <code>string</code> default (<code>string</code>) Name: Default Description: Default value for this property in JSON encoding. The value must be unserializable by the type specified in the type field. Required: No display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display (see in the Objects section below) examples (<code>list[string]</code>) Name: Examples Description: Example values for this property, encoded as JSON. Required: No List Items Type: <code>string</code> required (<code>bool</code>) Name: Required Description: When set to true, the value for this field must be provided under all circumstances. Required: No Default<pre><code>true\n</code></pre> required_if (<code>list[string]</code>) Name: Required if Description: Sets the current property to required if any of the properties in this list are set. Required: No List Items Type: <code>string</code> required_if_not (<code>list[string]</code>) Name: Required if not Description: Sets the current property to be required if none of the properties in this list are set. Required: No List Items Type: <code>string</code> type (<code>one of[string]</code>) Name: Type Description: Type definition for this field. Required: Yes Ref (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display (see in the Objects section below) id (<code>string</code>) Name: ID Description: Referenced object ID. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Schema (<code>object</code>) Type: <code>object</code> Properties steps (<code>map[string, reference[Step]]</code>) Name: Steps Description: Steps this schema supports. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Step]</code> Referenced object: Step (see in the Objects section below) Scope (<code>object</code>) Type: <code>object</code> Properties objects (<code>map[string, reference[Object]]</code>) Name: Objects Description: A set of referencable objects. These objects may contain references themselves. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Object]</code> Referenced object: Object (see in the Objects section below) root (<code>string</code>) Name: Root object Description: ID of the root object of the scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Step (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display (see in the Objects section below) id (<code>string</code>) Name: ID Description: Machine identifier for this step. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> input (<code>reference[Scope]</code>) Name: Input Description: Input data schema. Required: Yes Referenced object: Scope (see in the Objects section below) outputs (<code>map[string, reference[StepOutput]]</code>) Name: Input Description: Input data schema. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[StepOutput]</code> Referenced object: StepOutput (see in the Objects section below) StepOutput (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display (see in the Objects section below) error (<code>bool</code>) Name: Error Description: If set to true, this output will be treated as an error output. Required: No Default<pre><code>false\n</code></pre> schema (<code>reference[Scope]</code>) Name: Schema Description: Data schema for this particular output. Required: Yes Referenced object: Scope (see in the Objects section below) String (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>5\n</code></pre> pattern (<code>pattern</code>) Name: Pattern Description: Regular expression this string must match. Required: No Examples <pre><code>\"^[a-zA-Z]+$\"\n</code></pre> StringEnum (<code>object</code>) Type: <code>object</code> Properties values (<code>map[string, reference[Display]]</code>) Name: Values Description: Mapping where the left side of the map holds the possible value and the right side holds the display value for forms, etc. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>string</code> Value type Type: <code>reference[Display]</code> Referenced object: Display (see in the Objects section below) Examples <pre><code>{\n  \"apple\": {\n    \"name\": \"Apple\"\n  },\n  \"orange\": {\n    \"name\": \"Orange\"\n  }\n}\n</code></pre> Unit (<code>object</code>) Type: <code>object</code> Properties name_long_plural (<code>string</code>) Name: Name long (plural) Description: Longer name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"bytes\",\"characters\"\n</code></pre> name_long_singular (<code>string</code>) Name: Name long (singular) Description: Longer name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"byte\",\"character\"\n</code></pre> name_short_plural (<code>string</code>) Name: Name short (plural) Description: Shorter name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"B\",\"chars\"\n</code></pre> name_short_singular (<code>string</code>) Name: Name short (singular) Description: Shorter name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"B\",\"char\"\n</code></pre> Units (<code>object</code>) Type: <code>object</code> Properties base_unit (<code>reference[Unit]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: Yes Referenced object: Unit (see in the Objects section below) Examples <pre><code>{\n  \"name_short_singular\": \"B\",\n  \"name_short_plural\": \"B\",\n  \"name_long_singular\": \"byte\",\n  \"name_long_plural\": \"bytes\"\n}\n</code></pre> multipliers (<code>map[int, reference[Unit]]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: No Key type Type: <code>int</code> Value type Type: <code>reference[Unit]</code> Referenced object: Unit (see in the Objects section below) Examples <pre><code>{\n  \"1024\": {\n    \"name_short_singular\": \"kB\",\n    \"name_short_plural\": \"kB\",\n    \"name_long_singular\": \"kilobyte\",\n    \"name_long_plural\": \"kilobytes\"\n  },\n  \"1048576\": {\n    \"name_short_singular\": \"MB\",\n    \"name_short_plural\": \"MB\",\n    \"name_long_singular\": \"megabyte\",\n    \"name_long_plural\": \"megabytes\"\n  }\n}\n</code></pre>"},{"location":"arcaflow/contributing/typing/","title":"The Arcaflow type system","text":"<p>Arcaflow takes a departure from the classic run-and-pray approach of running workloads and validates workflows before executing them. To do this, Arcaflow starts the plugins as needed before the workflow is run and queries them for their schema. This schema will contain information about what kind of input a plugin requests and what kind of outputs it can produce.</p> <p>A plugin can support multiple workflow steps and must provide information about the data types in its input and output for each step. A step can have exactly one input format, but may declare more than one output.</p> <p>The typesystem is inspired by JSON schema and OpenAPI, but it is more restrictive due to the need to efficiently serialize workloads over various formats.</p>"},{"location":"arcaflow/contributing/typing/#types","title":"Types","text":"<p>The typing system supports the following data types.</p> <ul> <li>Objects are key-value pairs where the keys are always a fixed set of strings and values are of various types declared for each key. They are similar to classes in most programming languages. Fields in objects can be optional, which means they will have no value (commonly known as <code>null</code>, <code>nil</code>, or <code>None</code>), or a default value.</li> <li>OneOf are a special type that is a union of multiple objects, distinguished by a special field called the discriminator.</li> <li>Lists are a sequence of values of the same type. The value type can be any of the other types described in this section. List items must always have a value and cannot be empty (<code>null</code>, <code>nil</code>, or <code>None</code>).</li> <li>Maps are key-value pairs that always have fixed types for both keys and values. Maps with mixed keys or values are not supported. Map keys can only be strings, integers, or enums. Map keys and values must always have a value and cannot be empty (<code>null</code>, <code>nil</code>, or <code>None</code>).</li> <li>Enums are either strings or integers that can take only a fixed set of values. Enums with mixed value types are not supported.</li> <li>Strings are a sequence of bytes.</li> <li>Patterns are regular expressions.</li> <li>Integers are 64-bit numbers that can take both positive and negative values.</li> <li>Floats are 64-bit floating point numbers that can take both positive and negative values.</li> <li>Booleans are values of <code>true</code> or <code>false</code> and cannot take any other values.</li> <li>Scopes and Refs are object-like types that allow you to create circular references (see below).</li> <li>Any accepts any primitive type (string, int, float, bool, map, list) but no patterns, objects, etc.</li> </ul>"},{"location":"arcaflow/contributing/typing/#validation","title":"Validation","text":"<p>The typing system also contains more in-depth validation than just simple types:</p>"},{"location":"arcaflow/contributing/typing/#strings","title":"Strings","text":"<p>Strings can have a minimum or maximum length, as well as validation against a regular expression.</p>"},{"location":"arcaflow/contributing/typing/#ints-floats","title":"Ints, floats","text":"<p>Number types can have a minimum and maximum value (inclusive).</p>"},{"location":"arcaflow/contributing/typing/#booleans","title":"Booleans","text":"<p>Boolean types can take a value of either <code>true</code> or <code>false</code>, but when unserializing from YAML or JSON formats, strings or int values of <code>true</code>, <code>yes</code>, <code>on</code>, <code>enable</code>, <code>enabled</code>, <code>1</code>, <code>false</code>, <code>no</code>, <code>off</code>, <code>disable</code>, <code>disabled</code> or <code>0</code> are also accepted.</p>"},{"location":"arcaflow/contributing/typing/#lists-maps","title":"Lists, maps","text":"<p>Lists a7nd maps can have constraints on the minimum or maximum number of items in them (inclusive).</p>"},{"location":"arcaflow/contributing/typing/#objects","title":"Objects","text":"<p>Object fields can have several constraints:</p> <ul> <li><code>required_if</code> has a list of other fields that, if set, make the current field required.</li> <li><code>required_if_not</code> has a list of other fields that, if none are set, make the current field required.</li> <li><code>conflicts</code> has a list of other fields that cannot be set together with the current field.</li> </ul>"},{"location":"arcaflow/contributing/typing/#oneof","title":"OneOf","text":"<p>When you need to create a list of multiple object types, or simply have an either-or choice between two object types, you can use the OneOf type. This field uses an already existing field of the underlying objects, or adds an extra field to the schema to distinguish between the different types. Translated to JSON, you might see something like this:</p> <pre><code>{\n  \"_type\": \"Greeter\",\n  \"message\": \"Hello world!\"\n}\n</code></pre>"},{"location":"arcaflow/contributing/typing/#scopes-and-refs","title":"Scopes and refs","text":"<p>Objects, on their own, cannot create circular references. It is not possible to create two objects that refer to each other. That\u2019s where scopes and refs come into play. Scopes hold a list of objects, identified by an ID. Refs inside the scope (for example, in an object property) can refer to these IDs. Every scope has a root object, which will be used to provide its \u201cobject-like\u201d features, such as a list of fields.</p> <p>For example:</p> <pre><code>objects:\n  my_root_object:\n    id: my_root_object\n    properties:\n      ...\nroot: my_root_object\n</code></pre> <p>Multiple scopes can be nested into each other. The ref always refers to the closest scope up the tree. Multiple scopes can be used when combining objects from several sources (e.g. several plugins) into one schema to avoid conflicting ID assignments.</p>"},{"location":"arcaflow/contributing/typing/#any","title":"Any","text":"<p>Any accepts any primitive type (string, int, float, bool, map, list) but no patterns, objects, etc. This type is severely limited in its ability to validate data and should only be used in exceptional cases when there is no other way to describe a schema.</p>"},{"location":"arcaflow/contributing/typing/#metadata","title":"Metadata","text":"<p>Object fields can also declare metadata that will help with creating user interfaces for the object. These fields are:</p> <ul> <li>name: A user-readable name for the field.</li> <li>description: A user-readable description for the field. It may contain newlines, but no other formatting is allowed.</li> <li>icon: SVG icon</li> </ul>"},{"location":"arcaflow/contributing/typing/#intent-inference","title":"Intent inference","text":"<p>For display purposes, the type system is designed so that it can infer the intent of the data. We wish to communicate the following intents:</p> <ul> <li>Graphs are x-y values of timestamps mapped to one or more values.</li> <li>Log lines are timestamps associated with text.</li> <li>Events are timestamps associated with other structured data.</li> </ul> <p>We explicitly document the following inference rules, which will probably change in the future.</p> <ul> <li>A map with keys of timestamps and values of integers or floats is rendered as a graph.</li> <li>A map with keys of timestamps and values of objects consisting only of integers and floats is rendered as a graph.</li> <li>A map with keys of timestamps and values of strings is considered a log line.</li> <li>A map with keys of timestamps and objects that don\u2019t match the rules above are considered an event.</li> <li>A map with keys of short strings and integer or float values is considered a pie chart.</li> <li>A list of objects consisting of a single timestamp and otherwise only integers and floats is rendered as a graph.</li> <li>A list of objects with a single timestamp and a single string are considered a log line.</li> <li>A list of objects with a single short string and a single integer or float is considered a pie chart.</li> <li>A list of objects consisting of no more than one timestamp and multiple other fields not matching the rules above is considered an event.</li> <li>If an object has a field called \u201ctitle\u201d, \u201cname\u201d, or \u201clabel\u201d, it will be used as a label for the current data set in a chart, or as a title for the wrapping box for the user interface elements.</li> </ul>"},{"location":"arcaflow/contributing/typing/#reference-manual","title":"Reference Manual","text":"<p>This section explains how a scope object looks like. The plugin protocol contains a few more types that are used when communicating a schema.</p> Type: <code>scope</code> Root object: Scope Properties objects (<code>map[string, reference[Object]]</code>) Name: Objects Description: A set of referencable objects. These objects may contain references themselves. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Object]</code> Referenced object: Object (see in the Objects section below) root (<code>string</code>) Name: Root object Description: ID of the root object of the scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Objects AnySchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> BoolSchema (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Display (<code>object</code>) Type: <code>object</code> Properties description (<code>string</code>) Name: Description Description: Description for this item if needed. Required: No Minimum: 1 Examples <pre><code>\"Please select the fruit you would like.\"\n</code></pre> icon (<code>string</code>) Name: Icon Description: SVG icon for this item. Must have the declared size of 64x64, must not include additional namespaces, and must not reference external resources. Required: No Minimum: 1 Examples <pre><code>\"&lt;svg ...&gt;&lt;/svg&gt;\"\n</code></pre> name (<code>string</code>) Name: Name Description: Short text serving as a name or title for this item. Required: No Minimum: 1 Examples <pre><code>\"Fruit\"\n</code></pre> Float (<code>object</code>) Type: <code>object</code> Properties max (<code>float</code>) Name: Maximum Description: Maximum value for this float (inclusive). Required: No Examples <pre><code>16.0\n</code></pre> min (<code>float</code>) Name: Minimum Description: Minimum value for this float (inclusive). Required: No Examples <pre><code>5.0\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units (see in the Objects section below) Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> Int (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units (see in the Objects section below) Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> IntEnum (<code>object</code>) Type: <code>object</code> Properties units (<code>reference[Units]</code>) Name: Units Description: Units this number represents. Required: No Referenced object: Units (see in the Objects section below) Examples <pre><code>{   \"base_unit\": {       \"name_short_singular\": \"%\",       \"name_short_plural\": \"%\",       \"name_long_singular\": \"percent\",       \"name_long_plural\": \"percent\"   }}\n</code></pre> values (<code>map[int, reference[Display]]</code>) Name: Values Description: Possible values for this field. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>int</code> Value type Type: <code>reference[Display]</code> Referenced object: Display (see in the Objects section below) Examples <pre><code>{\"1024\": {\"name\": \"kB\"}, \"1048576\": {\"name\": \"MB\"}}\n</code></pre> List (<code>object</code>) Type: <code>object</code> Properties items (<code>one of[string]</code>) Name: Items Description: ReflectedType definition for items in this list. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> Map (<code>object</code>) Type: <code>object</code> Properties keys (<code>one of[string]</code>) Name: Keys Description: ReflectedType definition for keys in this map. Required: No max (<code>int</code>) Name: Maximum Description: Maximum value for this int (inclusive). Required: No Minimum: 0 Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum number of items in this list.. Required: No Minimum: 0 Examples <pre><code>5\n</code></pre> values (<code>one of[string]</code>) Name: Values Description: ReflectedType definition for values in this map. Required: No Object (<code>object</code>) Type: <code>object</code> Properties id (<code>string</code>) Name: ID Description: Unique identifier for this object within the current scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> properties (<code>map[string, reference[Property]]</code>) Name: Properties Description: Properties of this object. Required: Yes Key type Type: <code>string</code> Minimum: 1 Value type Type: <code>reference[Property]</code> Referenced object: Property (see in the Objects section below) OneOfIntSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[int, one of[string]]</code>) Name: Types Required: No Key type Type: <code>int</code> Value type Type: <code>one of[string]</code> OneOfStringSchema (<code>object</code>) Type: <code>object</code> Properties discriminator_field_name (<code>string</code>) Name: Discriminator field name Description: Name of the field used to discriminate between possible values. If this field is present on any of the component objects it must also be an int. Required: No Examples <pre><code>\"_type\"\n</code></pre> types (<code>map[string, one of[string]]</code>) Name: Types Required: No Key type Type: <code>string</code> Value type Type: <code>one of[string]</code> Pattern (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Property (<code>object</code>) Type: <code>object</code> Properties conflicts (<code>list[string]</code>) Name: Conflicts Description: The current property cannot be set if any of the listed properties are set. Required: No List Items Type: <code>string</code> default (<code>string</code>) Name: Default Description: Default value for this property in JSON encoding. The value must be unserializable by the type specified in the type field. Required: No display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display (see in the Objects section below) examples (<code>list[string]</code>) Name: Examples Description: Example values for this property, encoded as JSON. Required: No List Items Type: <code>string</code> required (<code>bool</code>) Name: Required Description: When set to true, the value for this field must be provided under all circumstances. Required: No Default<pre><code>true\n</code></pre> required_if (<code>list[string]</code>) Name: Required if Description: Sets the current property to required if any of the properties in this list are set. Required: No List Items Type: <code>string</code> required_if_not (<code>list[string]</code>) Name: Required if not Description: Sets the current property to be required if none of the properties in this list are set. Required: No List Items Type: <code>string</code> type (<code>one of[string]</code>) Name: Type Description: Type definition for this field. Required: Yes Ref (<code>object</code>) Type: <code>object</code> Properties display (<code>reference[Display]</code>) Name: Display Description: Name, description and icon. Required: No Referenced object: Display (see in the Objects section below) id (<code>string</code>) Name: ID Description: Referenced object ID. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Scope (<code>object</code>) Type: <code>object</code> Properties objects (<code>map[string, reference[Object]]</code>) Name: Objects Description: A set of referencable objects. These objects may contain references themselves. Required: Yes Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> Value type Type: <code>reference[Object]</code> Referenced object: Object (see in the Objects section below) root (<code>string</code>) Name: Root object Description: ID of the root object of the scope. Required: Yes Minimum: 1 Maximum: 255 Must match pattern: <code>^[$@a-zA-Z0-9-_]&amp;#43;$</code> String (<code>object</code>) Type: <code>object</code> Properties max (<code>int</code>) Name: Maximum Description: Maximum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>16\n</code></pre> min (<code>int</code>) Name: Minimum Description: Minimum length for this string (inclusive). Required: No Minimum: 0 Units: characters Examples <pre><code>5\n</code></pre> pattern (<code>pattern</code>) Name: Pattern Description: Regular expression this string must match. Required: No Examples <pre><code>\"^[a-zA-Z]+$\"\n</code></pre> StringEnum (<code>object</code>) Type: <code>object</code> Properties values (<code>map[string, reference[Display]]</code>) Name: Values Description: Mapping where the left side of the map holds the possible value and the right side holds the display value for forms, etc. Required: Yes <pre><code>| Minimum items: | 1 |\n</code></pre> Key type Type: <code>string</code> Value type Type: <code>reference[Display]</code> Referenced object: Display (see in the Objects section below) Examples <pre><code>{\n  \"apple\": {\n    \"name\": \"Apple\"\n  },\n  \"orange\": {\n    \"name\": \"Orange\"\n  }\n}\n</code></pre> Unit (<code>object</code>) Type: <code>object</code> Properties name_long_plural (<code>string</code>) Name: Name long (plural) Description: Longer name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"bytes\",\"characters\"\n</code></pre> name_long_singular (<code>string</code>) Name: Name long (singular) Description: Longer name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"byte\",\"character\"\n</code></pre> name_short_plural (<code>string</code>) Name: Name short (plural) Description: Shorter name for this UnitDefinition in plural form. Required: Yes Examples <pre><code>\"B\",\"chars\"\n</code></pre> name_short_singular (<code>string</code>) Name: Name short (singular) Description: Shorter name for this UnitDefinition in singular form. Required: Yes Examples <pre><code>\"B\",\"char\"\n</code></pre> Units (<code>object</code>) Type: <code>object</code> Properties base_unit (<code>reference[Unit]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: Yes Referenced object: Unit (see in the Objects section below) Examples <pre><code>{\n  \"name_short_singular\": \"B\",\n  \"name_short_plural\": \"B\",\n  \"name_long_singular\": \"byte\",\n  \"name_long_plural\": \"bytes\"\n}\n</code></pre> multipliers (<code>map[int, reference[Unit]]</code>) Name: Base UnitDefinition Description: The base UnitDefinition is the smallest UnitDefinition of scale for this set of UnitsDefinition. Required: No Key type Type: <code>int</code> Value type Type: <code>reference[Unit]</code> Referenced object: Unit (see in the Objects section below) Examples <pre><code>{\n  \"1024\": {\n    \"name_short_singular\": \"kB\",\n    \"name_short_plural\": \"kB\",\n    \"name_long_singular\": \"kilobyte\",\n    \"name_long_plural\": \"kilobytes\"\n  },\n  \"1048576\": {\n    \"name_short_singular\": \"MB\",\n    \"name_short_plural\": \"MB\",\n    \"name_long_singular\": \"megabyte\",\n    \"name_long_plural\": \"megabytes\"\n  }\n}\n</code></pre>"},{"location":"arcaflow/plugins/","title":"Creating Arcaflow plugins","text":"<p>Arcaflow supports writing plugins in any language, and we provide pre-made libraries for Python and Go.</p> <p>Plugins in Arcaflow run in containers, so you can use dependencies and libraries.</p> Writing plugins in Python <p>Python is the easiest language to start writing plugins in, you simply need to write a few dataclasses and a function and that\u2019s already a working plugin.</p> <p>Read more about Python plugins \u00bb</p> Writing plugins in Go <p>Go is the programming language of the engine. Writing plugins in Go is more complicated than Python because you will need to provide both the <code>struct</code>s and the Arcaflow schema. We recommend Go for plugins that interact with Kubernetes.</p> <p>Read more about Go plugins \u00bb</p> Packaging plugins <p>To use plugins with Arcaflow, you will need to package them into a container image. You can, of course, write your own <code>Dockerfile</code>, but we provide a handy utility called Carpenter to automate the process.</p> <p>Read more about packaging \u00bb</p>"},{"location":"arcaflow/plugins/packaging/","title":"Packaging Arcaflow plugins","text":"<p>Arcaflow plugins are distributed using container images. Whatever programming language you are using, you will need to package it up into a container image and distribute it via a container registry.</p>"},{"location":"arcaflow/plugins/packaging/#the-manual-method","title":"The manual method","text":"<p>Currently, we only support the manual method for non-Arcalot plugins. However, it\u2019s very simple. First, create a Dockerfile for your programming language:</p> PythonGo <p>With Python, the Dockerfile heavily depends on which build tool you are using. Here we are demonstrating the usage using pip.</p> <pre><code>FROM python:alpine\n\n# Add the plugin contents\nADD . /plugin\n# Set the working directory\nWORKDIR /plugin\n\n# Install the dependencies. Customize this\n# to your Python package manager.\nRUN pip install -r requirements.txt\n\n# Set this to your .py file\nENTRYPOINT [\"/usr/local/bin/python3\", /plugin/plugin.py\"]\n# Make sure this stays empty!\nCMD []\n</code></pre> <p>For Go plugins we recommend a multi-stage build so the source code doesn\u2019t unnecessarily bloat the image. (Keep in mind, for some libraries you will need to include at least a LICENSE and possibly a NOTICE file in the image.)</p> <pre><code>FROM golang AS build\n# Add the plugin contents\nADD . /plugin\n# Set the working directory\nWORKDIR /plugin\n# Build your image\nENV CGO_ENABLED=0\nRUN go build -o plugin\n\n# Start from an empty image\nFROM scratch\n# Copy the built binary\nCOPY --from=build /plugin/plugin /plugin\n# Set the entry point\nENTRYPOINT [\"/plugin\"]\n# Make sure this stays empty!\nCMD []\n</code></pre> <p>That\u2019s it! Now you can run your build:</p> <pre><code>docker build -t example.com/your-namespace/your-plugin:latest .\ndocker push example.com/your-namespace/your-plugin:latest\n</code></pre>"},{"location":"arcaflow/plugins/go/","title":"Creating plugins in Go","text":"<p>In contrast to Python, Go doesn\u2019t contain enough language elements to infer the types and validation from Go types. Therefore, in order to use Go you both need to create the data structures (e.g. <code>struct</code>) and write the schema by hand. Therefore, we recommend Python for writing plugins.</p> <p>For writing Go plugins, you will need:</p> <ol> <li>Go version 1.18 or higher.</li> <li>The Go SDK for Arcaflow plugins installed (preferably via go mod).</li> <li>A container engine that can build images for packaging.</li> </ol> <p>If you have these three, you can get started with your first plugin.</p>"},{"location":"arcaflow/plugins/go/first/","title":"Writing your first Go plugin","text":"<p>In order to create a Go plugin, you will need to create a Go module project (<code>go mod init</code>) and install the Arcaflow SDK usin <code>go get go.flow.arcalot.io/pluginsdk</code>.</p> <p>Writing a Go plugin consists of the following 4 parts:</p> <ol> <li>The input data model</li> <li>The output data model</li> <li>The callable function</li> <li>The calling scaffold</li> </ol>"},{"location":"arcaflow/plugins/go/first/#the-input-data-model","title":"The input data model","text":"<p>First, we define an input data model. This must be a struct.</p> <pre><code>type Input struct {\n    Name string `json:\"name\"`\n}\n</code></pre> <p>Note</p> <p>The Arcaflow serialization does not use the built-in Go JSON marshaling, so any additional tags like <code>omitempty</code>, or <code>yaml</code> tags are ignored.</p> <p>In addition to the struct above, we must also define a schema for the input data structure:</p> <pre><code>// We define a separate scope, so we can add subobjects later.\nvar inputSchema = schema.NewScopeSchema(\n    // Struct-mapped object schemas are object definitions that are mapped to a specific struct (Input)\n    schema.NewStructMappedObjectSchema[Input](\n        // ID for the object:\n        \"input\",\n        // Properties of the object:\n        map[string]*schema.PropertySchema{\n            \"name\": schema.NewPropertySchema(\n                // Type properties:\n                schema.NewStringSchema(nil, nil, nil),\n                // Display metadata:\n                schema.NewDisplayValue(\n                    schema.PointerTo(\"Name\"),\n                    schema.PointerTo(\"Name of the person to greet.\"),\n                    nil,\n                ),\n                // Required:\n                true,\n                // Required if:\n                []string{},\n                // Required if not:\n                []string{},\n                // Conflicts:\n                []string{},\n                // Default value, JSON encoded:\n                nil,\n                //Examples:\n                nil,\n            )\n        },\n    ),\n)\n</code></pre>"},{"location":"arcaflow/plugins/go/first/#the-output-data-model","title":"The output data model","text":"<p>The output data model is similar to the input. First, we define our output struct:</p> <pre><code>type Output struct {\n    Message string `json:\"message\"`\n}\n</code></pre> <p>Then, we have to describe the schema for this output similar to the input:</p> <pre><code>var outputSchema = schema.NewScopeSchema(\n    schema.NewStructMappedObjectSchema[Output](\n        \"output\",\n        map[string]*schema.PropertySchema{\n            \"message\": schema.NewPropertySchema(\n                schema.NewStringSchema(nil, nil, nil),\n                schema.NewDisplayValue(\n                    schema.PointerTo(\"Message\"),\n                    schema.PointerTo(\"The resulting message.\"),\n                    nil,\n                ),\n                true,\n                nil,\n                nil,\n                nil,\n                nil,\n                nil,\n            )\n        },\n    ),\n)\n</code></pre>"},{"location":"arcaflow/plugins/go/first/#the-callable-function","title":"The callable function","text":"<p>Now we can create a callable function. This function will always take one input and produce an output ID (e.g. <code>\"success\"</code>) and an output data structure. This allows you to return one of multiple possible outputs.</p> <pre><code>func greet(input Input) (string, any) {\n    return \"success\", Output{\n        fmt.Sprintf(\"Hello, %s!\", input.Name),        \n    }\n}\n</code></pre> <p>Finally, we can incorporate this function into a step schema:</p> <pre><code>var greetSchema = schema.NewCallableSchema(\n    schema.NewCallableStep[Input](\n        // ID of the function:\n        \"greet\",\n        // Add the input schema:\n        inputSchema,\n        map[string]*schema.StepOutputSchema{\n            // Define possible outputs:\n            \"success\": schema.NewStepOutputSchema(\n                // Add the output schema:\n                outputSchema,\n                schema.NewDisplayValue(\n                    schema.PointerTo(\"Success\"),\n                    schema.PointerTo(\"Successfully created message.\"),\n                    nil,\n                ),\n                false,\n            ),\n        },\n        // Metadata for the function:\n        schema.NewDisplayValue(\n            schema.PointerTo(\"Greet\"),\n            schema.PointerTo(\"Greets the user.\"),\n            nil,\n        ),\n        // Reference the function\n        greet,\n    )\n)\n</code></pre>"},{"location":"arcaflow/plugins/go/first/#the-calling-scaffold","title":"The calling scaffold","text":"<p>Finally, we need to create our main function to run the plugin:</p> <pre><code>package main\n\nimport (\n    \"go.flow.arcalot.io/pluginsdk/plugin\"\n)\n\nfunc main() {\n    plugin.Run(greetSchema)\n}\n</code></pre>"},{"location":"arcaflow/plugins/go/first/#running-the-plugin","title":"Running the plugin","text":"<p>Go plugins currently cannot run as CLI tools, so you will have to use this plugin in conjunction with the Arcaflow Engine. However, you can dump the schema by running:</p> <pre><code>go run yourplugin.go --schema\n</code></pre>"},{"location":"arcaflow/plugins/go/first/#next-steps","title":"Next steps","text":"<p>Once you are finished with your first plugin, you should read the section about writing a schema.</p>"},{"location":"arcaflow/plugins/go/schema/","title":"Writing a schema in Go","text":"<p>In contrast to Python, the Go SDK does not have the ability to infer the schema from the code of a plugin. The Go language does not have enough information to provide enough information.</p> <p>Therefore, schemas in Go need to be written by hand. This document will explain the details and intricacies of writing a Go schema by hand.</p>"},{"location":"arcaflow/plugins/go/schema/#typed-vs-untyped-serialization","title":"Typed vs. untyped serialization","text":"<p>Since Go is a strongly and statically typed language, there are two ways to serialize and unserialize a type.</p> <p>The untyped serialization functions (<code>Serialize</code>, <code>Unserialize</code>) always result in an <code>any</code> type (<code>interface{}</code> for pre-1.18 code) and you will have to perform a type assertion to get the type you can actually work with.</p> <p>The typed serialization functions (<code>SerializeType</code>, <code>UnserializeType</code>) result in a specific type, but cannot be used in lists, maps, etc. due to the lack of language features, such as covariance.</p> <p>In practice, you will always use untyped functions when writing a plugin, typed functions are only useful for writing Arcaflow Engine code.</p>"},{"location":"arcaflow/plugins/go/schema/#strings","title":"Strings","text":"<p>You can define a string by calling <code>schema.NewStringSchema()</code>. It has 3 parameters:</p> <ol> <li>The minimum number of characters in the string. (<code>*int64</code>)</li> <li>The maximum number of characters in the string. (<code>*int64</code>)</li> <li>A regular expression the string must match. (<code>*regexp.Regexp</code>)</li> </ol> <p>It will result in a <code>*StringSchema</code>, which also complies with the <code>schema.String</code> interface. It unserializes from a string, integer, float to a string and serializes back to a string.</p> <p>Tip</p> <p>You can easily convert a value to a pointer by using the <code>schema.PointerTo()</code> function.</p>"},{"location":"arcaflow/plugins/go/schema/#patterns","title":"Patterns","text":"<p>You can define a regular expression pattern by calling <code>schema.NewPatternSchema()</code>. It has no parameters and will result in a <code>*PatternSchema</code>, which also complies with the <code>schema.Pattern</code> interface. It unserializes from a string to a <code>*regexp.Regexp</code> and serializes back to a string.</p>"},{"location":"arcaflow/plugins/go/schema/#integer","title":"Integer","text":"<p>Integers in Are always 64-bit signed integers. You can define an integer type with the <code>schema.NewIntSchema()</code> function. It takes the following parameters:</p> <ol> <li>The minimum value for the integer. (<code>*int64</code>)</li> <li>The maximum value for the integer. (<code>*int64</code>)</li> <li>The units of the integer. (<code>*UnitsDefinition</code>, see Units)</li> </ol> <p>When unserializing from a string, or another int or float type, the SDK will attempt to parse it as an integer. When serializing, the integer type will always be serialized as an integer.</p>"},{"location":"arcaflow/plugins/go/schema/#floating-point-numbers","title":"Floating point numbers","text":"<p>Floating point numbers are always stored as 64-bit floating point numbers. You can define a float type with the <code>schema.NewFloatSchema()</code> function. It takes the following parameters:</p> <ol> <li>The minimum value for the float. (<code>*float64</code>)</li> <li>The maximum value for the float. (<code>*float64</code>)</li> <li>The units of the float. (<code>*UnitsDefinition</code>, see Units)</li> </ol> <p>When unserializing from a string, or another int or float type, the SDK will attempt to parse it as a float. When serializing, the float type will always be serialized as a float.</p>"},{"location":"arcaflow/plugins/go/schema/#booleans","title":"Booleans","text":"<p>You can define a boolean by calling <code>schema.NewBoolSchema()</code>. It has no parameters and will result in a <code>*BoolSchema</code>, which also complies with the <code>schema.Bool</code> interface. </p> <p>It converts both integers and strings to boolean if possible. The following values are accepted as <code>true</code> or <code>false</code>, respectively:</p> <ul> <li><code>1</code></li> <li><code>yes</code></li> <li><code>y</code></li> <li><code>on</code></li> <li><code>true</code></li> <li><code>enable</code></li> <li><code>enabled</code></li> <li><code>0</code></li> <li><code>no</code></li> <li><code>n</code></li> <li><code>off</code></li> <li><code>false</code></li> <li><code>disable</code></li> <li><code>disabled</code></li> </ul> <p>Boolean types will always serialize to <code>bool</code>.</p>"},{"location":"arcaflow/plugins/go/schema/#enums","title":"Enums","text":"<p>Go doesn\u2019t have any built-in enums, so Arcaflow supports <code>int64</code> and <code>string</code>-based enums. You can define an int enum by calling the <code>schema.NewIntEnumSchema()</code> function. It takes the following parameters:</p> <ol> <li>A <code>map[int64]*DisplayValue</code> of values. The keys are the valid values in the enum. The values are display values, which can also be nil if no special display properties are desired.</li> <li>The units of the enum. (<code>*UnitsDefinition</code>, see Units)</li> </ol> <p>Strings can be defined by using the <code>schema.NewStringEnumSchema()</code> function, which only takes the first parameter with <code>string</code> keys.</p> <p>Both functions return a <code>*EnumSchema[string|int64]</code>, which also complies with the <code>Enum[string|int64]</code> interface.</p>"},{"location":"arcaflow/plugins/go/schema/#lists","title":"Lists","text":"<p>Lists come in two variants: typed and untyped. (See Typed vs. Untyped.) You can create an untyped list by calling <code>schema.NewListSchema()</code> and a typed list by calling <code>schema.NewTypedListSchema()</code>. Both have the following parameters:</p> <ol> <li>The type of item in the list. For untyped lists, this is a plain schema, for typed lists this must also be a typed schema.</li> <li>The minimum number of items in the list. (<code>*int64</code>)</li> <li>The maximum number of items in the list. (<code>*int64</code>)</li> </ol> <p>The result is a <code>*ListSchema</code> for untyped lists, and a <code>*TypedListSchema</code> for typed lists, which also satisfy their corresponding interfaces.</p>"},{"location":"arcaflow/plugins/go/schema/#maps","title":"Maps","text":"<p>Maps, like lists, come in two variants: typed and untyped. (See Typed vs. Untyped.) You can create an untyped map by calling <code>schema.NewMapSchema()</code> and a typed map by calling <code>schema.NewTypedMapSchema()</code>. They both have the following parameters:</p> <ol> <li>The key type. This must be a schema of <code>string</code>, <code>int</code>, or an enum thereof.</li> <li>The value type. This can be any schema.</li> <li>The minimum number of items in the map. (<code>*int64</code>)</li> <li>The maximum number of items in the map. (<code>*int64</code>)</li> </ol> <p>The functions return a <code>*schema.MapSchema</code> and <code>*schema.TypedMapSchema</code>, respectively, which satisfy their corresponding interfaces.</p>"},{"location":"arcaflow/plugins/go/schema/#objects","title":"Objects","text":"<p>Objects come in not two, but three variants: untyped, struct-mapped, and typed. (See Typed vs. Untyped.) Untyped objects unserialize to a <code>map[string]any</code>, whereas struct-mapped objects are bound to a struct, but behave like untyped objects. Typed objects are bound to a struct and are typed. In plugins, you will always want to use struct-mapped object schemas.</p> <p>You can create objects with the following functions:</p> <ul> <li><code>schema.NewObjectSchema</code> for untyped objects.</li> <li><code>schema.NewStructMappedObjectSchema</code> for struct-mapped objects.</li> <li><code>schema.NewTypedObject</code> for typed objects.</li> </ul> <p>They all have two parameters:</p> <ol> <li>A unique object identifier in the current scope. (See Scopes.)</li> <li>A map of string to PropertySchema objects describing the object properties.</li> </ol>"},{"location":"arcaflow/plugins/go/schema/#properties","title":"Properties","text":"<p>Properties of objects are always untyped. You can create a property by calling <code>schema.NewPropertySchema()</code> and it has the following parameters:</p> <ol> <li>The underlying type for the property.</li> <li>The display options for this property. (See Display values.)</li> <li>If the property is required. (<code>bool</code>)</li> <li>The required-if fields. If any of these fields in the current object is set, the current property also becomes required. (<code>[]string</code>)</li> <li>The required-if-not fields. If none of these fields are set in the current object, the current property becomes required. (<code>[]string</code>)</li> <li>The fields the current field conflicts with. If any of these fields are set, the current field must not be set. (<code>[]string</code>)</li> <li>The default value for the current property. (JSON-serialized <code>*string</code>)</li> <li>Examples for the current property. (JSON-serialized <code>[]string</code>)</li> </ol>"},{"location":"arcaflow/plugins/go/schema/#scopes","title":"Scopes","text":"<p>Sometimes, objects need to have circular references to each other. That\u2019s where scopes help. Scopes behave like objects, but act as a container for Refs. They contain a root object and additional objects that can be referenced by ID.</p> <p>You can create a scope by calling <code>schema.NewScopeSchema()</code>. It takes the following parameters:</p> <ol> <li>The root object.</li> <li>A list of additional objects that can be referenced by ID.</li> </ol> <p>Warning</p> <p>When using scopes, you must call <code>ApplyScope</code> on the outermost scope once you have constructed your type tree, otherwise references won\u2019t work.</p>"},{"location":"arcaflow/plugins/go/schema/#refs","title":"Refs","text":"<p>Refs are references to objects in the current scope. You can create a ref by calling <code>schema.NewRefSchema()</code>. It takes two parameters:</p> <ol> <li>The ID of the object referenced.</li> <li>The display properties of this reference. (See Display values.)</li> </ol>"},{"location":"arcaflow/plugins/go/schema/#one-of","title":"One-of","text":"<p>Sometimes, a field must be able to hold more than one type of item. That\u2019s where one-of types come into play. They behave like objects, but have a special field called the discriminator which differentiates between the different possible types. This discriminator field can either be an integer or a string.</p> <p>You can use <code>schema.NewOneOfIntSchema()</code> to create an integer-based one-of type and <code>schema.NewOneOfStringSchema()</code> to create a string-based one. They both accept two parameters:</p> <ol> <li>A <code>map[int64|string]Object</code>, which holds the discriminator values and their corresponding objects (these can be refs or scopes too).</li> <li>A <code>string</code> holding the name of the discriminator field.</li> </ol> <p>The objects in the map are allowed to skip the discriminator field, but if they use it, it must have the same type as listed here.</p>"},{"location":"arcaflow/plugins/go/schema/#any","title":"Any","text":"<p>The \u201cany\u201d type allows any primitive type to pass through. However, this comes with severe limitations and the data cannot be validated, so its use is discouraged. You can create an <code>AnySchema</code> by calling <code>schema.NewAnySchema()</code>. This function has no parameters. </p>"},{"location":"arcaflow/plugins/go/schema/#display-values","title":"Display values","text":"<p>Several types, for example properties, accept a display value. This is a value designed to be rendered as a form field. It has three parameters:</p> <ol> <li>A short, human-readable name.</li> <li>A longer, possibly multi-line description.</li> <li>An embedded SVG icon. This icon should be 64x64 pixels and not contain any external references (e.g. CSS.)</li> </ol> <p>Display types are always optional (can be <code>nil</code>) and you can create one by calling <code>schema.NewDisplayValue()</code></p>"},{"location":"arcaflow/plugins/go/schema/#units","title":"Units","text":"<p>Units make it easier to parse and display numeric values. For example, if you have an integer representing nanoseconds, you may want to parse strings like <code>5m30s</code>. This is similar to the duration type in Go, but with the capabilities of defining your own units.</p> <p>Units have two parameters: the base type and multipliers. You can define a unit type by calling <code>schema.NewUnits()</code> and provide the base unit and multipliers by calling <code>schema.NewUnit()</code>.</p> <pre><code>var u = schema.NewUnits(\n    // Base unit:\n    NewUnit(\n        // Short name, singular\n        \"B\",\n        // Short name, plural\n        \"B\",\n        // Long name, singular\n        \"byte\",\n        // Long name, plural\n        \"bytes\",\n    ),\n    // Multipliers\n    map[int64]*UnitDefinition{\n        1024: NewUnit(\n            \"kB\",\n            \"kB\",\n            \"kilobyte\",\n            \"kilobytes\",\n        ),\n        //...\n    },\n)\n</code></pre> <p>You can use the built-in <code>schema.UnitBytes</code>, <code>schema.UnitDurationNanoseconds</code>, and <code>schema.UnitDurationSeconds</code> units for your plugins.</p>"},{"location":"arcaflow/plugins/python/","title":"Creating plugins with Python","text":"<p>If you want to create an Arcaflow plugin in Python, you will need three things:</p> <ol> <li>Python 3.9+ (PyPy is supported)</li> <li>The Python SDK for Arcaflow plugins</li> <li>A container engine that can build images for packaging.</li> </ol> <p>If you have these three, you can get started with your first plugin.</p>"},{"location":"arcaflow/plugins/python/data-model/","title":"Creating a Python data model","text":"<p>Every plugin needs a schema to represent its expected inputs and outputs in a machine-readable format. The schema strong typing is a core design element of Arcaflow, enabling us to build portable workflows that compartmentalize failure conditions and avoid data errors.</p> <p>When creating a data model for Arcaflow plugins in Python, everything starts with dataclasses. They allow Arcaflow to get information about the data types of individual fields in your class:</p> plugin.py<pre><code>import dataclasses\n\n\n@dataclasses.dataclass\nclass MyDataModel:\n    some_field: str\n    other_field: int\n</code></pre> <p>However, Arcaflow doesn\u2019t support all Python data types. You pick from the following list:</p> <ul> <li><code>str</code></li> <li><code>int</code></li> <li><code>float</code></li> <li><code>bool</code></li> <li>Enums</li> <li><code>re.Pattern</code></li> <li><code>typing.List[othertype]</code></li> <li><code>typing.Dict[keytype, valuetype]</code></li> <li><code>typing.Union[onedataclass, anotherdataclass]</code></li> <li>Dataclasses</li> <li><code>typing.Any</code></li> </ul> <p>You can read more about the individual types in the data types section</p>"},{"location":"arcaflow/plugins/python/data-model/#optional-parameters","title":"Optional parameters","text":"<p>You can also declare any parameter as optional like this:</p> plugin.py<pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Optional[int] = None\n</code></pre> <p>Note that adding <code>typing.Optional</code> is not enough, you must specify the default value.</p>"},{"location":"arcaflow/plugins/python/data-model/#annotations-for-validation-and-metadata","title":"Annotations for validation and metadata","text":"<p>You can specify desired validations for each field like this:</p> plugin.py<pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Annotated[int, schema.name(\"Param\")]\n</code></pre> <p>Tip</p> <p>Annotated objects are preferred as a best practice for a documented schema, and are expected for any officially-supported community plugins.</p> <p>You can use the following annotations to add metadata to your fields:</p> <ul> <li><code>schema.id</code> adds a serialized field name for the current field (e.g. one containing dashes, which is not valid in Python)</li> <li><code>schema.name</code> adds a human-readable name to the parameter. This can be used to present a form field.</li> <li><code>schema.description</code> adds a long-form description to the field.</li> <li><code>schema.example</code> adds an example value to the field. You can repeat this annotation multiple times. The example must be provided as primitive types (no dataclasses).</li> </ul> <p>You can also add validations to the fields. The following annotations are valid for all data types:</p> <ul> <li><code>schema.required_if</code> specifies a field that causes the current field to be required. If the other field is empty, the current field is not required. You can repeat this annotation multiple times. (Make sure to use the optional annotation above.)</li> <li><code>schema.required_if_not</code> specifies a field that, if not filled, causes the current field to be required. You can repeat this annotation multiple times.(Make sure to use the optional annotation above.)</li> <li><code>schema.conflicts</code> specifies a field that cannot be used together with the current field. You can repeat this annotation multiple times. (Make sure to use the optional annotation above.)</li> </ul> <p>Additionally, some data types have their own validations and metadata, such as <code>schema.min</code>, <code>schema.max</code>, <code>schema.pattern</code>, or <code>schema.units</code>.</p> <p>Note</p> <p>When combining <code>typing.Annotated</code> with <code>typing.Optional</code>, the default value is assigned to the <code>Annotated</code> object, not to the <code>Optional</code> object.</p> plugin.py<pre><code>@dataclasses.dataclass\nclass MyClass:\n    param: typing.Annotated[\n        typing.Optional[int],\n        schema.name(\"Param\")\n    ] = None\n</code></pre>"},{"location":"arcaflow/plugins/python/data-model/#data-types","title":"Data types","text":""},{"location":"arcaflow/plugins/python/data-model/#strings","title":"Strings","text":"<p>Strings are, as the name suggests, strings of human-readable characters. You can specify them in your dataclass like this:</p> <pre><code>some_field: str\n</code></pre> <p>Additionally, you can apply the following validations:</p> <ul> <li><code>schema.min()</code> specifies the minimum length of the string if the field is set.</li> <li><code>schema.max()</code> specifies the maximum length of the string if the field is set.</li> <li><code>schema.pattern()</code> specifies the regular expression the string must match if the field is set.</li> </ul>"},{"location":"arcaflow/plugins/python/data-model/#integers","title":"Integers","text":"<p>Integers are 64-bit signed whole numbers. You can specify them in your dataclass like this:</p> <pre><code>some_field: int\n</code></pre> <p>Additionally, you can apply the following validations and metadata:</p> <ul> <li><code>schema.min()</code> specifies the minimum number if the field is set.</li> <li><code>schema.max()</code> specifies the maximum number if the field is set.</li> <li><code>schema.units()</code> specifies the units for this field (e.g. bytes). See Units.</li> </ul>"},{"location":"arcaflow/plugins/python/data-model/#floating-point-numbers","title":"Floating point numbers","text":"<p>Floating point numbers are 64-bit signed fractions. You can specify them in your dataclass like this:</p> <pre><code>some_field: float\n</code></pre> <p>Warning</p> <p>Floating point numbers are inaccurate! Make sure to transmit numbers requiring accuracy as integers!</p> <p>Additionally, you can apply the following validations and metadata:</p> <ul> <li><code>schema.min()</code> specifies the minimum number if the field is set.</li> <li><code>schema.max()</code> specifies the maximum number if the field is set.</li> <li><code>schema.units()</code> specifies the units for this field (e.g. bytes). See Units.</li> </ul>"},{"location":"arcaflow/plugins/python/data-model/#booleans","title":"Booleans","text":"<p>Booleans are <code>True</code> or <code>False</code> values. You can specify them in your dataclass like this:</p> <pre><code>some_field: bool\n</code></pre> <p>Booleans have no additional validations or metadata.</p>"},{"location":"arcaflow/plugins/python/data-model/#enums","title":"Enums","text":"<p>Enums, short for enumerations, are used to define a set of named values as unique constants. They provide a way to represent a fixed number of possible values for a variable, parameter, or property. In Python, an enum is declared as a class, but doesn\u2019t behave as a normal class. Instead, the \u201cattributes\u201d of the class act as independent \u201cmember\u201d or \u201cenumeration member\u201d objects, each of which has a name and a constant value.</p> <p>By using enums, you can give meaningful names to distinct values, making the code more self-explanatory and providing a convenient way to work with sets of related constants.</p> <p>In an Arcaflow schema, an Enum type provides a list of valid values for a field. The Enum must define a set of members with unique values, all of which are either strings or integers.</p> <p>You can specify an enum with string values like this:</p> <p><pre><code>import enum\n\n\nclass MyEnum(enum.Enum):\n  Value1 = \"value 1\"\n  Value2 = \"value 2\"\n\nmy_field: MyEnum\n</code></pre> The MyEnum class above defines two members, Value1 and Value2. Each member is associated with a constant value, in this case, the strings \u201cvalue 1\u201d and \u201cvalue 2\u201d respectively. An input value of \u201cvalue 1\u201d will result in the plugin seeing a value for <code>my_field</code> of MyEnum.Value1.</p> <p>You can specify an Enum class with integer values like this:</p> <pre><code>import enum\n\nclass MyEnum(enum.Enum):\n    Value1 = 1\n    Value2 = 2\n\nmy_field: MyEnum\n</code></pre> <p>The <code>my_field</code> variable is a variable of type MyEnum. It can store one of the defined enumeration members (Value1 or Value2). An input value of 1 in this case will result in the plugin receiving a value for <code>my_field</code> of MyEnum.Value1.</p> <p><pre><code>     value = MyEnum.Value1\n</code></pre> In the above example, the Value1 member of MyEnum is accessed and assigned to the variable value.</p> <p>Note</p> <p>Enumeration members are \u201csingleton\u201d objects, which have a single instance. In Python you should compare enumeration members using <code>is</code> rather than <code>==</code> (for example, <code>variable is MyEnum.Value1</code>). The values of an Enum used in an Arcaflow schema must have values of string or integer data type.</p> <p>Tip</p> <p>Enums aren\u2019t dataclasses, but can be used as the type of dataclass attributes.</p> <p>Warning</p> <p>Do not mix integers and strings in the same enum! The values for each Enum type must all be strings, or all integers.</p>"},{"location":"arcaflow/plugins/python/data-model/#patterns","title":"Patterns","text":"<p>When you need to hold regular expressions, you can use a pattern field. This is tied to the Python regular expressions library. You can specify a pattern field like this:</p> <pre><code>import re\n\nmy_field: re.Pattern\n</code></pre> <p>Pattern fields have no additional validations or metadata.</p> <p>Note</p> <p>If you are looking for a way to do pattern/regex matching for a string you will need to use the schema.pattern() validation which specifies the regular expression, to which the string must match.</p> <p>The below example declares that the first_name variable must only have uppercase and lowercase alphabets.</p> plugin.py<pre><code>@dataclasses.dataclass\nclass MyClass:\n    first_name: typing.Annotated[\n        str,\n        schema.min(2),\n        schema.pattern(re.compile(\"^[a-zA-Z]+$\")),\n        schema.example(\"Arca\"),\n        schema.name(\"First name\")\n    ]\n</code></pre>"},{"location":"arcaflow/plugins/python/data-model/#lists","title":"Lists","text":"<p>When you want to make a list in Arcaflow, you always need to specify its contents. You can do that like this:</p> <pre><code>my_field: typing.List[str]\n</code></pre> <p>Lists can have the following validations:</p> <ul> <li><code>schema.min()</code> specifies the minimum number of items in the list.</li> <li><code>schema.max()</code> specifies the maximum number of items in the list.</li> </ul> <p>Tip</p> <p>Items in lists can also be annotated with validations.</p>"},{"location":"arcaflow/plugins/python/data-model/#dicts","title":"Dicts","text":"<p>Dicts (maps in Arcaflow) are key-value pairs. You need to specify both the key and the value type. You can do that as follows:</p> <pre><code>my_field: typing.Dict[str, str]\n</code></pre> <p>Lists can have the following validations:</p> <ul> <li><code>schema.min()</code> specifies the minimum number of items in the list.</li> <li><code>schema.max()</code> specifies the maximum number of items in the list.</li> </ul> <p>Tip</p> <p>Items in dicts can also be annotated with validations.</p>"},{"location":"arcaflow/plugins/python/data-model/#union-types","title":"Union types","text":"<p>Union types (one-of in Arcaflow) allow you to specify two or more possible objects (dataclasses) that can be in a specific place. The only requirement is that there must be a common field (discriminator) and each dataclass must have a unique value for this field. If you do not add this field to your dataclasses, it will be added automatically for you.</p> <p>For example:</p> <pre><code>import typing\nimport dataclasses\n\n\n@dataclasses.dataclass\nclass FullName:\n    first_name: str\n    last_name: str\n\n\n@dataclasses.dataclass\nclass Nickname:\n    nickname: str\n\n\nname: typing.Annotated[\n    typing.Union[\n        typing.Annotated[FullName, schema.discriminator_value(\"full\")],\n        typing.Annotated[Nickname, schema.discriminator_value(\"nick\")]\n    ], schema.discriminator(\"name_type\")]\n</code></pre> <p>Tip</p> <p>The <code>schema.discriminator</code> and <code>schema.discriminator_value</code> annotations are optional. If you do not specify them, a discriminator will be generated for you.</p>"},{"location":"arcaflow/plugins/python/data-model/#any-types","title":"Any types","text":"<p>Any types allow you to pass through any primitive data (no dataclasses). However, this comes with severe limitations as far as validation and use in workflows is concerned, so this type should only be used in limited cases. For example, if you would like to create a plugin that inserts data into an ElasticSearch database the \u201cany\u201d type would be appropriate here.</p> <p>You can define an \u201cany\u201d type like this:</p> <pre><code>my_data: typing.Any\n</code></pre>"},{"location":"arcaflow/plugins/python/data-model/#units","title":"Units","text":"<p>Integers and floats can have unit metadata associated with them. For example, a field may contain a unit description like this:</p> <pre><code>time: typing.Annotated[int, schema.units(schema.UNIT_TIME)]\n</code></pre> <p>In this case, a string like <code>5m30s</code> will automatically be parsed into nanoseconds. Integers will pass through without conversion. You can also define your own unit types. At minimum, you need to specify the base type (nanoseconds in this case), and you can specify multipliers:</p> <pre><code>my_units = schema.Units(\n  schema.Unit(\n    # Short, singular\n    \"ns\",\n    # Short, plural\n    \"ns\",\n    # Long, singular\n    \"nanosecond\",\n    # Long, plural\n    \"nanoseconds\"\n  ),\n  {\n    1000: schema.Unit(\n      \"ms\",\n      \"ms\",\n      \"microsecond\",\n      \"microseconds\"\n    ),\n    # ...\n  }\n)\n</code></pre> <p>You can then use this description in your <code>schema.units</code> annotations. Additionally, you can also use it to convert an integer or float into its string representation with the <code>my_units.format_short</code> or <code>my_units.format_long</code> functions. If you need to parse a string yourself, you can use <code>my_units.parse</code>.</p>"},{"location":"arcaflow/plugins/python/data-model/#built-in-units","title":"Built-In Units","text":"<p>A number of unit types are built-in to the python SDK for convenience:</p> <ul> <li><code>UNIT_BYTE</code> - Bytes and 2^10 multiples (kilo-, mega-, giga-, tera-, peta-)</li> <li><code>UNIT_TIME</code> - Nanoseconds and human-friendly multiples (microseconds, seconds, minutes, hours, days)</li> <li><code>UNIT_CHARACTER</code> - Character notations (char, chars, character, characters)</li> <li><code>UNIT_PERCENT</code> - Percentage notations (%, percent)</li> </ul>"},{"location":"arcaflow/plugins/python/embedding/","title":"Embedding your Python plugin","text":"<p>Instead of using your plugin as a standalone tool or in conjunction with Arcaflow, you can also embed your plugin into your existing Python application. To do that you simply build a schema and then call the schema yourself. You can pass raw data as an input, and you\u2019ll get the benefit of schema validation.</p> myapp.py<pre><code>from arcaflow_plugin_sdk import plugin\nimport my_arcaflow_plugin\n\n# Build your schema with the step functions passed\nschema = plugin.build_schema(my_arcaflow_plugin.hello_world)\n\n# Which step from the plugin we want to execute\nstep_id = \"hello_world\"\n\n# Input parameters. Note, these must be a dict, not a dataclass\nstep_params = {\n    \"name\": \"Arca Lot\",\n}\n\n# Execute the step\noutput_id, output_data = schema(step_id, step_params)\n\n# Print which kind of result we have\npprint.pprint(output_id)\n\n# Print the result data\npprint.pprint(output_data)\n</code></pre> <p>However, the example above requires you to provide the data as a <code>dict</code>, not a <code>dataclass</code>, and it will also return a <code>dict</code> as an output object. Sometimes, you may want to use a partial approach, where you only use part of the SDK. In this case, you can change your code to run any of the following functions, in order:</p> <ul> <li><code>serialization.load_from_file()</code> to load a YAML or JSON file into a dict</li> <li><code>yourschema.unserialize_input()</code> to turn a <code>dict</code> into a <code>dataclass</code> needed for your steps</li> <li><code>yourschema.call_step()</code> to run a step with the unserialized <code>dataclass</code></li> <li><code>yourschema.serialize_output()</code> to turn the output <code>dataclass</code> into a <code>dict</code></li> </ul>"},{"location":"arcaflow/plugins/python/faq/","title":"Python SDK FAQ","text":""},{"location":"arcaflow/plugins/python/faq/#how-can-i-add-a-field-with-dashes-such-as-my-field","title":"How can I add a field with dashes, such as <code>my-field</code>?","text":"<p>Dataclasses don\u2019t support dashes in parameters. You can work around this by defining the <code>id</code> annotation:</p> <pre><code>@dataclasses.dataclass\nclass MyData:\n    my_field: typing.Annotated[\n        str,\n        schema.id(\"my-field\"),\n    ]\n</code></pre>"},{"location":"arcaflow/plugins/python/faq/#how-can-i-write-a-dataclass-from-a-schema-to-a-yaml-or-json-file","title":"How can I write a dataclass from a schema to a YAML or JSON file?","text":"<p>You can extend Python\u2019s JSON encoder to support dataclasses. If that doesn\u2019t suit your needs, you can use this SDK to convert the dataclasses to their basic representations and then write that to your JSON or YAML file. First, add this outside of your step:</p> <pre><code>my_object_schema = plugin.build_object_schema(MyDataclass)\n</code></pre> <p>Inside your step function you can then dump the data from your input</p> <pre><code>def my_step(params: MyParams):\n    yaml_contents = yaml.dump(my_object_schema.serialize(params.some_param))\n</code></pre>"},{"location":"arcaflow/plugins/python/faq/#how-can-i-easily-load-a-list-from-a-yaml-or-json-into-a-list-of-dataclasses","title":"How can I easily load a list from a YAML or JSON into a list of dataclasses?","text":"<p>This requires a bit of trickery. First, we build a schema from the dataclass representing the row or entry in the list:</p> <pre><code>my_row_schema = plugin.build_object_schema(MyRow)\n</code></pre> <p>Then you can create a list schema:</p> <pre><code>my_list_schema = schema.ListType(my_row_schema)\n</code></pre> <p>You can now unserialize a list obtained from the YAML or JSON file:</p> <pre><code>my_data = my_list_schema.unserialize(json.loads(...))\n</code></pre>"},{"location":"arcaflow/plugins/python/first/","title":"Writing your first Python plugin","text":"<p>In this guide you will learn how to write a basic \u201cHello World\u201d plugin for Arcaflow and then run it without the engine as a standalone tool. In order to proceed this tutorial, you will need to install Python version 3.9 or higher on your machine. The tutorial will make use of the Arcaflow Python SDK to provide the required functionality.</p>"},{"location":"arcaflow/plugins/python/first/#step-1-setting-up-your-environment","title":"Step 1: Setting up your environment","text":"<p>If you have Python installed, you will need to set up your environment. You can use any dependency manager you like, but here are three methods to get you started quickly.</p> <p>Official plugins</p> <p>If you wish to contribute an official Arcaflow plugin on GitHub, please use Poetry. For simplicity, we only accept Poetry plugins.</p> From the template repositoryUsing pipUsing Poetry <ol> <li>Clone or download the template repository</li> <li>Figure out what the right command to call your Python version is:        <pre><code>python3.10 --version\npython3.9 --version\npython3 --version\npython --version\n</code></pre>    Make sure you have at least Python 3.9.</li> <li>Create a virtualenv in your project directory using the following command, replacing your Python call:        <pre><code>python -m venv venv\n</code></pre></li> <li>Activate the venv:        <pre><code>source venv/bin/activate\n</code></pre></li> <li>Install the dependencies:        <pre><code>pip install -r requirements.txt\n</code></pre></li> </ol> <ol> <li>Create an empty folder.</li> <li>Create a <code>requirements.txt</code> with the following content:        <pre><code>arcaflow-plugin-sdk\n</code></pre></li> <li>Figure out what the right command to call your Python version is:        <pre><code>python3.10 --version\npython3.9 --version\npython3 --version\npython --version\n</code></pre>    Make sure you have at least Python 3.9.</li> <li>Create a virtualenv in your project directory using the following command, replacing your Python call:        <pre><code>python -m venv venv\n</code></pre></li> <li>Activate the venv:        <pre><code>source venv/bin/activate\n</code></pre></li> <li>Install the dependencies:        <pre><code>pip install -r requirements.txt\n</code></pre></li> <li>Copy the example plugin, example config and the [tests]https://github.com/arcalot/arcaflow-plugin-template-python/blob/main/tests/test_example_plugin.py) to your directory.</li> </ol> <ol> <li>Assuming you have Poetry installed, run the following command:        <pre><code>poetry new your-plugin\n</code></pre>    Then change the current directory to <code>your-plugin</code>.</li> <li>Figure out what the right command to call your Python version is:        <pre><code>which python3.10\nwhich python3.9\nwhich python3\nwhich python\n</code></pre>    Make sure you have at least Python 3.9.</li> <li>Set Poetry to Python 3.9:        <pre><code>poetry env use /path/to/your/python3.9\n</code></pre></li> <li>Check that your <code>pyproject.toml</code> file has the following lines:        <pre><code>[tool.poetry.dependencies]\npython = \"^3.9\"\n</code></pre></li> <li>Add the SDK as a dependency:        <pre><code>poetry add arcaflow-plugin-sdk\n</code></pre></li> <li>Copy the example plugin, example config and the [tests]https://github.com/arcalot/arcaflow-plugin-template-python/blob/main/tests/test_example_plugin.py) to your directory.</li> <li>Activate the venv:        <pre><code>poetry shell\n</code></pre></li> </ol> <p>Now you are ready to start hacking away at your plugin! You can open the <code>example_plugin.py</code> file and follow along, or you can create a new Python file and write the code.</p>"},{"location":"arcaflow/plugins/python/first/#step-2-creating-an-input-and-output-data-model","title":"Step 2: Creating an input and output data model","text":"<p>Plugins in Arcaflow must explain how they want their input data and what kind of output they produce. Let\u2019s start with the input data model. In our case, we want to ask the user for a name. Normally, you would write this in Python:</p> plugin.py<pre><code>def hello_world(name):\n    return f\"Hello, {name}\"\n</code></pre> <p>However, that\u2019s not how the Arcaflow SDK works. You must always specify the data type of any variable. Additionally, every function can only have one input and it must be a dataclass.</p> <p>So, let\u2019s change the code a little:</p> plugin.py<pre><code>import dataclasses\n\n\n@dataclasses.dataclass\nclass InputParams:\n    name: str\n\ndef hello_world(params: InputParams):\n    # ...\n</code></pre> <p>So far so good, but we are not done yet. The output also has special rules. One plugin function can have more than one possible output, so you need to say which output it is and you need to also return a dataclass.</p> <p>For example:</p> plugin.py<pre><code>import dataclasses\n\n\n@dataclasses.dataclass\nclass InputParams:\n    name: str\n\n\n@dataclasses.dataclass\nclass SuccessOutput:\n    message: str\n\n\ndef hello_world(params: InputParams):\n    return \"success\", SuccessOutput(f\"Hello, {params.name}\")\n</code></pre> <p>Tip</p> <p>If your plugin has a problem, you could create and return an <code>ErrorOutput</code> instead. In the Arcaflow workflow you can then handle each output separately. </p>"},{"location":"arcaflow/plugins/python/first/#step-3-decorating-your-step-function","title":"Step 3: Decorating your step function","text":"<p>Of course, Arcaflow doesn\u2019t know what to do with this code yet. You will need to add a decorator to the <code>hello_world</code> function in order to give Arcaflow the necessary information:</p> plugin.py<pre><code>from arcaflow_plugin_sdk import plugin\n\n\n@plugin.step(\n    id=\"hello-world\",\n    name=\"Hello world!\",\n    description=\"Says hello :)\",\n    outputs={\"success\": SuccessOutput},\n)\ndef hello_world(params: InputParams):\n    # ...\n</code></pre> <p>Let\u2019s go through the parameters:</p> <ul> <li><code>id</code> provides the step identifier. If your plugin provides more than one step function, you need to specify this in your workflow.</li> <li><code>name</code> provides the human-readable name of the plugin step. This will help render a user interface for the workflow.</li> <li><code>description</code> is a longer description for the function and may contain line breaks.</li> <li><code>outputs</code> specifies the possible outputs and the dataclasses associated with these outputs. This is important so Arcaflow knows what to expect.</li> </ul> <p>Tip</p> <p>If you want, you can specify the function return type like this, but Arcaflow won\u2019t use it: <pre><code>def hello_world(params: InputParams) -&gt; typing.Tuple[str, ...]:\n</code></pre> Unfortunately, Python doesn\u2019t give us a good way to extract this information, so it\u2019s safe to skip.</p>"},{"location":"arcaflow/plugins/python/first/#step-4-running-the-plugin","title":"Step 4: Running the plugin","text":"<p>There is one more piece missing to run a plugin: the calling code. Add the following to your file:</p> plugin.py<pre><code>import sys\nfrom arcaflow_plugin_sdk import plugin\n\n\nif __name__ == \"__main__\":\n    sys.exit(\n        plugin.run(\n            plugin.build_schema(\n                # List your step functions here:\n                hello_world,\n            )\n        )\n    )\n</code></pre> <p>Now your plugin is ready. You can package it up for a workflow, or you can run it as a standalone tool from the command line:</p> <pre><code>python example_plugin.py -f input-data.yaml\n</code></pre> <p>You will need to provide the input data in YAML format:</p> input-data.yaml<pre><code>name: Arca Lot\n</code></pre> <p>Tip</p> <p>If your plugin provides more than one step function, you can specify the correct one to use with the <code>-s</code> parameter.</p> <p>Tip</p> <p>To prevent output from breaking the functionality when attached to the Arcaflow Engine, the SDK hides any output your step function writes to the standard output or standard error. You can use the <code>--debug</code> flag to show any output on the standard error in standalone mode.</p> <p>Tip</p> <p>You can generate a JSON schema file for your step input by running</p> <pre><code>python example_plugin.py --json-schema input &gt;example.schema.json\n</code></pre> <p>If you are using the YAML plugin for VSCode, add the following line to the top of your input file for code completion:     <pre><code># yaml-language-server: $schema=example.schema.json\n</code></pre></p>"},{"location":"arcaflow/plugins/python/first/#next-steps","title":"Next steps","text":"<p>In order to create an actually useful plugin, you will want to create a data model for your plugin. Once the data model is complete, you should look into packaging your plugin.</p>"},{"location":"arcaflow/plugins/python/official/","title":"Creating official Arcaflow plugins","text":"<p>Official Arcaflow plugins have more stringent requirements than normal. This document describes how to create a plugin that conforms to those requirements.</p>"},{"location":"arcaflow/plugins/python/official/#development-environment","title":"Development environment","text":"<p>Official Python plugins are standardized on Poetry and a Linux-based development environment. </p>"},{"location":"arcaflow/plugins/python/official/#installing-poetry","title":"Installing Poetry","text":"<p>First, please ensure your <code>python3</code> executable is at least version 3.9.</p> <pre><code>$ python3 --version\nPython 3.9.15\n</code></pre> How to install Python RHEL, CentOS, FedoraUbuntu <pre><code>$ dnf -y install python3.9\n</code></pre> <pre><code>$ apt-get -y install python3.9\n</code></pre> <p>Tip</p> <p>If the <code>python3</code> command doesn\u2019t work for you, but <code>python3.9</code> does, you can alias the command: <pre><code>$ alias python3=\"python3.9\"\n</code></pre></p> <p>Install Poetry using one of their supported methods for your environment.</p> <p>Warning</p> <p>Make sure to install Poetry into exactly one Python executable on your system. If something goes wrong with your package\u2019s Python virtual environment, you do not want to also spend time figuring out which Poetry executable is responsible for it.</p> <p>Now, verify your Poetry version.</p> <pre><code>$ poetry --version\nPoetry (version 1.2.2)\n</code></pre>"},{"location":"arcaflow/plugins/python/official/#setting-up-your-project","title":"Setting up your project","text":"<p>Create your plugin project, <code>plugin-project</code>, and change directory into the project root. You should see a directory structure similar to this with the following files.</p> <pre><code>$ poetry new plugin-project\nCreated package plugin_project in plugin-project\n\n$ tree plugin-project\nplugin-project\n\u251c\u2500\u2500 plugin_project\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 __init__.py\n\n2 directories, 4 files\n\n$ cd plugin-project\n</code></pre> <p>Ensure <code>python3</code> is at least 3.9.</p> <pre><code>$ python3 --version\nPython 3.9.15\n</code></pre> <p>Set Poetry to use your Python that is at least 3.9.</p> <pre><code>$ poetry env use $(which python3)\n</code></pre> <p>Check that your <code>pyproject.toml</code> is using at least Python 3.9 by looking for the following line.</p> pyproject.toml<pre><code>[tool.poetry.dependencies]\npython = \"^3.9\"\n</code></pre> <p>Add the arcaflow plugin sdk for python as a software dependency for your Python project.</p> <pre><code>$ poetry add arcaflow-plugin-sdk-python\n</code></pre> <p>You should now have a <code>poetry.lock</code> file in your project root. Poetry maintains the state of your <code>pyproject.toml</code>, and its exact software dependencies as hashes in the <code>poetry.lock</code> file.</p>"},{"location":"arcaflow/plugins/python/official/#building-a-container-image","title":"Building a container image","text":"<p>To build an official plugin container image we use the carpenter workflow on GitHub Actions. This workflow calls the Arcaflow image builder to build the image and perform all validations necessary.</p> <p>In order to successfully run the build, you should add the following files from the template repository:</p> <ul> <li><code>Dockerfile</code></li> <li><code>LICENSE</code></li> <li><code>.flake8</code></li> </ul> <p>Additionally, you need to add tests to your project, write a <code>README.md</code>, and make sure that the code directory matches your project name.</p>"},{"location":"arcaflow/plugins/python/official/#publishing-on-pypi","title":"Publishing on PyPI","text":"<p>Some plugins work well as libraries too. You can publish Arcaflow plugins on PyPI.</p> <p>To push an official package to PyPI, please contact an Arcalot chair to create an API token on PyPI and set up a CI environment. For testing purposes you can use TestPyPI.</p> <p>You can configure Poetry to use this API token by calling:</p> <pre><code>$ poetry config pypi-token.&lt;any name&gt; &lt;PYPI API TOKEN&gt;\n</code></pre> <p>Alternatively, you can also use environment variables:</p> <pre><code>$ export POETRY_PYPI_TOKEN_PYPI=my-token\n$ export POETRY_HTTP_BASIC_PYPI_USERNAME=&lt;username&gt;\n$ export POETRY_HTTP_BASIC_PYPI_PASSWORD=&lt;password&gt;\n</code></pre> <p>You can generate distribution archives by typing:</p> <pre><code>$ poetry build\n</code></pre> <p>You can then test publishing:</p> <pre><code>$ poetry publish --dry-run\n\nPublishing arcaflow-plugin-template-python (0.1.0) to PyPI\n- Uploading arcaflow_plugin_template_python-0.1.0-py3-none-any.whl 100%\n- Uploading arcaflow_plugin_template_python-0.1.0.tar.gz 100%\n</code></pre> <p>Remove the <code>--dry-run</code> to actually publish or call <code>poetry publish --build</code> to run it in one go.</p>"},{"location":"arcaflow/plugins/python/schema/","title":"Writing a Python plugin schema by hand","text":"<p>If you want to skip the automatic schema generation described in previous chapters, you can also create a schema by hand.</p> <p>Warning</p> <p>This process is complicated, requires providing redundant information and should be avoided if at all possible. We recommend creating a data model using dataclasses, decorators and annotations.</p> <p>We start by defining a schema:</p> <pre><code>from arcaflow_plugin_sdk import schema\nfrom typing import Dict\n\nsteps: Dict[str, schema.StepSchema]\n\ns = schema.Schema(\n    steps,\n)\n</code></pre> <p>The <code>steps</code> parameter here must be a dict, where the key is the step ID and the value is the step schema. So, let\u2019s create a step schema:</p> <pre><code>from arcaflow_plugin_sdk import schema\n\nstep_schema = schema.StepSchema(\n    id = \"pod\",\n    name = \"Pod scenario\",\n    description = \"Kills pods\",\n    input = input_schema,\n    outputs = outputs,\n    handler = my_handler_func\n)\n</code></pre> <p>Let\u2019s go in order:</p> <ul> <li>The <code>input</code> must be a schema of the type <code>schema.ObjectType</code>. This describes the single parameter that will be passed to <code>my_handler_func</code>.</li> <li>The <code>outputs</code> describe a <code>Dict[str, schema.ObjectType]</code>, where the key is the ID for the returned output type, while the value describes the output schema.</li> <li>The <code>handler</code> function takes one parameter, the object described in <code>input</code> and must return a tuple of a string and the output object. Here the ID uniquely identifies which output is intended, for example <code>success</code> and <code>error</code>, while  the second parameter in the tuple must match the <code>outputs</code> declaration.</li> </ul> <p>That\u2019s it! Now all that\u2019s left is to define the <code>ObjectType</code> and any subobjects.</p>"},{"location":"arcaflow/plugins/python/schema/#objecttype","title":"ObjectType","text":"<p>The ObjectType is intended as a backing type for dataclasses. For example:</p> <pre><code>t = schema.ObjectType(\n    TestClass,\n    {\n        \"a\": schema.Field(\n            type=schema.StringType(),\n            required=True,\n        ),\n        \"b\": schema.Field(\n            type=schema.IntType(),\n            required=True,\n        )\n    }\n)\n</code></pre> <p>The fields support the following parameters:</p> <ul> <li><code>type</code>: underlying type schema for the field (required)</li> <li><code>name</code>: name for the current field</li> <li><code>description</code>: description for the current field</li> <li><code>required</code>: marks the field as required</li> <li><code>required_if</code>: a list of other fields that, if filled, will also cause the current field to be required</li> <li><code>required_if_not</code>: a list of other fields that, if not set, will cause the current field to be required</li> <li><code>conflicts</code>: a list of other fields that cannot be set together with the current field</li> </ul>"},{"location":"arcaflow/plugins/python/schema/#scopetype-and-reftype","title":"ScopeType and RefType","text":"<p>Sometimes it is necessary to create circular references. This is where the <code>ScopeType</code> and the <code>RefType</code> comes into play. Scopes contain a list of objects that can be referenced by their ID, but one object is special: the root object of the scope. The RefType, on the other hand, is there to reference objects in a scope.</p> <p>Currently, the Python implementation passes the scope to the ref type directly, but the important rule is that ref types always reference their nearest scope up the tree. Do not create references that aim at scopes not directly above the ref!</p> <p>For example:</p> <pre><code>@dataclasses.dataclass\nclass OneOfData1:\n    a: str\n\n@dataclasses.dataclass\nclass OneOfData2:\n    b: OneOfData1\n\nscope = schema.ScopeType(\n    {\n        \"OneOfData1\": schema.ObjectType(\n            OneOfData1,\n            {\n                \"a\": schema.Field(\n                    schema.StringType()\n                )\n            }\n        ),\n    },\n    # Root object of scopes\n    \"OneOfData2\",\n)\n\nscope.objects[\"OneOfData2\"] = schema.ObjectType(\n    OneOfData2,\n    {\n        \"b\": schema.Field(\n            schema.RefType(\"OneOfData1\", scope)\n        )\n    }\n)\n</code></pre> <p>As you can see, this API is not easy to use and is likely to change in the future.</p>"},{"location":"arcaflow/plugins/python/schema/#oneoftype","title":"OneOfType","text":"<p>The OneOfType allows you to create a type that is a combination of other ObjectTypes. When a value is deserialized, a special discriminator field is consulted to figure out which type is actually being sent.</p> <p>This discriminator field may be present in the underlying type. If it is, the type must match the declaration in the AnyOfType.</p> <p>For example:</p> <pre><code>@dataclasses.dataclass\nclass OneOfData1:\n    type: str\n    a: str\n\n@dataclasses.dataclass\nclass OneOfData2:\n    b: int\n\nscope = schema.ScopeType(\n    {\n        \"OneOfData1\": schema.ObjectType(\n            OneOfData1,\n            {\n                # Here the discriminator field is also present in the underlying type\n                \"type\": schema.Field(\n                    schema.StringType(),\n                ),\n                \"a\": schema.Field(\n                    schema.StringType()\n                )\n            }\n        ),\n        \"OneOfData2\": schema.ObjectType(\n            OneOfData2,\n            {\n                \"b\": schema.Field(\n                    schema.IntType()\n                )\n            }\n        )\n    },\n    # Root object of scopes\n    \"OneOfData1\",\n)\n\ns = schema.OneOfStringType(\n    {\n        # Option 1\n        \"a\": schema.RefType(\n            # The RefType resolves against the scope.\n            \"OneOfData1\",\n            scope\n        ),\n        # Option 2\n        \"b\": schema.RefType(\n            \"OneOfData2\",\n            scope\n        ),\n    },\n    # Pass the scope this type belongs do\n    scope,\n    # Discriminator field\n    \"type\",\n)\n\nserialized_data = s.serialize(OneOfData1(\n    \"a\",\n    \"Hello world!\"\n))\npprint.pprint(serialized_data)\n</code></pre> <p>Note, that the OneOfTypes take all object-like elements, such as refs, objects, or scopes.</p>"},{"location":"arcaflow/plugins/python/schema/#stringtype","title":"StringType","text":"<p>String types indicate that the underlying type is a string.</p> <pre><code>t = schema.StringType()\n</code></pre> <p>The string type supports the following parameters:</p> <ul> <li><code>min_length</code>: minimum length for the string (inclusive)</li> <li><code>max_length</code>: maximum length for the string (inclusive)</li> <li><code>pattern</code>: regular expression the string must match</li> </ul>"},{"location":"arcaflow/plugins/python/schema/#patterntype","title":"PatternType","text":"<p>The pattern type indicates that the field must contain a regular expression. It will be decoded as <code>re.Pattern</code>.</p> <pre><code>t = schema.PatternType()\n</code></pre> <p>The pattern type has no parameters.</p>"},{"location":"arcaflow/plugins/python/schema/#inttype","title":"IntType","text":"<p>The int type indicates that the underlying type is an integer.</p> <pre><code>t = schema.IntType()\n</code></pre> <p>The int type supports the following parameters:</p> <ul> <li><code>min</code>: minimum value for the number (inclusive).</li> <li><code>max</code>: minimum value for the number (inclusive).</li> </ul>"},{"location":"arcaflow/plugins/python/schema/#floattype","title":"FloatType","text":"<p>The float type indicates that the underlying type is a floating point number.</p> <pre><code>t = schema.FloatType()\n</code></pre> <p>The float type supports the following parameters:</p> <ul> <li><code>min</code>: minimum value for the number (inclusive).</li> <li><code>max</code>: minimum value for the number (inclusive).</li> </ul>"},{"location":"arcaflow/plugins/python/schema/#booltype","title":"BoolType","text":"<p>The bool type indicates that the underlying value is a boolean. When unserializing, this type also supports string and integer values of <code>true</code>, <code>yes</code>, <code>on</code>, <code>enable</code>, <code>enabled</code>, <code>1</code>, <code>false</code>, <code>no</code>, <code>off</code>, <code>disable</code>, <code>disabled</code> or <code>0</code>.</p>"},{"location":"arcaflow/plugins/python/schema/#enumtype","title":"EnumType","text":"<p>The enum type creates a type from an existing enum:</p> <pre><code>class MyEnum(Enum):\n    A = \"a\"\n    B = \"b\"\n\nt = schema.EnumType(MyEnum)\n</code></pre> <p>The enum type has no further parameters.</p>"},{"location":"arcaflow/plugins/python/schema/#listtype","title":"ListType","text":"<p>The list type describes a list of items. The item type must be described:</p> <pre><code>t = schema.ListType(\n    schema.StringType()\n)\n</code></pre> <p>The list type supports the following extra parameters:</p> <ul> <li><code>min</code>: The minimum number of items in the list (inclusive)</li> <li><code>max</code>: The maximum number of items in the list (inclusive)</li> </ul>"},{"location":"arcaflow/plugins/python/schema/#maptype","title":"MapType","text":"<p>The map type describes a key-value type (dict). You must specify both the key and the value type:</p> <pre><code>t = schema.MapType(\n    schema.StringType(),\n    schema.StringType()\n)\n</code></pre> <p>The map type supports the following extra parameters:</p> <ul> <li><code>min</code>: The minimum number of items in the map (inclusive)</li> <li><code>max</code>: The maximum number of items in the map (inclusive)</li> </ul>"},{"location":"arcaflow/plugins/python/schema/#anytype","title":"AnyType","text":"<p>The \u201cany\u201d type allows any primitive type to pass through. However, this comes with severe limitations and the data cannot be validated, so its use is discouraged. You can create an <code>AnyType</code> by simply doing this:</p> <pre><code>t = schema.AnyType()\n</code></pre>"},{"location":"arcaflow/plugins/python/schema/#running-the-plugin","title":"Running the plugin","text":"<p>If you create the schema by hand, you can add the following code to your plugin:</p> <pre><code>if __name__ == \"__main__\":\n    sys.exit(plugin.run(your_schema))\n</code></pre> <p>You can then run your plugin as described in the writing your first plugin section.</p>"},{"location":"arcaflow/plugins/python/testing/","title":"Testing your Python plugin","text":"<p>When writing your first plugin, you will probably want to test it manually. However, as development progresses, you should switch to automated testing. Automated testing makes sure your plugins don\u2019t break when you introduce changes.</p> <p>This page describes the following test scenarios:</p> <ol> <li>Manual testing helps </li> <li>Serialization tests for your input and output to make sure your classes can be serialized for transport</li> <li>Functional tests that call your plugin and make sure it works correctly</li> </ol>"},{"location":"arcaflow/plugins/python/testing/#manual-testing","title":"Manual testing","text":"<p>Manual testing is easy: prepare a test input file in YAML format, then run the plugin as a command line tool. For example, the hello world plugin would take this input:</p> <pre><code>name: Arca Lot\n</code></pre> <p>You could then run the example plugin:</p> <pre><code>python example_plugin -f my-input-file.yaml\n</code></pre> <p>The plugin will run and present you with the output.</p> <p>Tip</p> <p>If you have more than one step, don\u2019t forget to pass the <code>-s step-id</code> parameter.</p> <p>Tip</p> <p>To prevent output from breaking the functionality when attached to the Arcaflow Engine, the SDK hides any output your step function writes to the standard output or standard error. You can use the <code>--debug</code> flag to show any output on the standard error in standalone mode.</p>"},{"location":"arcaflow/plugins/python/testing/#writing-a-serialization-test","title":"Writing a serialization test","text":"<p>You can use any test framework you like for your serialization test, we\u2019ll demonstrate with unittest as it is included directly in Python. The key to this test is to call <code>plugin.test_object_serialization()</code> with an instance of your dataclass that you want to test:</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_serialization(self):\n        self.assertTrue(plugin.test_object_serialization(\n            example_plugin.PodScenarioResults(\n                [\n                    example_plugin.Pod(\n                        namespace=\"default\",\n                        name=\"nginx-asdf\"\n                    )\n                ]\n            )\n        ))\n</code></pre> <p>Remember, you need to call this function with an instance containing actual data, not just the class name.</p> <p>The test function will first serialize, then unserialize your data and check if it\u2019s the same. If you want to use a manually created schema, you can do so, too:</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_serialization(self):\n        plugin.test_object_serialization(\n            example_plugin.PodScenarioResults(\n                #...\n            ),\n            schema.ObjectType(\n                #...\n            )\n        )\n</code></pre>"},{"location":"arcaflow/plugins/python/testing/#functional-tests","title":"Functional tests","text":"<p>Functional tests don\u2019t have anything special about them. You can directly call your code with your dataclasses as parameters, and check the return. This works best on auto-generated schemas with the <code>@plugin.step</code> decorator. See below for manually created schemas.</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_functional(self):\n        input = example_plugin.PodScenarioParams()\n\n        output_id, output_data = example_plugin.pod_scenario(input)\n\n        # Check if the output is always an error, as it is the case for the example plugin.\n        self.assertEqual(\"error\", output_id)\n        self.assertEqual(\n            output_data,\n            example_plugin.PodScenarioError(\n                \"Cannot kill pod .* in namespace .*, function not implemented\"\n            )\n        )\n</code></pre> <p>If you created your schema manually, the best way to write your tests is to include the schema in your test. This will automatically validate both the input and the output, making sure they conform to your schema. For example:</p> <pre><code>class ExamplePluginTest(unittest.TestCase):\n    def test_functional(self):\n        step_schema = schema.StepSchema(\n            #...\n            handler = example_plugin.pod_scenario,\n        )\n        input = example_plugin.PodScenarioParams()\n\n        output_id, output_data = step_schema(input)\n\n        # Check if the output is always an error, as it is the case for the example plugin.\n        self.assertEqual(\"error\", output_id)\n        self.assertEqual(\n            output_data,\n            example_plugin.PodScenarioError(\n                \"Cannot kill pod .* in namespace .*, function not implemented\"\n            )\n        )\n</code></pre>"},{"location":"arcaflow/running/","title":"Running Arcaflow","text":"<p>Running Arcaflow is simple! You will need three things:</p> <ol> <li>A local container engine (e.g. Docker or Podman)</li> <li>The Arcaflow Engine</li> <li>A workflow file (see the example workflows)</li> </ol> <p>Please start by setting up Arcaflow.</p>"},{"location":"arcaflow/running/running/","title":"Running Arcaflow","text":"<p>Before you proceed, you will need to perform the following steps:</p> <ol> <li>Download and configure Arcaflow</li> <li>Create a YAML file with your workflow input data (e.g. `input.yaml)</li> </ol> Linux/MacOSWindows <pre><code>/path/to/arcaflow -input path/to/input.yaml\n</code></pre> <pre><code>c:\\path\\to\\arcaflow.exe -input path/to/input.yaml\n</code></pre> <p>You can pass the following additional options to Arcaflow:</p> Option Description <code>-config /path/to/config.yaml</code> Set an Arcaflow configuration file. (See the configuration guide.) <code>-context /path/to/workflow/dir</code> Set a different workflow directory. (Defaults to the current directory.) <code>-workflow workflow.yaml</code> Set a different workflow file. (Defaults to <code>workflow.yaml</code>.)"},{"location":"arcaflow/running/running/#execution","title":"Execution","text":"<p>Once you start Arcaflow, it will perform the following three phases:</p> <ol> <li>It will start all plugins using your local deployer (see the configuration guide), load their schemas, and then stop the plugins.</li> </ol> <p>Note</p> <p>The loading phase only reads the plugin schemas; it does not run any of the functional steps of the plugins.</p> <ol> <li>It will execute the workflow.</li> <li>Once the workflow execution is complete, it will output the resulting data.</li> </ol> <p>Tip</p> <p>You can redirect the standard output to capture the output data and still read the log messages on the standard error.</p>"},{"location":"arcaflow/running/setup/","title":"Setting up Arcaflow","text":"<p>In order to use Arcaflow, you will need to download the Arcaflow Engine. You can simply unpack and run it, no need for installing it.</p> <p>On Linux and MacOS, you may need to run <code>chmod +x</code> on the engine binary.</p>"},{"location":"arcaflow/running/setup/#configuration","title":"Configuration","text":"<p>If you are using Docker as the local deployer (see below), you generally do not need to perform any extra configuration.</p> <p>If you wish to customize Arcaflow, you can pass a YAML configuration file to Arcaflow with the <code>-config your-arcaflow-config.yaml</code> parameter.</p>"},{"location":"arcaflow/running/setup/#local-deployer","title":"Local deployer","text":"<p>The Arcaflow Engine needs a local container deployer to temporarily run plugins and read their schema. We recommend either Docker (default) or Podman for this purpose. You can use a Kubernetes cluster for this purpose too, but a local container engine is the better choice for performance reasons.</p> <p>You can then change the deployer type like this:</p> config.yaml<pre><code>deployer:\n  type: podman\n  # Deployer-specific options \n</code></pre> DockerPodmanKubernetes <p>Docker is the default local deployer. You can configure it like this:</p> config.yaml<pre><code>deployer:\n  type: docker\n  connection:\n    # Change this to point to a TCP-based Docker socket\n    host: host-to-docker \n    # Add a certificates here. This is usually needed in TCP mode.\n    cacert: |\n      Add your CA cert PEM here\n    cert: |\n      Add your client cert PEM here.\n    key: |\n      Add your client key PEM here.\n  deployment:\n    # For more options here see: https://docs.docker.com/engine/api/v1.42/#tag/Container/operation/ContainerCreate\n    container:\n      # Add your container config here.\n    host:\n      # Add your host config here.\n    network:\n      # Add your network config here\n    platform:\n      # Add your platform config here\n    imagePullPolicy: Always|IfNotPresent|Never\n  timeouts:\n    # HTTP timeout\n    http: 5s\n</code></pre> All options for the Docker deployer Type: <code>scope</code> Root object: Config Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) Objects Config (<code>object</code>) Type: <code>object</code> Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) Connection (<code>object</code>) Type: <code>object</code> Properties cacert (<code>string</code>) Name: CA certificate Description: CA certificate in PEM format to verify the Dockerd server certificate against. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> cert (<code>string</code>) Name: Client certificate Description: Client certificate in PEM format to authenticate against the Dockerd with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> host (<code>string</code>) Name: Host Description: Host name for Dockerd. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z0-9./:_-]&amp;#43;$</code> Default<pre><code>\"npipe:////./pipe/docker_engine\"\n</code></pre> Examples <pre><code>'unix:///var/run/docker.sock'\n</code></pre> <p>\u201d     <pre><code>'npipe:////./pipe/docker_engine'\n</code></pre></p> key (<code>string</code>) Name: Client key Description: Client private key in PEM format to authenticate against the Dockerd with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN ([A-Z]&amp;#43;) PRIVATE KEY-----(\\s*.*\\s*)*-----END ([A-Z]&amp;#43;) PRIVATE KEY-----\\s*$</code> Examples <pre><code>\"-----BEGIN PRIVATE KEY-----\\nMIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEArr89f2kggSO/yaCB\\n6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1nEiPnLbzDDgMU8KCPAMhI7JpYRlH\\nnipxWwIDAQABAkBybu/x0MElcGi2u/J2UdwScsV7je5Tt12z82l7TJmZFFJ8RLmc\\nrh00Gveb4VpGhd1+c3lZbO1mIT6v3vHM9A0hAiEA14EW6b+99XYza7+5uwIDuiM+\\nBz3pkK+9tlfVXE7JyKsCIQDPlYJ5xtbuT+VvB3XOdD/VWiEqEmvE3flV0417Rqha\\nEQIgbyxwNpwtEgEtW8untBrA83iU2kWNRY/z7ap4LkuS+0sCIGe2E+0RmfqQsllp\\nicMvM2E92YnykCNYn6TwwCQSJjRxAiEAo9MmaVlK7YdhSMPo52uJYzd9MQZJqhq+\\nlB1ZGDx/ARE=\\n-----END PRIVATE KEY-----\\n\"\n</code></pre> ContainerConfig (<code>object</code>) Type: <code>object</code> Properties Domainname (<code>string</code>) Name: Domain name Description: Domain name for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> Env (<code>map[string, string]</code>) Name: Environment variables Description: Environment variables to set on the plugin container. Required: No Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[A-Z0-9_]&amp;#43;$</code> Value type Type: <code>string</code> Maximum: 32760 Hostname (<code>string</code>) Name: Hostname Description: Hostname for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> MacAddress (<code>string</code>) Name: MAC address Description: Media Access Control address for the container. Required: No Must match pattern: <code>^[a-fA-F0-9]{2}(:[a-fA-F0-9]{2}){5}$</code> NetworkDisabled (<code>bool</code>) Name: Disable network Description: Disable container networking completely. Required: No User (<code>string</code>) Name: Username Description: User that will run the command inside the container. Optionally, a group can be specified in the user:group format. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z_][a-z0-9_-]*[$]?(:[a-z_][a-z0-9_-]*[$]?)$</code> Deployment (<code>object</code>) Type: <code>object</code> Properties container (<code>reference[ContainerConfig]</code>) Name: Container configuration Description: Provides information about the container for the plugin. Required: No Referenced object: ContainerConfig (see in the Objects section below) host (<code>reference[HostConfig]</code>) Name: Host configuration Description: Provides information about the container host for the plugin. Required: No Referenced object: HostConfig (see in the Objects section below) imagePullPolicy (<code>enum[string]</code>) Name: Image pull policy Description: When to pull the plugin image. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> network (<code>reference[NetworkConfig]</code>) Name: Network configuration Description: Provides information about the container networking for the plugin. Required: No Referenced object: NetworkConfig (see in the Objects section below) platform (<code>reference[PlatformConfig]</code>) Name: Platform configuration Description: Provides information about the container host platform for the plugin. Required: No Referenced object: PlatformConfig (see in the Objects section below) HostConfig (<code>object</code>) Type: <code>object</code> Properties CapAdd (<code>list[string]</code>) Name: Add capabilities Description: Add capabilities to the container. Required: No List Items Type: <code>string</code> CapDrop (<code>list[string]</code>) Name: Drop capabilities Description: Drop capabilities from the container. Required: No List Items Type: <code>string</code> CgroupnsMode (<code>enum[string]</code>) Name: CGroup namespace mode Description: CGroup namespace mode to use for the container. Required: No Values <ul> <li>`` Empty</li> <li><code>host</code> Host</li> <li><code>private</code> Private</li> </ul> Dns (<code>list[string]</code>) Name: DNS servers Description: DNS servers to use for lookup. Required: No List Items Type: <code>string</code> DnsOptions (<code>list[string]</code>) Name: DNS options Description: DNS options to look for. Required: No List Items Type: <code>string</code> DnsSearch (<code>list[string]</code>) Name: DNS search Description: DNS search domain. Required: No List Items Type: <code>string</code> ExtraHosts (<code>list[string]</code>) Name: Extra hosts Description: Extra hosts entries to add Required: No List Items Type: <code>string</code> NetworkMode (<code>string</code>) Name: Network mode Description: Specifies either the network mode, the container network to attach to, or a name of a Docker network to use. Required: No Must match pattern: <code>^(none|bridge|host|container:[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;|[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;)$</code> Examples <pre><code>\"none\"\n</code></pre> <p>\u201d     <pre><code>\"bridge\"\n</code></pre> \u201d     <pre><code>\"host\"\n</code></pre> \u201d     <pre><code>\"container:container-name\"\n</code></pre> \u201d     <pre><code>\"network-name\"\n</code></pre></p> PortBindings (<code>map[string, list[reference[PortBinding]]]</code>) Name: Port bindings Description: Ports to expose on the host machine. Ports are specified in the format of portnumber/protocol. Required: No Key type Type: <code>string</code> Must match pattern: <code>^[0-9]&amp;#43;(/[a-zA-Z0-9]&amp;#43;)$</code> Value type Type: <code>list[reference[PortBinding]]</code> List Items Type: <code>reference[PortBinding]</code> Referenced object: PortBinding (see in the Objects section below) NetworkConfig (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PlatformConfig (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PortBinding (<code>object</code>) Type: <code>object</code> Properties HostIP (<code>string</code>) Name: Host IP Required: No HostPort (<code>string</code>) Name: Host port Required: No Must match pattern: <code>^0-9&amp;#43;$</code> Timeouts (<code>object</code>) Type: <code>object</code> Properties http (<code>int</code>) Name: HTTP Description: HTTP timeout for the Docker API. Required: No Minimum: 100000000 Units: nanoseconds Default<pre><code>\"15s\"\n</code></pre> <p>If you want to use Podman as your local deployer instead of Docker, you can do so like this:</p> config.yaml<pre><code>deployer:\n  type: podman\n  podman:\n    # Change where Podman is. (You can use this to point to a shell script\n    path: /path/to/your/podman\n    # Change the network mode\n    networkMode: host\n  deployment:\n    # For more options here see: https://docs.docker.com/engine/api/v1.42/#tag/Container/operation/ContainerCreate\n    container:\n      # Add your container config here.\n    host:\n      # Add your host config here.\n    imagePullPolicy: Always|IfNotPresent|Never\n  timeouts:\n    # HTTP timeout\n    http: 5s\n</code></pre> All options for the Podman deployer Type: <code>scope</code> Root object: Config Properties deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) podman (<code>reference[Podman]</code>) Name: Podman Description: Podman CLI configuration Required: No Referenced object: Podman (see in the Objects section below) Objects Config (<code>object</code>) Type: <code>object</code> Properties deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) podman (<code>reference[Podman]</code>) Name: Podman Description: Podman CLI configuration Required: No Referenced object: Podman (see in the Objects section below) ContainerConfig (<code>object</code>) Type: <code>object</code> Properties Domainname (<code>string</code>) Name: Domain name Description: Domain name for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> Env (<code>list[string]</code>) Name: Environment variables Description: Environment variables to set on the plugin container. Required: No List Items Type: <code>string</code> Minimum: 1 Maximum: 32760 Must match pattern: <code>^.&amp;#43;=.&amp;#43;$</code> Hostname (<code>string</code>) Name: Hostname Description: Hostname for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> MacAddress (<code>string</code>) Name: MAC address Description: Media Access Control address for the container. Required: No Must match pattern: <code>^[a-fA-F0-9]{2}(:[a-fA-F0-9]{2}){5}$</code> NetworkDisabled (<code>bool</code>) Name: Disable network Description: Disable container networking completely. Required: No User (<code>string</code>) Name: Username Description: User that will run the command inside the container. Optionally, a group can be specified in the user:group format. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z_][a-z0-9_-]*[$]?(:[a-z_][a-z0-9_-]*[$]?)$</code> Deployment (<code>object</code>) Type: <code>object</code> Properties container (<code>reference[ContainerConfig]</code>) Name: Container configuration Description: Provides information about the container for the plugin. Required: No Referenced object: ContainerConfig (see in the Objects section below) host (<code>reference[HostConfig]</code>) Name: Host configuration Description: Provides information about the container host for the plugin. Required: No Referenced object: HostConfig (see in the Objects section below) imagePullPolicy (<code>enum[string]</code>) Name: Image pull policy Description: When to pull the plugin image. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> HostConfig (<code>object</code>) Type: <code>object</code> Properties Binds (<code>list[string]</code>) Name: Volume Bindings Description: Volumes Required: No List Items Type: <code>string</code> Minimum: 1 Maximum: 32760 Must match pattern: <code>^.&amp;#43;:.&amp;#43;$</code> CapAdd (<code>list[string]</code>) Name: Add capabilities Description: Add capabilities to the container. Required: No List Items Type: <code>string</code> CapDrop (<code>list[string]</code>) Name: Drop capabilities Description: Drop capabilities from the container. Required: No List Items Type: <code>string</code> CgroupnsMode (<code>enum[string]</code>) Name: CGroup namespace mode Description: CGroup namespace mode to use for the container. Required: No Values <ul> <li>`` Empty</li> <li><code>host</code> Host</li> <li><code>private</code> Private</li> </ul> Dns (<code>list[string]</code>) Name: DNS servers Description: DNS servers to use for lookup. Required: No List Items Type: <code>string</code> DnsOptions (<code>list[string]</code>) Name: DNS options Description: DNS options to look for. Required: No List Items Type: <code>string</code> DnsSearch (<code>list[string]</code>) Name: DNS search Description: DNS search domain. Required: No List Items Type: <code>string</code> ExtraHosts (<code>list[string]</code>) Name: Extra hosts Description: Extra hosts entries to add Required: No List Items Type: <code>string</code> NetworkMode (<code>string</code>) Name: Network mode Description: Specifies either the network mode, the container network to attach to, or a name of a Docker network to use. Required: No Must match pattern: <code>^(none|bridge|host|container:[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;|[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;)$</code> Examples <pre><code>\"none\"\n</code></pre> <p>\u201d     <pre><code>\"bridge\"\n</code></pre> \u201d     <pre><code>\"host\"\n</code></pre> \u201d     <pre><code>\"container:container-name\"\n</code></pre> \u201d     <pre><code>\"network-name\"\n</code></pre></p> PortBindings (<code>map[string, list[reference[PortBinding]]]</code>) Name: Port bindings Description: Ports to expose on the host machine. Ports are specified in the format of portnumber/protocol. Required: No Key type Type: <code>string</code> Must match pattern: <code>^[0-9]&amp;#43;(/[a-zA-Z0-9]&amp;#43;)$</code> Value type Type: <code>list[reference[PortBinding]]</code> List Items Type: <code>reference[PortBinding]</code> Referenced object: PortBinding (see in the Objects section below) Podman (<code>object</code>) Type: <code>object</code> Properties cgroupNs (<code>string</code>) Name: CGroup namespace Description: Provides the Cgroup Namespace settings for the container Required: No Must match pattern: <code>^host|ns:/proc/\\d&amp;#43;/ns/cgroup|container:.&amp;#43;|private$</code> containerName (<code>string</code>) Name: Container Name Description: Provides name of the container Required: No Must match pattern: <code>^.*$</code> imageArchitecture (<code>string</code>) Name: Podman image Architecture Description: Provides Podman Image Architecture Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"amd64\"\n</code></pre> imageOS (<code>string</code>) Name: Podman Image OS Description: Provides Podman Image Operating System Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"linux\"\n</code></pre> networkMode (<code>string</code>) Name: Network Mode Description: Provides network settings for the container Required: No Must match pattern: <code>^bridge:.*|host|none$</code> path (<code>string</code>) Name: Podman path Description: Provides the path of podman executable Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"podman\"\n</code></pre> PortBinding (<code>object</code>) Type: <code>object</code> Properties HostIP (<code>string</code>) Name: Host IP Required: No HostPort (<code>string</code>) Name: Host port Required: No Must match pattern: <code>^0-9&amp;#43;$</code> <p>Kubernetes can be used as the \u201clocal\u201d deployer, but this is typically not recommended for performance reasons. You can set up the Kubernetes deployer like this:</p> config.yaml<pre><code>deployer:\n  type: kubernetes\n  connection:\n    host: localhost:6443\n    cert: |\n      Add your client cert in PEM format here.\n    key: |\n      Add your client key in PEM format here.\n    cacert: |\n      Add the server CA cert in PEM format here.\n</code></pre> All options for the Kubernetes deployer Type: <code>scope</code> Root object: Config Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) pod (<code>reference[Pod]</code>) Name: Pod Description: Pod configuration for the plugin. Required: No Referenced object: Pod (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) Objects AWSElasticBlockStoreVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> AzureDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> AzureFileVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CSIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CephFSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CinderVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Config (<code>object</code>) Type: <code>object</code> Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) pod (<code>reference[Pod]</code>) Name: Pod Description: Pod configuration for the plugin. Required: No Referenced object: Pod (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) ConfigMapVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Connection (<code>object</code>) Type: <code>object</code> Properties bearerToken (<code>string</code>) Name: Bearer token Description: Bearer token to authenticate against the Kubernetes API with. Required: No burst (<code>int</code>) Name: Burst Description: Burst value for query throttling. Required: No Minimum: 0 Default<pre><code>10\n</code></pre> cacert (<code>string</code>) Name: CA certificate Description: CA certificate in PEM format to verify Kubernetes server certificate against. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> cert (<code>string</code>) Name: Client certificate Description: Client certificate in PEM format to authenticate against Kubernetes with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> host (<code>string</code>) Name: Host Description: Host name and port of the Kubernetes server Required: No Default<pre><code>\"kubernetes.default.svc\"\n</code></pre> key (<code>string</code>) Name: Client key Description: Client private key in PEM format to authenticate against Kubernetes with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN ([A-Z]&amp;#43;) PRIVATE KEY-----(\\s*.*\\s*)*-----END ([A-Z]&amp;#43;) PRIVATE KEY-----\\s*$</code> Examples <pre><code>\"-----BEGIN PRIVATE KEY-----\\nMIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEArr89f2kggSO/yaCB\\n6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1nEiPnLbzDDgMU8KCPAMhI7JpYRlH\\nnipxWwIDAQABAkBybu/x0MElcGi2u/J2UdwScsV7je5Tt12z82l7TJmZFFJ8RLmc\\nrh00Gveb4VpGhd1+c3lZbO1mIT6v3vHM9A0hAiEA14EW6b+99XYza7+5uwIDuiM+\\nBz3pkK+9tlfVXE7JyKsCIQDPlYJ5xtbuT+VvB3XOdD/VWiEqEmvE3flV0417Rqha\\nEQIgbyxwNpwtEgEtW8untBrA83iU2kWNRY/z7ap4LkuS+0sCIGe2E+0RmfqQsllp\\nicMvM2E92YnykCNYn6TwwCQSJjRxAiEAo9MmaVlK7YdhSMPo52uJYzd9MQZJqhq+\\nlB1ZGDx/ARE=\\n-----END PRIVATE KEY-----\\n\"\n</code></pre> password (<code>string</code>) Name: Password Description: Password for basic authentication. Required: No path (<code>string</code>) Name: Path Description: Path to the API server. Required: No Default<pre><code>\"/api\"\n</code></pre> qps (<code>float</code>) Name: QPS Description: Queries Per Second allowed against the API. Required: No Minimum: 0 Units: queries Default<pre><code>5.0\n</code></pre> serverName (<code>string</code>) Name: TLS server name Description: Expected TLS server name to verify in the certificate. Required: No username (<code>string</code>) Name: Username Description: Username for basic authentication. Required: No Container (<code>object</code>) Type: <code>object</code> Properties args (<code>list[string]</code>) Name: Arguments Description: Arguments to the entypoint (command). Required: No List Items Type: <code>string</code> command (<code>list[string]</code>) Name: Command Description: Override container entry point. Not executed with a shell. Required: No Minimum items: 1 List Items Type: <code>string</code> env (<code>list[object]</code>) Name: Environment Description: Environment variables for this container. Required: No List Items Type: <code>object</code> Properties name (<code>string</code>) Name: Name Description: Environment variables name. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> value (<code>string</code>) Name: Value Description: Value for the environment variable. Required: No valueFrom (<code>reference[EnvFromSource]</code>) Name: Value source Description: Load the environment variable from a secret or config map. Required: No Referenced object: EnvFromSource (see in the Objects section below) envFrom (<code>list[reference[EnvFromSource]]</code>) Name: Environment sources Description: List of sources to populate the environment variables from. Required: No List Items Type: <code>reference[EnvFromSource]</code> Referenced object: EnvFromSource (see in the Objects section below) image (<code>string</code>) Name: Image Description: Container image to use for this container. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9_\\-:./]&amp;#43;$</code> imagePullPolicy (<code>enum[string]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> name (<code>string</code>) Name: Name Description: Name for the container. Each container in a pod must have a unique name. Required: Yes Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> securityContext (<code>object</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Properties capabilities (<code>object</code>) Name: Capabilities Description: Add or drop POSIX capabilities. Required: No Properties add (<code>list[string]</code>) Name: Add Description: Add POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> drop (<code>list[string]</code>) Name: Drop Description: Drop POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> privileged (<code>bool</code>) Name: Privileged Description: Run the container in privileged mode. Required: No volumeDevices (<code>list[object]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No List Items Type: <code>object</code> Properties devicePath (<code>string</code>) Name: Device path Description: Path inside the container the device will be mapped to. Required: Yes Minimum: 1 name (<code>string</code>) Name: Name Description: Must match the persistent volume claim in the pod. Required: Yes Minimum: 1 volumeMounts (<code>list[object]</code>) Name: Volume mounts Description: Pod volumes to mount on this container. Required: No List Items Type: <code>object</code> Properties mountPath (<code>string</code>) Name: Mount path Description: Path to mount the volume on inside the container. Required: Yes Minimum: 1 name (<code>string</code>) Name: Volume name Description: Must match the pod volume to mount. Required: Yes Minimum: 1 readOnly (<code>bool</code>) Name: Read only Description: Mount volume as read-only. Required: No Default<pre><code>false\n</code></pre> subPath (<code>string</code>) Name: Subpath Description: Path from the volume to mount. Required: No Minimum: 1 workingDir (<code>string</code>) Name: Working directory Description: Override the container working directory. Required: No DownwardAPIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> EmptyDirVolumeSource (<code>object</code>) Type: <code>object</code> Properties medium (<code>string</code>) Name: Medium Description: How to store the empty directory Required: No Minimum: 1 Must match pattern: <code>^(|Memory|HugePages|HugePages-.*)$</code> EnvFromSource (<code>object</code>) Type: <code>object</code> Properties configMapRef (<code>object</code>) Name: Config map source Description: Populates the source from a config map. Required: No Properties name (<code>string</code>) Name: Name Description: Name of the referenced config map. Required: Yes Minimum: 1 optional (<code>bool</code>) Name: Optional Description: Specify whether the config map must be defined. Required: No prefix (<code>string</code>) Name: Prefix Description: An optional identifier to prepend to each key in the ConfigMap. Required: No Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> secretRef (<code>object</code>) Name: Secret source Description: Populates the source from a secret. Required: No Properties name (<code>string</code>) Name: Name Description: Name of the referenced secret. Required: Yes Minimum: 1 optional (<code>bool</code>) Name: Optional Description: Specify whether the secret must be defined. Required: No EphemeralVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FCVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FlexVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FlockerVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> GCEPersistentDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> GlusterfsVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> HostPathVolumeSource (<code>object</code>) Type: <code>object</code> Properties path (<code>string</code>) Name: Path Description: Path to the directory on the host. Required: Yes Minimum: 1 Examples <pre><code>\"/srv/volume1\"\n</code></pre> type (<code>enum[string]</code>) Name: Type Description: Type of the host path. Required: No Values <ul> <li>`` Unset</li> <li><code>BlockDevice</code> Block device</li> <li><code>CharDevice</code> Character device</li> <li><code>Directory</code> Directory</li> <li><code>DirectoryOrCreate</code> Create directory if not found</li> <li><code>File</code> File</li> <li><code>FileOrCreate</code> Create file if not found</li> <li><code>Socket</code> Socket</li> </ul> ISCSIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> NFSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ObjectMeta (<code>object</code>) Type: <code>object</code> Properties annotations (<code>map[string, string]</code>) Name: Annotations Description: Kubernetes annotations to appy. See https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/ for details. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> generateName (<code>string</code>) Name: Name prefix Description: Name prefix to generate pod names from. Required: No labels (<code>map[string, string]</code>) Name: Labels Description: Kubernetes labels to appy. See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ for details. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> name (<code>string</code>) Name: Name Description: Pod name. Required: No namespace (<code>string</code>) Name: Namespace Description: Kubernetes namespace to deploy in. Required: No Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> Default<pre><code>\"default\"\n</code></pre> PersistentVolumeClaimVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PhotonPersistentDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Pod (<code>object</code>) Type: <code>object</code> Properties metadata (<code>reference[ObjectMeta]</code>) Name: Metadata Description: Pod metadata. Required: No Referenced object: ObjectMeta (see in the Objects section below) spec (<code>reference[PodSpec]</code>) Name: Specification Description: Pod specification. Required: No Referenced object: PodSpec (see in the Objects section below) PodSpec (<code>object</code>) Type: <code>object</code> Properties affinity (<code>object</code>) Name: Affinity rules Description: Affinity rules. Required: No Properties podAffinity (<code>object</code>) Name: Pod Affinity Description: The pod affinity rules. Required: No Properties requiredDuringSchedulingIgnoredDuringExecution (<code>list[object]</code>) Name: Required During Scheduling Ignored During Execution Description: Hard pod affinity rules. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties labelSelector (<code>object</code>) Name: MatchExpressions Description: Expressions for the label selector. Required: No Properties matchExpressions (<code>list[object]</code>) Name: MatchExpression Description: Expression for the label selector. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties key (<code>string</code>) Name: Key Description: Key for the label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> operator (<code>string</code>) Name: Operator Description: Logical operator for Kubernetes to use when interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt. Required: No Maximum: 253 Must match pattern: <code>In|NotIn|Exists|DoesNotExist|Gt|Lt</code> values (<code>list[string]</code>) Name: Values Description: Values for the label that the system uses to denote the domain. Required: No Minimum items: 1 List Items Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> topologyKey (<code>string</code>) Name: TopologyKey Description: Key for the node label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_./][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> podAntiAffinity (<code>object</code>) Name: Pod Affinity Description: The pod affinity rules. Required: No Properties requiredDuringSchedulingIgnoredDuringExecution (<code>list[object]</code>) Name: Required During Scheduling Ignored During Execution Description: Hard pod affinity rules. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties labelSelector (<code>object</code>) Name: MatchExpressions Description: Expressions for the label selector. Required: No Properties matchExpressions (<code>list[object]</code>) Name: MatchExpression Description: Expression for the label selector. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties key (<code>string</code>) Name: Key Description: Key for the label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> operator (<code>string</code>) Name: Operator Description: Logical operator for Kubernetes to use when interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt. Required: No Maximum: 253 Must match pattern: <code>In|NotIn|Exists|DoesNotExist|Gt|Lt</code> values (<code>list[string]</code>) Name: Values Description: Values for the label that the system uses to denote the domain. Required: No Minimum items: 1 List Items Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> topologyKey (<code>string</code>) Name: TopologyKey Description: Key for the node label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_./][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> containers (<code>list[reference[Container]]</code>) Name: Containers Description: A list of containers belonging to the pod. Required: No List Items Type: <code>reference[Container]</code> Referenced object: Container (see in the Objects section below) initContainers (<code>list[reference[Container]]</code>) Name: Init containers Description: A list of initialization containers belonging to the pod. Required: No List Items Type: <code>reference[Container]</code> Referenced object: Container (see in the Objects section below) nodeSelector (<code>map[string, string]</code>) Name: Labels Description: Node labels you want the target node to have. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> pluginContainer (<code>object</code>) Name: Plugin container Description: The container to run the plugin in. Required: Yes Properties env (<code>list[object]</code>) Name: Environment Description: Environment variables for this container. Required: No List Items Type: <code>object</code> Properties name (<code>string</code>) Name: Name Description: Environment variables name. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> value (<code>string</code>) Name: Value Description: Value for the environment variable. Required: No valueFrom (<code>reference[EnvFromSource]</code>) Name: Value source Description: Load the environment variable from a secret or config map. Required: No Referenced object: EnvFromSource (see in the Objects section below) envFrom (<code>list[reference[EnvFromSource]]</code>) Name: Environment sources Description: List of sources to populate the environment variables from. Required: No List Items Type: <code>reference[EnvFromSource]</code> Referenced object: EnvFromSource (see in the Objects section below) imagePullPolicy (<code>enum[string]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> name (<code>string</code>) Name: Name Description: Name for the container. Each container in a pod must have a unique name. Required: No Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> Default<pre><code>\"arcaflow-plugin-container\"\n</code></pre> securityContext (<code>object</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Properties capabilities (<code>object</code>) Name: Capabilities Description: Add or drop POSIX capabilities. Required: No Properties add (<code>list[string]</code>) Name: Add Description: Add POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> drop (<code>list[string]</code>) Name: Drop Description: Drop POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> privileged (<code>bool</code>) Name: Privileged Description: Run the container in privileged mode. Required: No volumeDevices (<code>list[object]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No List Items Type: <code>object</code> Properties devicePath (<code>string</code>) Name: Device path Description: Path inside the container the device will be mapped to. Required: Yes Minimum: 1 name (<code>string</code>) Name: Name Description: Must match the persistent volume claim in the pod. Required: Yes Minimum: 1 volumeMounts (<code>list[object]</code>) Name: Volume mounts Description: Pod volumes to mount on this container. Required: No List Items Type: <code>object</code> Properties mountPath (<code>string</code>) Name: Mount path Description: Path to mount the volume on inside the container. Required: Yes Minimum: 1 name (<code>string</code>) Name: Volume name Description: Must match the pod volume to mount. Required: Yes Minimum: 1 readOnly (<code>bool</code>) Name: Read only Description: Mount volume as read-only. Required: No Default<pre><code>false\n</code></pre> subPath (<code>string</code>) Name: Subpath Description: Path from the volume to mount. Required: No Minimum: 1 volumes (<code>list[reference[Volume]]</code>) Name: Volumes Description: A list of volumes that can be mounted by containers belonging to the pod. Required: No List Items Type: <code>reference[Volume]</code> Referenced object: Volume (see in the Objects section below) PortworxVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ProjectedVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> QuobyteVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> RBDVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ScaleIOVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> SecretVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> StorageOSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Timeouts (<code>object</code>) Type: <code>object</code> Properties http (<code>int</code>) Name: HTTP Description: HTTP timeout for the Docker API. Required: No Minimum: 100000000 Units: nanoseconds Default<pre><code>\"15s\"\n</code></pre> Volume (<code>object</code>) Type: <code>object</code> Properties awsElasticBlockStore (<code>reference[AWSElasticBlockStoreVolumeSource]</code>) Name: AWS EBS Description: AWS Elastic Block Storage. Required: No Referenced object: AWSElasticBlockStoreVolumeSource (see in the Objects section below) azureDisk (<code>reference[AzureDiskVolumeSource]</code>) Name: Azure Data Disk Description: Mount an Azure Data Disk as a volume. Required: No Referenced object: AzureDiskVolumeSource (see in the Objects section below) azureFile (<code>reference[AzureFileVolumeSource]</code>) Name: Azure File Description: Mount an Azure File Service mount. Required: No Referenced object: AzureFileVolumeSource (see in the Objects section below) cephfs (<code>reference[CephFSVolumeSource]</code>) Name: CephFS Description: Mount a CephFS volume. Required: No Referenced object: CephFSVolumeSource (see in the Objects section below) cinder (<code>reference[CinderVolumeSource]</code>) Name: Cinder Description: Mount a cinder volume attached and mounted on the host machine. Required: No Referenced object: CinderVolumeSource (see in the Objects section below) configMap (<code>reference[ConfigMapVolumeSource]</code>) Name: ConfigMap Description: Mount a ConfigMap as a volume. Required: No Referenced object: ConfigMapVolumeSource (see in the Objects section below) csi (<code>reference[CSIVolumeSource]</code>) Name: CSI Volume Description: Mount a volume using a CSI driver. Required: No Referenced object: CSIVolumeSource (see in the Objects section below) downwardAPI (<code>reference[DownwardAPIVolumeSource]</code>) Name: Downward API Description: Specify a volume that the pod should mount itself. Required: No Referenced object: DownwardAPIVolumeSource (see in the Objects section below) emptyDir (<code>reference[EmptyDirVolumeSource]</code>) Name: Empty directory Description: Temporary empty directory. Required: No Referenced object: EmptyDirVolumeSource (see in the Objects section below) ephemeral (<code>reference[EphemeralVolumeSource]</code>) Name: Ephemeral Description: Mount a volume that is handled by a cluster storage driver. Required: No Referenced object: EphemeralVolumeSource (see in the Objects section below) fc (<code>reference[FCVolumeSource]</code>) Name: Fibre Channel Description: Mount a Fibre Channel volume that's attached to the host machine. Required: No Referenced object: FCVolumeSource (see in the Objects section below) flexVolume (<code>reference[FlexVolumeSource]</code>) Name: Flex Description: Mount a generic volume provisioned/attached using an exec based plugin. Required: No Referenced object: FlexVolumeSource (see in the Objects section below) flocker (<code>reference[FlockerVolumeSource]</code>) Name: Flocker Description: Mount a Flocker volume. Required: No Referenced object: FlockerVolumeSource (see in the Objects section below) gcePersistentDisk (<code>reference[GCEPersistentDiskVolumeSource]</code>) Name: GCE disk Description: Google Cloud disk. Required: No Referenced object: GCEPersistentDiskVolumeSource (see in the Objects section below) glusterfs (<code>reference[GlusterfsVolumeSource]</code>) Name: GlusterFS Description: Mount a Gluster volume. Required: No Referenced object: GlusterfsVolumeSource (see in the Objects section below) hostPath (<code>reference[HostPathVolumeSource]</code>) Name: Host path Description: Mount volume from the host. Required: No Referenced object: HostPathVolumeSource (see in the Objects section below) iscsi (<code>reference[ISCSIVolumeSource]</code>) Name: iSCSI Description: Mount an iSCSI volume. Required: No Referenced object: ISCSIVolumeSource (see in the Objects section below) name (<code>string</code>) Name: Name Description: The name this volume can be referenced by. Required: Yes Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> nfs (<code>reference[NFSVolumeSource]</code>) Name: NFS Description: Mount an NFS share. Required: No Referenced object: NFSVolumeSource (see in the Objects section below) persistentVolumeClaim (<code>reference[PersistentVolumeClaimVolumeSource]</code>) Name: Persistent Volume Claim Description: Mount a Persistent Volume Claim. Required: No Referenced object: PersistentVolumeClaimVolumeSource (see in the Objects section below) photonPersistentDisk (<code>reference[PhotonPersistentDiskVolumeSource]</code>) Name: PhotonController persistent disk Description: Mount a PhotonController persistent disk as a volume. Required: No Referenced object: PhotonPersistentDiskVolumeSource (see in the Objects section below) portworxVolume (<code>reference[PortworxVolumeSource]</code>) Name: Portworx Volume Description: Mount a Portworx volume. Required: No Referenced object: PortworxVolumeSource (see in the Objects section below) projected (<code>reference[ProjectedVolumeSource]</code>) Name: Projected Description: Projected items for all in one resources secrets, configmaps, and downward API. Required: No Referenced object: ProjectedVolumeSource (see in the Objects section below) quobyte (<code>reference[QuobyteVolumeSource]</code>) Name: quobyte Description: Mount Quobyte volume from the host. Required: No Referenced object: QuobyteVolumeSource (see in the Objects section below) rbd (<code>reference[RBDVolumeSource]</code>) Name: Rados Block Device Description: Mount a Rados Block Device. Required: No Referenced object: RBDVolumeSource (see in the Objects section below) scaleIO (<code>reference[ScaleIOVolumeSource]</code>) Name: ScaleIO Persistent Volume Description: Mount a ScaleIO persistent volume. Required: No Referenced object: ScaleIOVolumeSource (see in the Objects section below) secret (<code>reference[SecretVolumeSource]</code>) Name: Secret Description: Mount a Kubernetes secret. Required: No Referenced object: SecretVolumeSource (see in the Objects section below) storageos (<code>reference[StorageOSVolumeSource]</code>) Name: StorageOS Volume Description: Mount a StorageOS volume. Required: No Referenced object: StorageOSVolumeSource (see in the Objects section below) vsphereVolume (<code>reference[VsphereVirtualDiskVolumeSource]</code>) Name: vSphere Virtual Disk Description: Mount a vSphere Virtual Disk as a volume. Required: No Referenced object: VsphereVirtualDiskVolumeSource (see in the Objects section below) VsphereVirtualDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p>"},{"location":"arcaflow/running/setup/#logging","title":"Logging","text":"<p>Logging is useful when you need more information about what is happening while you run a workload.</p>"},{"location":"arcaflow/running/setup/#basic-logging","title":"Basic logging","text":"<p>Here is the syntax for setting the log level: config.yaml<pre><code>log:\n  level: info\n</code></pre></p> <p>Options for the <code>level</code> are:</p> <ul> <li><code>debug</code>: Extra verbosity useful to developers</li> <li><code>info</code>: General info</li> <li><code>warning</code>: Something went wrong, and you should know about it</li> <li><code>error</code>: Something failed. This inf o should help you figure out why</li> </ul> <p>This sets which types of log output are shown or hidden. <code>debug</code> shows everything, while <code>error</code> shows the least, only showing <code>error</code> output. Each output shows more, rather than just its type, so <code>debug</code>, <code>info</code>, and <code>warning</code> still show <code>error</code> output.</p>"},{"location":"arcaflow/running/setup/#step-logging","title":"Step logging","text":"<p>Step logging is useful for getting output from failed steps, or general debugging. It is not recommended that you rely on this long term, as there may be better methods of debugging failed workflows.</p> <p>To make the workflow output just <code>error</code> level logs when a step fails, set it as shown: config.yaml<pre><code>logged_outputs:\n  error:\n    level: error\n</code></pre></p> <p>Tip</p> <p>The standard name for the output path when a step fails is called <code>error</code>, which happens to also be the name of the log level here, but these are independent values.</p> <p>You can specify multiple types of outputs and their log levels. For example, if you also want to output success steps as debug, set it as shown: config.yaml<pre><code>logged_outputs:\n  error:\n    level: error\n  success:\n    level: debug\n</code></pre></p> <p>Note: If you set the level lower than the general log level shown above, it will not show up in the output.</p>"},{"location":"arcaflow/workflows/","title":"Creating Arcaflow workflows","text":"<p>Arcaflow workflows consist of four parts:</p> Version <p>The schema version must be at the root of your workflow file. It indicates the semantic version of the workflow file structure being used.</p> <p>Learn more about versioning \u00bb</p> Inputs <p>The input section of a workflow is much like a plugin schema: it describes the data model of the workflow itself. This is useful because the input can be validated ahead of time. Any input data can then be referenced by the individual plugin steps.</p> <p>Learn more about inputs \u00bb</p> Steps <p>Steps hold the individual parts of the workflow. You can feed data from one step to the next, or feed data from the input to a step.</p> <p>Learn more about steps \u00bb</p> Outputs <p>Outputs hold the final result of a workflow. Outputs can reference outputs of steps.</p> <p>Learn more about output \u00bb</p>"},{"location":"arcaflow/workflows/expressions/","title":"Arcaflow expressions","text":"<p>Arcaflow expressions were inspired by JSONPath but have diverged from the syntax. You can use expressions in a workflow YAML like this:</p> <pre><code>some_value: !expr $.your.expression.here\n</code></pre> <p>This page explains the language elements of expressions.</p> <p>Warning</p> <p>Expressions in workflow definitions must be prefixed with <code>!expr</code>, otherwise their literal value will be taken as a string.</p>"},{"location":"arcaflow/workflows/expressions/#literals","title":"Literals","text":"<p>Literals represent constant values in an expression.</p>"},{"location":"arcaflow/workflows/expressions/#string-values","title":"String values","text":"<p>Normal string literals start and end with a matched pair of either single quotes (<code>'</code>) or double quotes (<code>\"</code>) and have zero or more characters between the quotes.</p> <p>Strings may contain special characters.  In normal strings, these characters are represented by \u201cescape sequences\u201d consisting of a backslash followed by another character.  Since a backslash therefore has a special meaning, in order to represent a literal backslash character, it must be preceded by another backslash.  Similarly, in a string delimited by double quotes, a double quote occurring inside the string must be escaped to prevent it from marking the end of the string. The same is true for single quotes occurring inside a string delimited by single quotes.  However, you do not need to escape double quotes in a single-quoted string nor single-quotes in a double-quoted string.</p> <p>Here is the list of supported escape characters:</p> Escape Result <code>\\\\</code> <code>\\</code> backslash character <code>\\t</code> tab character <code>\\n</code> newline character <code>\\r</code> carriage return character <code>\\b</code> backspace character <code>\\\"</code> <code>\"</code> double quote character <code>\\'</code> <code>'</code> single quote character <code>\\0</code> null character <p>For example, to have the following text represented in a single string:</p> <p>test test2/\\</p> <p>You would need the expression <code>\"test\\ntest2/\\\\\"</code></p>"},{"location":"arcaflow/workflows/expressions/#string-expressions-in-yaml","title":"String Expressions in YAML","text":"<p>When expressing string literals in YAML, be aware that YAML has its own rules around the use of quotation marks.</p> <p>For example, to include a double-quoted string in an expression, you must either add single quotes around the expression or use block flow scalars. Inside a single-quoted string, an apostrophe needs to be preceded by another apostrophe to indicate that it does not terminate the string.</p> <p>Here is an example of the following value represented in a few of the various ways:</p> <p>Here\u2019s an apostrophe and \u201cembedded quotes\u201d.</p> <p>Inlined with single quotes: <pre><code>some_value_1: !expr '\"Here''s an apostrophe and \\\"embedded quotes\\\".\"'\n</code></pre></p> <p>Tip</p> <ul> <li>The <code>!expr</code> tag indicates to the YAML processor that the value is an Arca expression.</li> <li>The single quotes cause the YAML processor to pass the contents of the string intact except for replacing the   repeated apostrophe with a single one.  (They are not included in the expression value.)</li> <li>The backslash-escapes are replaced by Arca\u2019s expression processing.  (The unescaped double quotes are not included   in the expression value.)</li> </ul> <p>Inlined with double quotes: <pre><code>some_value_2: !expr \"'Here\\\\'s an apostrophe and \\\"embedded quotes\\\".'\"\n</code></pre></p> <p>Tip</p> <ul> <li>The <code>!expr</code> tag indicates to the YAML processor that the value is an Arca expression.</li> <li>The double quotes cause the YAML processor to interpret the contents of the string:   <ul><li>the <code>\\\\</code> is replaced with a single backslash;   <li>each <code>\\\"</code> is replaced with a literal <code>\"</code>;   <li>the surrounding double quotes are not included in the expression value.</li> <li>The backslash-escapes are replaced by Arca\u2019s expression processing.  (The unescaped single quotes are not included   in the expression value.)</li> <p>With Block Flow Scalar: <pre><code>some_value_1: !expr |-\n  'Here\\'s an apostrophe and \"embedded quotes\".'\nsome_value_2: !expr |-\n  \"Here's an apostrophe and \\\"embedded quotes\\\".\"\n</code></pre></p> <p>Tip</p> <ul> <li>The <code>!expr</code> tag indicates to the YAML processor that the value is an Arca expression.</li> <li>The vertical bar (<code>|</code>) causes the YAML processor to pass the contents of the string without modification.</li> <li>Newlines within the expression are included in the string; the hyphen (<code>-</code>) after the vertical bar causes the trailing newline to be omitted from the end of the string.</li> <li>The backslash-escapes are replaced by Arca\u2019s expression processing.  The unescaped quotes are not included in the expression value; the other quotes are escaped to prevent them from ending the string prematurely; the double quotes in <code>some_value_1</code> do not need to be escaped nor do the single quotes in <code>some_value_2</code>.</li> </ul> <p>See Raw string values to see how to do this without escaping.</p>"},{"location":"arcaflow/workflows/expressions/#raw-string-values","title":"Raw string values","text":"<p>Raw string literals start and end with backtick characters \u201c`\u201c.</p> <p>In a raw string, all characters are interpreted literally. This means that you can use <code>'</code> and <code>\"</code> characters without escaping them, and backslashes are treated like any other character.  However, backtick characters cannot appear in a raw string.</p> <p>Here is an example of the following value represented using raw strings:</p> <p>Here\u2019s an apostrophe and \u201cembedded quotes\u201d.</p> <p>Inlined: <pre><code>some_value: !expr '`Here''s an apostrophe and \"embedded quotes\".`'\n</code></pre></p> <p>Tip</p> <ul> <li>The <code>!expr</code> tag indicates to the YAML processor that the value is an Arca expression.</li> <li>The single quotes cause the YAML processor to pass the contents of the string intact except for replacing the   repeated apostrophe with a single one.  (They are not included in the expression value.)</li> <li>The backticks cause Arca\u2019s expression processing to use the string verbatim.  (The backticks are not included   in the expression value.)</li> </ul> <p>With Block Flow Scalar: <pre><code>some_value: !expr |-\n  `Here's an apostrophe and \"embedded quotes\".`\n</code></pre></p> <p>Tip</p> <ul> <li>The <code>!expr</code> tag indicates to the YAML processor that the value is an Arca expression.</li> <li>The vertical bar (<code>|</code>) causes the YAML processor to pass the contents of the string without modification.</li> <li>Newlines within the expression are included in the string; the hyphen (<code>-</code>) after the vertical bar causes the   trailing newline to be omitted from the end of the string.</li> <li>The backticks cause Arca\u2019s expression processing to use the string verbatim, thus the embedded quotes don\u2019t require   escapes.  (The backticks are not included in the expression value.)</li> </ul>"},{"location":"arcaflow/workflows/expressions/#integer-numbers","title":"Integer numbers","text":"<p>Integers are whole numbers expressed as sequences of base-10 digits.</p> <p>Integer literals may not start with <code>0</code>, unless the value is <code>0</code>. For example, <code>001</code> is not a valid integer literal.</p> <p>Examples:</p> <ul> <li><code>0</code></li> <li><code>1</code></li> <li><code>503</code></li> </ul> <p>Negative values are constructed by applying the negation operator (<code>-</code>) to a literal numeric value.</p>"},{"location":"arcaflow/workflows/expressions/#floating-point-numbers","title":"Floating point numbers","text":"<p>Floating point literals are non-negative double-precision floating point numbers.</p> <p>Supported formats include:</p> <ul> <li>number characters followed by a period followed by zero or more number characters: <code>1.1</code> or <code>1.</code></li> <li>base-10 exponential scientific notation formats like <code>5.0e5</code> and <code>5.0E-5</code></li> </ul> <p>Negative values are constructed by applying the negation operator (<code>-</code>) to a literal numeric value.</p>"},{"location":"arcaflow/workflows/expressions/#boolean-values","title":"Boolean values","text":"<p>Boolean literals have two valid values:</p> <ul> <li><code>true</code></li> <li><code>false</code></li> </ul> <p>No other values are valid boolean literals. The values are case-sensitive.</p>"},{"location":"arcaflow/workflows/expressions/#root-reference","title":"Root reference","text":"<p>The <code>$</code> character always references the root of the data structure. Let\u2019s take this data structure:</p> <pre><code>foo:\n  bar: Hello world!\n</code></pre> <p>You can reference the text like this:</p> <pre><code>$.foo.bar\n</code></pre>"},{"location":"arcaflow/workflows/expressions/#dot-notation","title":"Dot notation","text":"<p>The dot notation allows you to reference fields of an object.</p> <p>For example, if you have an object on the root data structure named \u201ca\u201d with the field \u201cb\u201d in it, you can access it with:</p> <pre><code>$.a.b\n</code></pre>"},{"location":"arcaflow/workflows/expressions/#bracket-accessor","title":"Bracket accessor","text":"<p>The bracket accessor is used for referencing values in maps or lists.</p>"},{"location":"arcaflow/workflows/expressions/#list-access","title":"List access","text":"<p>For list access, you specify the index of the value you want to access. The index should be an expression yielding a non-negative integer value, where zero corresponds to the first value in the list.</p> <p>If you have a list named <code>foo</code>:</p> <pre><code>foo:\n  - Hello world!\n</code></pre> <p>You can access the first value with the expression: <pre><code>$.foo[0]\n</code></pre></p> <p>Giving the output <code>\"Hello world!\"</code></p>"},{"location":"arcaflow/workflows/expressions/#map-access","title":"Map access","text":"<p>Maps, also known as dictionaries in some languages, are key-value pair data structures.</p> <p>To use a map in an expression, the expression to the left of the brackets must be a reference to a map. That is then followed by a pair of brackets with a sub-expression between them. That sub-expression must evaluate to a valid key in the map.</p> <p>Here is an example of a map with string keys and integer values. The map is stored in a field called <code>foo</code> in the root-level object:</p> <pre><code>foo:\n  a: 1\n  b: 2\n</code></pre> <p>Given the map shown above, the following expression would yield a value of <code>2</code>: <pre><code>$.foo[\"b\"]\n</code></pre></p>"},{"location":"arcaflow/workflows/expressions/#functions","title":"Functions","text":"<p>The engine provides predefined functions for use in expressions.  These provide transformations beyond what is available from operators.</p> <p>Functions:</p> function definition return type description <code>intToFloat(integer)</code> float Converts an integer value into the equivalent floating point value. <code>floatToInt(float)</code> integer Converts a floating point value into an integer value by discarding the fraction, rounding toward zero to the nearest integer.Special cases:\u00a0 +Inf yields the maximum 64-bit integer (9223372036854775807)\u00a0 -Inf and NaN yield the minimum 64-bit integer (-9223372036854775808)For example, <code>5.5</code> yields <code>5</code>, and <code>-1.9</code> yields <code>-1</code> <code>intToString(integer)</code> string Returns a string containing the base-10 representation of the input.For example, an input of <code>55</code> yields <code>\"55\"</code> <code>floatToString(float)</code> string Returns a string containing the base-10 representation of the input.For example, an input of <code>5000.5</code> yields <code>\"5000.5\"</code> <code>floatToFormattedString(float, string, integer)</code> string Returns a string containing the input in the specified format with the specified precision.\u00a0 Param 1: the floating point input value\u00a0 Param 2: the format specifier: <code>\"e\"</code>, <code>\"E\"</code>, <code>\"f\"</code>, <code>\"g\"</code>, <code>\"G\"</code>\u00a0 Param 3: the number of digitsSpecifying -1 for the precision will produce the minimum number of digits required to represent the value exactly.  (See the Go runtime documentation for details.) <code>boolToString(boolean)</code> string Returns <code>\"true\"</code> for <code>true</code>, and <code>\"false\"</code> for <code>false</code>. <code>stringToInt(string)</code> integer Interprets the string as a base-10 integer. Returns an error if the input is not a valid integer. <code>stringToFloat(string)</code> float Converts the input string to a double-precision floating-point number.Accepts floating-point numbers as defined by the Go syntax for floating point literals.  If the input is well-formed and near a valid floating-point number, returns the nearest floating-point number rounded using IEEE754 unbiased rounding. Returns an error when an invalid input is received. <code>stringToBool(string)</code> boolean Interprets the input as a boolean.Accepts <code>\"1\"</code>, <code>\"t\"</code>, and <code>\"true\"</code> as <code>true</code> and <code>\"0\"</code>, <code>\"f\"</code>, and <code>\"false\"</code> as <code>false</code> (case is not significant). Returns an error for any other input. <code>ceil(float)</code> float Returns the least integer value greater than or equal to the input.Special cases are:\u00a0 ceil(\u00b10.0) = \u00b10.0\u00a0 ceil(\u00b1Inf) = \u00b1Inf\u00a0 ceil(NaN) = NaNFor example <code>ceil(1.5)</code> yields <code>2.0</code>, and <code>ceil(-1.5)</code> yields <code>-1.0</code> <code>floor(float)</code> float Returns the greatest integer value less than or equal to the input.Special cases are:\u00a0 floor(\u00b10.0) = \u00b10.0\u00a0 floor(\u00b1Inf) = \u00b1Inf\u00a0 floor(NaN) = NaNFor example <code>floor(1.5)</code> yields <code>1.0</code>, and <code>floor(-1.5)</code> yields <code>-2.0</code> <code>round(float)</code> float Returns the nearest integer to the input, rounding half away from zero.Special cases are:\u00a0 round(\u00b10.0) = \u00b10.0\u00a0 round(\u00b1Inf) = \u00b1Inf\u00a0 round(NaN) = NaNFor example <code>round(1.5)</code> yields <code>2.0</code>, and <code>round(-1.5)</code> yields <code>-2.0</code> <code>abs(float)</code> float Returns the absolute value of the input.Special cases are:\u00a0 abs(\u00b1Inf) = +Inf\u00a0 abs(NaN) = NaN <code>toLower(string)</code> string Returns the input with Unicode letters mapped to their lower case. <code>toUpper(string)</code> string Returns the input with Unicode letters mapped to their upper case. <code>splitString(string, string)</code> list[string] Returns a list of the substrings which appear between instances of the specified separator; the separator instances are not included in the resulting list elements; adjacent occurrences of separator instances as well as instances appearing at the beginning or ending of the input will produce empty string list elements.\u00a0 Param 1: The string to split.\u00a0 Param 2: The separator. <code>readFile(string)</code> string Returns the contents of a file as a UTF-8 character string, given a file path string. Relative file paths are resolved from the Arcaflow process working directory. Shell environment variables are not expanded. <p>A function is used in an expression by referencing its name followed by a comma-separated list of zero or more argument expressions enclosed in parentheses.</p> <p>Example: <pre><code>thisIsAFunction(\"this is a string literal for the first parameter\", $.a.b)\n</code></pre></p>"},{"location":"arcaflow/workflows/expressions/#binary-operations","title":"Binary Operations","text":"<p>Binary Operations have an expression to the left and right, with an operator in between. The order of operations determines which operators are evaluated first. See Order of Operations</p> <p>The types of the left and right operand expressions must match. To convert between types, see the list of available functions. The type of the resulting expression is the same as the type of its operands.</p> Operator Description <code>+</code> Addition/Concatenation <code>-</code> Subtraction <code>*</code> Multiplication <code>/</code> Division <code>%</code> Modulus <code>^</code> Exponentiation <code>==</code> Equal To <code>!=</code> Not Equal To <code>&gt;</code> Greater Than <code>&lt;</code> Less Than <code>&gt;=</code> Greater Than or Equal To <code>&lt;=</code> Less Than or Equal To <code>&amp;&amp;</code> Logical And <code>\\|\\|</code> Logical Or"},{"location":"arcaflow/workflows/expressions/#additionconcatenation","title":"Addition/Concatenation","text":"<p>This operator has different behavior depending on the type.</p>"},{"location":"arcaflow/workflows/expressions/#string-concatenation","title":"String Concatenation","text":"<p>When the <code>+</code> operator is used with two strings, it concatenates them together. For example, the expression <code>\"a\" + \"b\"</code> would output the string <code>\"ab\"</code>.</p>"},{"location":"arcaflow/workflows/expressions/#mathematical-addition","title":"Mathematical Addition","text":"<p>When the <code>+</code> operator is used with numerical operands, it adds them together. The operator requires numerical operands with the same type. You cannot mix float and integer operands. For example, the expression <code>2 + 2</code> would output the integer <code>4</code>.</p>"},{"location":"arcaflow/workflows/expressions/#subtraction","title":"Subtraction","text":"<p>When the <code>-</code> operator is applied to numerical operands, the result is the value of the right operand subtracted from the value of the left. The operator requires numerical operands with the same type. You cannot mix float and integer operands.</p> <p>For example, the expression <code>6 - 4</code> would output the integer <code>2</code>. The expression <code>$.a - $.b</code> would evaluate the values of <code>a</code> and <code>b</code> within the root, and subtract the value of <code>$.b</code> from <code>$.a</code>.</p>"},{"location":"arcaflow/workflows/expressions/#multiplication","title":"Multiplication","text":"<p>When the <code>*</code> operator is used with numerical operands, it multiplies them. The operator requires numerical operands with the same type.</p> <p>For example, the expression <code>3 * 3</code> would output the integer <code>9</code>.</p>"},{"location":"arcaflow/workflows/expressions/#division","title":"Division","text":"<p>When the <code>/</code> operator is used with numerical operands, it outputs the value of the left expression divided by the value of the right. The operator requires numerical operands with the same type.</p> <p>The result of integer division is rounded towards zero. If a non-integral result is required, or if different rounding logic is required, convert the inputs into floating point numbers with the <code>intToFloat</code> function. Different types of rounding can be performed on floating point numbers with the functions <code>ceil</code>, <code>floor</code>, and <code>round</code>.</p> <p>For example, the expression <code>-3 / 2</code> would yield the integer value <code>-1</code>.</p>"},{"location":"arcaflow/workflows/expressions/#modulus","title":"Modulus","text":"<p>When the <code>%</code> operator is used with numerical operands, it evaluates to the remainder when the value of the left expression is divided by the value of the right. The operator requires numerical operands with the same type.</p> <p>For example, the expression <code>5 % 3</code> would output the integer <code>2</code>.</p>"},{"location":"arcaflow/workflows/expressions/#exponentiation","title":"Exponentiation","text":"<p>The <code>^</code> operator outputs the result of the left side raised to the power of the right side. The operator requires numerical operands with the same type.</p> <p>The mathematical expression 2<sup>3</sup> is represented in the expression language as <code>2^3</code>, which would output the integer <code>8</code>.</p>"},{"location":"arcaflow/workflows/expressions/#equal-to","title":"Equal To","text":"<p>The <code>==</code> operator evaluates to true if the values of the left and right operands are the same. Both operands must have the same type. You may use functions to convert between types \u2013 see functions for more type conversions. The operator supports the types <code>integer</code>, <code>float</code>, <code>string</code>, and <code>boolean</code>.</p> <p>For example, <code>2 == 2</code> results in <code>true</code>, and <code>\"a\" == \"b\"</code> results in <code>false</code>.  <code>1 == 1.0</code> would result in a type error.</p>"},{"location":"arcaflow/workflows/expressions/#not-equal-to","title":"Not Equal To","text":"<p>The <code>!=</code> operator is the inverse of the <code>==</code> operator. It evaluates to false if the values of the left and right operands are the same. Both operands must have the same type. You may use functions to convert between types \u2013 see functions for more type conversions. The operator supports the types <code>integer</code>, <code>float</code>, <code>string</code>, and <code>boolean</code>.</p> <p>For example, <code>2 != 2</code> results in <code>false</code>, and <code>\"a\" != \"b\"</code> results in <code>true</code>.  <code>1 != 1.0</code> would result in a type error.</p>"},{"location":"arcaflow/workflows/expressions/#greater-than","title":"Greater Than","text":"<p>The <code>&gt;</code> operator outputs <code>true</code> if the left side is greater than the right side, and <code>false</code> otherwise. The operator requires numerical or string operands. The type must be the same for both operands. String operands are compared using the lexicographical order of the charset.</p> <p>For an integer example, the expression <code>3 &gt; 3</code> would output the boolean <code>false</code>, and <code>4 &gt; 3</code> would output <code>true</code>. For a string example, the expression <code>\"a\" &gt; \"b\"</code> would output <code>false</code>.</p>"},{"location":"arcaflow/workflows/expressions/#less-than","title":"Less Than","text":"<p>The <code>&lt;</code> operator outputs <code>true</code> if the left side is less than the right side, and <code>false</code> otherwise. The operator requires numerical or string operands. The type must be the same for both operands. String operands are compared using the lexicographical order of the charset.</p> <p>For an integer example, the expression <code>3 &lt; 3</code> would output the boolean <code>false</code>, and <code>1 &lt; 2</code> would output <code>true</code>. For a string example, the expression <code>\"a\" &lt; \"b\"</code> would output <code>true</code>.</p>"},{"location":"arcaflow/workflows/expressions/#greater-than-or-equal-to","title":"Greater Than or Equal To","text":"<p>The <code>&gt;=</code> operator outputs <code>true</code> if the left side is greater than or equal to (not less than) the right side, and <code>false</code> otherwise. The operator requires numerical or string operands. The type must be the same for both operands. String operands are compared using the lexicographical order of the charset.</p> <p>For an integer example, the expression <code>3 &gt;= 3</code> would output the boolean <code>true</code>, <code>3 &gt;= 4</code> would output <code>false</code>, and <code>4 &gt;= 3</code> would output <code>true</code>.</p>"},{"location":"arcaflow/workflows/expressions/#less-than-or-equal-to","title":"Less Than or Equal To","text":"<p>The <code>&lt;=</code> operator outputs <code>true</code> if the left side is less than or equal to (not greater than) the right side, and <code>false</code> otherwise. The operator requires numerical or string operands. The type must be the same for both operands. String operands are compared using the lexicographical order of the charset.</p> <p>For example, the expression <code>3 &lt;= 3</code> would output the boolean <code>true</code>, <code>3 &lt;= 4</code> would output <code>true</code>, and <code>4 &lt;= 3</code> would output <code>false</code>.</p>"},{"location":"arcaflow/workflows/expressions/#logical-and","title":"Logical AND","text":"<p>The <code>&amp;&amp;</code> operator returns <code>true</code> if both the left and right sides are <code>true</code>, and <code>false</code> otherwise. This operator requires boolean operands. Note: The operation does not \u201cshort-circuit\u201d \u2013 both the left and right expressions are evaluated before the comparison takes place.</p> <p>All cases:</p> Left Right <code>&amp;&amp;</code> <code>true</code> <code>true</code> <code>true</code> <code>true</code> <code>false</code> <code>false</code> <code>false</code> <code>true</code> <code>false</code> <code>false</code> <code>false</code> <code>false</code>"},{"location":"arcaflow/workflows/expressions/#logical-or","title":"Logical OR","text":"<p>The <code>||</code> operator returns <code>true</code> if either or both of the left and right sides are <code>true</code>, and <code>false</code> otherwise. This operator requires boolean operands. Note: The operation does not \u201cshort-circuit\u201d \u2013 both the left and right expressions are evaluated before the comparison takes place.</p> <p>All cases:</p> Left Right <code>\\|\\|</code> <code>true</code> <code>true</code> <code>true</code> <code>true</code> <code>false</code> <code>true</code> <code>false</code> <code>true</code> <code>true</code> <code>false</code> <code>false</code> <code>false</code>"},{"location":"arcaflow/workflows/expressions/#unary-operations","title":"Unary Operations","text":"<p>Unary operations are operations that have one input. The operator is applied to the expression which follows it.</p> Operator Description - Negation ! Logical complement"},{"location":"arcaflow/workflows/expressions/#negation","title":"Negation","text":"<p>The <code>-</code> operator negates the value of the expression which follows it.</p> <p>This operation requires numeric input.</p> <p>Examples with integer literals: <code>-5</code>, <code>- 5</code> Example with a float literal: <code>-50.0</code> Example with a reference: <code>-$.foo</code> Example with parentheses and a sub-expression: <code>-(5 + 5)</code></p>"},{"location":"arcaflow/workflows/expressions/#logical-complement","title":"Logical complement","text":"<p>The <code>!</code> operator logically inverts the value of the expression which follows it.</p> <p>This operation requires boolean input.</p> <p>Example with a boolean literal: <code>!true</code> Example with a reference: <code>!$.foo</code></p>"},{"location":"arcaflow/workflows/expressions/#parentheses","title":"Parentheses","text":"<p>Parentheses are used to force precedence in the expression. They do not do anything implicitly (for example, there is no implied multiplication).</p> <p>For example, the expression <code>5 + 5 * 5</code> evaluates the <code>5 * 5</code> before the <code>+</code>, resulting in <code>5 + 25</code>, and finally <code>30</code>. If you want the 5 + 5 to be run first, you must use parentheses. That gives you the expression <code>(5 + 5) * 5</code>, resulting in <code>10 * 5</code>, and finally <code>50</code>.</p>"},{"location":"arcaflow/workflows/expressions/#order-of-operations","title":"Order of Operations","text":"<p>The order of operations is designed to match mathematics and most programming languages.</p> <p>Order (highest to lowest; operators listed on the same line are evaluated in the order they appear in the expression):</p> <ul> <li>negation (<code>-</code>)</li> <li>parentheses (<code>()</code>)</li> <li>exponent (<code>^</code>)</li> <li>multiplication (<code>*</code>) and division (<code>/</code>)</li> <li>addition/concatenation (<code>+</code>) and subtraction (<code>-</code>)</li> <li> <p>binary equality and inequality (all equal)  <ul><li>equals (<code>==</code>) <li>not equals (<code>!=</code>) <li>greater than (<code>&gt;</code>) <li>less than (<code>&lt;</code>) <li>greater than or equal to (<code>&gt;=</code>) <li>less than or equal to (<code>&lt;=</code>)</li> </li> <li> <p>logical complement (<code>!</code>)</p> </li> <li>logical AND (<code>&amp;&amp;</code>)</li> <li>logical OR (<code>||</code>)</li> <li>dot notation (<code>.</code>) and bracket access (<code>[]</code>)</li>"},{"location":"arcaflow/workflows/expressions/#other-information","title":"Other information","text":"<p>More information on the expression language is available in the development guide.</p>"},{"location":"arcaflow/workflows/expressions/#examples","title":"Examples","text":""},{"location":"arcaflow/workflows/expressions/#referencing-inputs","title":"Referencing inputs","text":"<p>Pass a workflow input directly to a plugin input</p> workflow.yaml<pre><code>input:\n  root: RootObject\n  objects:\n    RootObject:\n      id: RootObject\n      properties:\n        name:\n          type:\n            type_id: string\n\nsteps:\n  step_a:\n    plugin: quay.io/some/container/image\n    input:\n      some:\n        key: !expr $.input.name\n</code></pre>"},{"location":"arcaflow/workflows/expressions/#passing-between-steps","title":"Passing between steps","text":"<p>Pass output from one plugin to the input of another plugin</p> workflow.yaml<pre><code>steps:\n  step_a:\n    plugin: quay.io/some/container/image\n    input: {}\n\n  step_b:\n    plugin: quay.io/some/container/image\n    input:\n      some:\n        key: !expr $.steps.step_a.outputs.success.some_value\n</code></pre>"},{"location":"arcaflow/workflows/flow-control/","title":"Using Flow Control Mechanics","text":"<p>Flow control allows the workflow author to build a workflow with a decision tree based on supported flow logic. These flow control operations are not implemented by plugins, but are part of the workflow engine itself.</p>"},{"location":"arcaflow/workflows/flow-control/#foreach-loops","title":"Foreach Loops","text":"<p>Foreach loops allow for running a sub-workflow with iterative inputs from a parent workflow. A sub-workflow is a complete Arcaflow workflow file with it\u2019s own input and output schemas as described in this section. The inputs for the sub-workflow are provided as a list, where each list item is an object that matches the sub-workflow input schema.</p> <p>Tip</p> <p>A complete functional example is available in the arcaflow-workflows repository.</p> <p>In the parent workflow file, the author can define an input schema with the list that will contain the input object that will be passed to the sub-workflow. For example:</p> workflow.yaml<pre><code>input:\n  root: RootObject\n  objects:\n    RootObject:\n      id: RootObject\n      properties:\n        loop:\n          type:\n            type_id: list\n            items:\n              type_id: object\n              id: loop_id\n              properties:\n                loop_id:\n                  type:\n                    type_id: integer\n                param_1:\n                  type:\n                    type_id: integer\n                param_2:\n                  type:\n                    type_id: string\n</code></pre> <p>Then in the <code>steps</code> secton of the workflow, the sub-workflow can be defined as a step with the <code>loop</code> list object from above passed to its input.</p> <p>The parameters for the sub-workflow step are:</p> <ul> <li><code>kind</code> - The type of loop (currently only foreach is supported)</li> <li><code>items</code> - A list of objects to pass to the sub-workflow (the expression language allows to pass this from the input schema per the above example)</li> <li><code>workflow</code> - The file name for the sub-workflow (this should be in the same directory as the parent workflow)</li> <li><code>parallelism</code> - The number of sub-workflow loop iterations that will run in parallel</li> </ul> workflow.yaml<pre><code>steps:\n  sub_workflow_loop:\n    kind: foreach\n    items: !expr $.input.loop\n    workflow: sub-workflow.yaml\n    parallelism: 1\n</code></pre> <p>The input yaml file for the above parent workflow would provide the list of objects to loop over as in this example:</p> input.yaml<pre><code>loop:\n  - loop_id: 1\n    param_1: 10\n    param_2: \"a\"\n  - loop_id: 2\n    param_1: 20\n    param_2: \"b\"\n  - loop_id: 3\n    param_1: 30\n    param_2: \"c\"\n</code></pre> <p>The sub-workflow file then has its complete schema and set of steps as in this example:</p> sub-workflow.yaml<pre><code>input:\n  root: RootObject\n  objects:\n    RootObject:\n      id: RootObject\n      properties:\n        loop_id:\n          type:\n            type_id: integer\n        param_1:\n          type:\n            type_id: integer\n        param_2:\n          type:\n            type_id: string\nsteps:\n  my_plugin:\n    plugin: path/to/my_plugin:1\n    input:\n      param_1: !expr $.input.param_1\n  my_other_plugin:\n    plugin: path/to/my_other_plugin:1\n    input:\n      param_2: !expr $.input.param_2\noutputs:\n  success:\n    loop_id: !expr $.input.loop_id\n    my_plugin: !expr $.steps.my_plugin.outputs.success\n    my_other_plugin: !expr $.steps.my_other_plugin.outputs.success\n</code></pre>"},{"location":"arcaflow/workflows/input/","title":"Writing workflow inputs","text":"<p>The input section of a workflow is much like a plugin schema: it describes the data model of the workflow itself. This is useful because the input can be validated ahead of time. Any input data can then be referenced by the individual steps.</p> <p>Tip</p> <p>The workflow input schema is analogous to the plugin input schema in that it defines the expected inputs and formats. But a workflow author has the freedom to define the schema independently of the plugin schema \u2013 This means that objects can be named and documented differently, catering to the workflow user, and input validation can happen before a plugin is loaded.</p> <p>The workflow inputs start with a scope object. As an overview, a scope looks like this:</p> workflow.yaml<pre><code>input:\n  root: RootObject\n  objects:\n    RootObject:\n      id: RootObject\n      properties:\n        name:\n          type:\n            type_id: string\n        # Other properties of the root object\n    # Other objects that can be referenced here\n</code></pre> <p>This corresponds to the following workflow input:</p> workflow_input.yaml<pre><code>name: Arca Lot\n</code></pre> <p>Admittedly, this looks complicated, but read on, it will become clear very quickly.</p>"},{"location":"arcaflow/workflows/input/#objects","title":"Objects","text":"<p>Let\u2019s start with objects. Objects are like structs or classes in programming. They have two properties: an ID and a list of properties. The basic structure looks like this:</p> <pre><code>some_object:\n  id: some_object\n  properties:\n    # Properties here\n</code></pre>"},{"location":"arcaflow/workflows/input/#properties","title":"Properties","text":"<p>Now you need to define a property. Let\u2019s say, we want to define a string with the name of the user. You can do this as follows:</p> <pre><code>type_id: object\nid: some_object\nproperties:\nname:\n  type:\n    type_id: string\n</code></pre> <p>Notice, that the <code>type_id</code> field is indented. That\u2019s because the <code>type</code> field describes a string type, which has additional parameters. For example:</p> <pre><code>type_id: object\nid: some_object\nproperties:\nname:\n  type:\n    type_id: string\n    min: 1 # Minimum length for the string\n</code></pre> <p>There are also additional attributes of the property itself. For example:</p> <pre><code>type_id: object\nid: some_object\nproperties:\nname:\n  type:\n    type_id: string\n    min: 1 # Minimum length for the string\n  display:\n    name: Name\n    description: Name of the user.\n  conflicts:\n    - full_name\n</code></pre> <p>Properties have the following attributes:</p> Attribute Type Description <code>display</code> <code>Display</code> Display metadata of the property. See Display values. <code>required</code> <code>bool</code> If set to true, the field must always be filled. <code>required_if</code> <code>[]string</code> List of other properties that, if filled, lead to the current property being required. <code>required_if_not</code> <code>[]string</code> List of other properties that, if not filled, lead to the current property being required. <code>conflicts</code> <code>[]string</code> List of other properties that conflict the current property. <code>default</code> <code>string</code> Default value for this property, JSON-encoded. <code>examples</code> <code>[]string</code> Examples for the current property, JSON-encoded. <p>Note</p> <p>Unlike the plugin schema where an unassigned default value is set to <code>None</code>, for the workflow schema you simply omit the default to leave it unassigned.</p>"},{"location":"arcaflow/workflows/input/#scopes-and-refs","title":"Scopes and refs","text":"<p>Scopes behave like objects, but they serve an additional purpose. Suppose, object <code>A</code> had a property of the object type <code>B</code>, but now you needed to reference back to object <code>A</code>. Without references, there would be no way to do this.</p> <p>OpenAPI and JSON Schema have a similar concept, but in those systems all references are global. This presents a problem when merging schemas. For example, both Docker and Kubernetes have an object called <code>Volume</code>. These objects would need to be renamed when both configurations are in one schema.</p> <p>Arcaflow has a different solution: every plugin, every part of a workflow has its own scope. When a reference is found in a scope, it always relates to its own scope. This way, references don\u2019t get mixed.</p> <p>Let\u2019s take a simple example: a scope with objects <code>A</code> and <code>B</code>, referencing each other.</p> <pre><code>type_id: scope\nroot: A\nobjects:\n  A:\n    type_id: object\n    id: A\n    properties:\n      b:\n        type:\n          type_id: ref\n          id: B\n        required: false\n  B:\n    type_id: object\n    id: B\n    properties:\n      a:\n        type:\n          type_id: ref\n          id: A\n        required: false\n</code></pre> <p>This you can create a circular dependency between these objects without needing to copy-paste their properties.</p> <p>Additionally, refs have an extra <code>display</code> property, which references a Display value to provide context for the reference.</p>"},{"location":"arcaflow/workflows/input/#strings","title":"Strings","text":"<p>Strings are, as the name suggests, strings of human-readable characters. They have the following properties:</p> <pre><code>type_id: string\nmin: # Minimum number of characters. Optional.\nmax: # Maximum number of characters. Optional.\npattern: # Regular expression this string must match. Optional.\n</code></pre>"},{"location":"arcaflow/workflows/input/#pattern","title":"Pattern","text":"<p>Patterns are special kinds of strings that hold regular expressions.</p> <pre><code>type_id: pattern\n</code></pre>"},{"location":"arcaflow/workflows/input/#integers","title":"Integers","text":"<p>Integers are similar to strings, but they don\u2019t have a <code>pattern</code> field but have a <code>units</code> field. (See Units.)</p> <pre><code>type_id: integer\nmin: # Minimum value. Optional.\nmax: # Maximum value. Optional.\nunits:\n  # Units definition. Optional.\n</code></pre>"},{"location":"arcaflow/workflows/input/#floats","title":"Floats","text":"<p>Floating point numbers are similar to integers.</p> <pre><code>type_id: float\nmin: # Minimum value. Optional.\nmax: # Maximum value. Optional.\nunits:\n  # Units definition. Optional.\n</code></pre>"},{"location":"arcaflow/workflows/input/#string-enums","title":"String enums","text":"<p>Enums only allow a fixed set of values. String enums map string keys to a display value. (See Display values.)</p> <pre><code>type_id: enum_string\nvalues:\n  red:\n    name: Red\n  yellow:\n    name: Yellow\n</code></pre>"},{"location":"arcaflow/workflows/input/#integer-enums","title":"Integer enums","text":"<p>Enums only allow a fixed set of values. Integer enums map integer keys to a display value. (See Display values.)</p> <pre><code>type_id: enum_integer\nvalues:\n  1:\n    name: Red\n  2:\n    name: Yellow\n</code></pre>"},{"location":"arcaflow/workflows/input/#booleans","title":"Booleans","text":"<p>Booleans can hold a true or false value.</p> <pre><code>type_id: bool\n</code></pre>"},{"location":"arcaflow/workflows/input/#lists","title":"Lists","text":"<p>Lists hold items of a specific type. You can also define their minimum and maximum size.</p> <pre><code>type_id: list\nitems:\n  type_id: type of the items\n  # Other definitions for list items\nmin: 1 # Minimum number of items in the list (optional)\nmax: 2 # maximum number of items in the list (optional)\n</code></pre>"},{"location":"arcaflow/workflows/input/#maps","title":"Maps","text":"<p>Maps are key-value mappings. You must define both the key and value types, whereas keys can only be strings, integers, string enums, or integer enums.</p> <pre><code>type_id: map\nkeys:\n  type_id: string\nvalues:\n  type_id: string\nmin: 1 # Minimum number of items in the map (optional)\nmax: 2 # maximum number of items in the map (optional)\n</code></pre>"},{"location":"arcaflow/workflows/input/#one-of-string-discriminator","title":"One-of (string discriminator)","text":"<p>One-of types allow you to specify multiple alternative objects, scopes, or refs. However, these objects must contain a common field (discriminator) and each value for that field must correspond to exactly one object type.</p> <p>Tip</p> <p>If the common field is not specified in the possible objects, it is implicitly added. If it is specified, however, it must match the discriminator type.</p> <pre><code>type_id: one_of_string\ndiscriminator_field_name: object_type # Defaults to: _type\ntypes:\n  a:\n    type_id: object\n    id: A\n    properties:\n      # Properties of object A.\n  b:\n    type_id: object\n    id: B\n    properties:\n      # Properties of object B\n</code></pre> <p>We can now use the following value as an input:</p> <pre><code>object_type: a\n# Other values for object A\n</code></pre> <p>In contrast, you can specify <code>object_type</code> as <code>b</code> and that will cause the unserialization to run with the properties of object <code>B</code>.</p>"},{"location":"arcaflow/workflows/input/#one-of-integer-discriminator","title":"One-of (integer discriminator)","text":"<p>One-of types allow you to specify multiple alternative objects, scopes, or refs. However, these objects must contain a common field (discriminator) and each value for that field must correspond to exactly one object type.</p> <p>Tip</p> <p>If the common field is not specified in the possible objects, it is implicitly added. If it is specified, however, it must match the discriminator type.</p> <pre><code>type_id: one_of_int\ndiscriminator_field_name: object_type # Defaults to: _type\ntypes:\n  1:\n    type_id: object\n    id: A\n    properties:\n      # Properties of object A.\n  2:\n    type_id: object\n    id: B\n    properties:\n      # Properties of object B\n</code></pre> <p>We can now use the following value as an input:</p> <pre><code>object_type: 1\n# Other values for object A\n</code></pre> <p>In contrast, you can specify <code>object_type</code> as <code>2</code> and that will cause the unserialization to run with the properties of object <code>B</code>.</p>"},{"location":"arcaflow/workflows/input/#any-types","title":"Any types","text":"<p>Any types allow any data to pass through without validation. We recommend using the \u201cany\u201d type due to its lack of validation and the risk to cause runtime errors. Only use any types if you can truly handle any data that is passed.</p> <pre><code>type_id: any\n</code></pre>"},{"location":"arcaflow/workflows/input/#display-values","title":"Display values","text":"<p>Display values are all across the Arcaflow schema. They are useful to provide human-readable descriptions of properties, refs, etc. that can be used to generate nice, human-readable documentation, user interfaces, etc. They are always optional and consist of the following 3 fields:</p> <pre><code>name: Short name\ndescription: Longer description of what the item does, possibly in multiple lines.\nicon: |\n  &lt;svg ...&gt;&lt;/svg&gt; # SVG icon, 64x64 pixels, without doctype and external references.\n</code></pre>"},{"location":"arcaflow/workflows/input/#units","title":"Units","text":"<p>Units make it easier to parse and display numeric values. For example, if you have an integer representing nanoseconds, you may want to parse strings like <code>5m30s</code>.</p> <p>Units have two parameters: a base unit description and multipliers. For example:</p> <pre><code>base_unit:\n  name_short_singular: B\n  name_short_plural: B\n  name_long_singular: byte\n  name_long_plural: bytes\nmultipliers:\n  1024:\n    name_short_singular: kB\n    name_short_plural: kB\n    name_long_singular: kilobyte\n    name_long_plural: kilobytes\n  # ...\n</code></pre>"},{"location":"arcaflow/workflows/output/","title":"Writing workflow outputs","text":"<p>Outputs in Arcaflow serve a dual purpose:</p> <ol> <li>They provide the desired resulting data from steps and inputs to STDOUT.</li> <li>They allow for the conditional pass/fail state of the workflow (if any defined output is not available, the workflow reports a failure).</li> </ol> <p>You can define an output simply with expressions. Outputs generally include desired output parameters from individual steps, but may also include data from inputs or even static values.</p> <pre><code>output:\n  some_key:\n    some_other_key: !expr $.steps.some_step.outputs.success.some_value\n  foo: !expr $.inputs.bar\n  arca: \"flow\"\n</code></pre>"},{"location":"arcaflow/workflows/output/#writing-multiple-outputs","title":"Writing multiple outputs","text":"<p>Arcaflow can produce multiple output groups for a workflow. These output groups are mutually exclusive to each other.</p> <p>A common example of two mutually exclusive events could be the availability of your data storage service. Let\u2019s assume the service is either available, or unavailable (the unavailble state also includes any states where an error is thrown during data insertion). Multiple workflow outputs allows you to plan for these two events.</p> <p>In this example taken from the Arcaflow Workflows project, the <code>success</code> output collects the data from the specified steps and inserts it into data storage. The <code>no-indexing</code> output collects the data, the error logs, and does not store the data.</p> <pre><code>outputs:\n success:\n   pcp: !expr $.steps.pcp.outputs.success\n   sysbench: !expr $.steps.sysbench.outputs.success\n   metadata: !expr $.steps.metadata.outputs.success\n   opensearch: !expr $.steps.opensearch.outputs.success\n no-indexing:\n   pcp: !expr $.steps.pcp.outputs.success\n   sysbench: !expr $.steps.sysbench.outputs.success\n   metadata: !expr $.steps.metadata.outputs.success\n   no-index: !expr $.steps.opensearch.outputs.error\n</code></pre>"},{"location":"arcaflow/workflows/step/","title":"Writing workflow steps","text":"<p>If your input is complete, you can now turn to writing your workflow steps. You can connect workflow steps by using expressions. For example, if step <code>A</code> has an input that needs data from step <code>B</code>, Arcaflow will automatically run step <code>B</code> first.</p> <p>To define a step type, you can do the following:</p> workflow.yaml<pre><code>steps:\n  step_a: # Specify any ID here you want to reference the step by\n    plugin: quay.io/some/container/image # This must be an Arcaflow-compatible image\n    input: # specify input values as a data structure, mixing in expressions as needed\n      some:\n        key: !expr $.steps.step_b.outputs.success.some_value \n  step_b:\n    plugin: quay.io/some/container/image\n    input:\n      some:\n        key: !expr $.input.some_value # Reference an input value\n</code></pre>"},{"location":"arcaflow/workflows/step/#plugin-steps","title":"Plugin steps","text":"<p>Plugin steps run Arcaflow plugins in containers. They can use Docker, Podman, or Kubernetes as deployers. If no deployer is specified in the workflow, the plugin will use the local deployer.</p> <p>Plugin steps have the following properties:</p> Property Description <code>plugin</code> Full name of the container image to run. This must be an Arcaflow-compatible container image. <code>step</code> If a plugin provides more than one possible step, you can specify the step ID here. <code>deploy</code> Configuration for the deployer. (See below.) This can contain expressions, so you can dynamically specify deployment parameters. <code>input</code> Input data for the plugin. This can contain expressions, so you can dynamically define inputs. <p>You can reference plugin outputs in the format of <code>$.steps.your_step_id.outputs.your_plugin_output_id.some_variable</code>.</p>"},{"location":"arcaflow/workflows/step/#deployers","title":"Deployers","text":"<p>The <code>deploy</code> key for plugins lets you control how the plugin container is deployed. You can use expressions to use other plugins (e.g. the kubeconfig plugin) to generate the deployment configuration and feed it into other steps.</p> DockerPodmanKubernetes <p>You can configure the Docker deployer like this:</p> <pre><code>step:\n  your_step_id:\n    plugin: ...\n    input: ...\n    deploy: # You can use expressions here\n      type: docker\n      connection:\n        # Change this to point to a TCP-based Docker socket\n        host: host-to-docker\n        # Add a certificates here. This is usually needed in TCP mode.\n        cacert: |\n          Add your CA cert PEM here\n        cert: |\n          Add your client cert PEM here.\n        key: |\n          Add your client key PEM here.\n      deployment:\n        # For more options here see: https://docs.docker.com/engine/api/v1.42/#tag/Container/operation/ContainerCreate\n        container:\n          # Add your container config here.\n        host:\n          # Add your host config here.\n        network:\n          # Add your network config here\n        platform:\n          # Add your platform config here\n        imagePullPolicy: Always|IfNotPresent|Never\n      timeouts:\n        # HTTP timeout\n        http: 5s\n</code></pre> All options for the Docker deployer Type: <code>scope</code> Root object: Config Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) Objects Config (<code>object</code>) Type: <code>object</code> Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) Connection (<code>object</code>) Type: <code>object</code> Properties cacert (<code>string</code>) Name: CA certificate Description: CA certificate in PEM format to verify the Dockerd server certificate against. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> cert (<code>string</code>) Name: Client certificate Description: Client certificate in PEM format to authenticate against the Dockerd with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> host (<code>string</code>) Name: Host Description: Host name for Dockerd. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z0-9./:_-]&amp;#43;$</code> Default<pre><code>\"npipe:////./pipe/docker_engine\"\n</code></pre> Examples <pre><code>'unix:///var/run/docker.sock'\n</code></pre> <p>\u201d     <pre><code>'npipe:////./pipe/docker_engine'\n</code></pre></p> key (<code>string</code>) Name: Client key Description: Client private key in PEM format to authenticate against the Dockerd with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN ([A-Z]&amp;#43;) PRIVATE KEY-----(\\s*.*\\s*)*-----END ([A-Z]&amp;#43;) PRIVATE KEY-----\\s*$</code> Examples <pre><code>\"-----BEGIN PRIVATE KEY-----\\nMIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEArr89f2kggSO/yaCB\\n6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1nEiPnLbzDDgMU8KCPAMhI7JpYRlH\\nnipxWwIDAQABAkBybu/x0MElcGi2u/J2UdwScsV7je5Tt12z82l7TJmZFFJ8RLmc\\nrh00Gveb4VpGhd1+c3lZbO1mIT6v3vHM9A0hAiEA14EW6b+99XYza7+5uwIDuiM+\\nBz3pkK+9tlfVXE7JyKsCIQDPlYJ5xtbuT+VvB3XOdD/VWiEqEmvE3flV0417Rqha\\nEQIgbyxwNpwtEgEtW8untBrA83iU2kWNRY/z7ap4LkuS+0sCIGe2E+0RmfqQsllp\\nicMvM2E92YnykCNYn6TwwCQSJjRxAiEAo9MmaVlK7YdhSMPo52uJYzd9MQZJqhq+\\nlB1ZGDx/ARE=\\n-----END PRIVATE KEY-----\\n\"\n</code></pre> ContainerConfig (<code>object</code>) Type: <code>object</code> Properties Domainname (<code>string</code>) Name: Domain name Description: Domain name for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> Env (<code>map[string, string]</code>) Name: Environment variables Description: Environment variables to set on the plugin container. Required: No Key type Type: <code>string</code> Minimum: 1 Maximum: 255 Must match pattern: <code>^[A-Z0-9_]&amp;#43;$</code> Value type Type: <code>string</code> Maximum: 32760 Hostname (<code>string</code>) Name: Hostname Description: Hostname for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> MacAddress (<code>string</code>) Name: MAC address Description: Media Access Control address for the container. Required: No Must match pattern: <code>^[a-fA-F0-9]{2}(:[a-fA-F0-9]{2}){5}$</code> NetworkDisabled (<code>bool</code>) Name: Disable network Description: Disable container networking completely. Required: No User (<code>string</code>) Name: Username Description: User that will run the command inside the container. Optionally, a group can be specified in the user:group format. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z_][a-z0-9_-]*[$]?(:[a-z_][a-z0-9_-]*[$]?)$</code> Deployment (<code>object</code>) Type: <code>object</code> Properties container (<code>reference[ContainerConfig]</code>) Name: Container configuration Description: Provides information about the container for the plugin. Required: No Referenced object: ContainerConfig (see in the Objects section below) host (<code>reference[HostConfig]</code>) Name: Host configuration Description: Provides information about the container host for the plugin. Required: No Referenced object: HostConfig (see in the Objects section below) imagePullPolicy (<code>enum[string]</code>) Name: Image pull policy Description: When to pull the plugin image. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> network (<code>reference[NetworkConfig]</code>) Name: Network configuration Description: Provides information about the container networking for the plugin. Required: No Referenced object: NetworkConfig (see in the Objects section below) platform (<code>reference[PlatformConfig]</code>) Name: Platform configuration Description: Provides information about the container host platform for the plugin. Required: No Referenced object: PlatformConfig (see in the Objects section below) HostConfig (<code>object</code>) Type: <code>object</code> Properties CapAdd (<code>list[string]</code>) Name: Add capabilities Description: Add capabilities to the container. Required: No List Items Type: <code>string</code> CapDrop (<code>list[string]</code>) Name: Drop capabilities Description: Drop capabilities from the container. Required: No List Items Type: <code>string</code> CgroupnsMode (<code>enum[string]</code>) Name: CGroup namespace mode Description: CGroup namespace mode to use for the container. Required: No Values <ul> <li>`` Empty</li> <li><code>host</code> Host</li> <li><code>private</code> Private</li> </ul> Dns (<code>list[string]</code>) Name: DNS servers Description: DNS servers to use for lookup. Required: No List Items Type: <code>string</code> DnsOptions (<code>list[string]</code>) Name: DNS options Description: DNS options to look for. Required: No List Items Type: <code>string</code> DnsSearch (<code>list[string]</code>) Name: DNS search Description: DNS search domain. Required: No List Items Type: <code>string</code> ExtraHosts (<code>list[string]</code>) Name: Extra hosts Description: Extra hosts entries to add Required: No List Items Type: <code>string</code> NetworkMode (<code>string</code>) Name: Network mode Description: Specifies either the network mode, the container network to attach to, or a name of a Docker network to use. Required: No Must match pattern: <code>^(none|bridge|host|container:[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;|[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;)$</code> Examples <pre><code>\"none\"\n</code></pre> <p>\u201d     <pre><code>\"bridge\"\n</code></pre> \u201d     <pre><code>\"host\"\n</code></pre> \u201d     <pre><code>\"container:container-name\"\n</code></pre> \u201d     <pre><code>\"network-name\"\n</code></pre></p> PortBindings (<code>map[string, list[reference[PortBinding]]]</code>) Name: Port bindings Description: Ports to expose on the host machine. Ports are specified in the format of portnumber/protocol. Required: No Key type Type: <code>string</code> Must match pattern: <code>^[0-9]&amp;#43;(/[a-zA-Z0-9]&amp;#43;)$</code> Value type Type: <code>list[reference[PortBinding]]</code> List Items Type: <code>reference[PortBinding]</code> Referenced object: PortBinding (see in the Objects section below) NetworkConfig (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PlatformConfig (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PortBinding (<code>object</code>) Type: <code>object</code> Properties HostIP (<code>string</code>) Name: Host IP Required: No HostPort (<code>string</code>) Name: Host port Required: No Must match pattern: <code>^0-9&amp;#43;$</code> Timeouts (<code>object</code>) Type: <code>object</code> Properties http (<code>int</code>) Name: HTTP Description: HTTP timeout for the Docker API. Required: No Minimum: 100000000 Units: nanoseconds Default<pre><code>\"15s\"\n</code></pre> <p>If you want to use Podman as your local deployer, you can do so like this:</p> <pre><code>step:\n  your_step_id:\n    plugin: ...\n    input: ...\n    deploy: # You can use expressions here\n      type: podman\n      podman:\n        # Change where Podman is. (You can use this to point to a shell script\n        path: /path/to/your/podman\n        # Change the network mode\n        networkMode: host\n      deployment:\n        # For more options here see: https://docs.docker.com/engine/api/v1.42/#tag/Container/operation/ContainerCreate\n        container:\n          # Add your container config here.\n        host:\n          # Add your host config here.\n        imagePullPolicy: Always|IfNotPresent|Never\n      timeouts:\n        # HTTP timeout\n        http: 5s\n</code></pre> All options for the Podman deployer Type: <code>scope</code> Root object: Config Properties deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) podman (<code>reference[Podman]</code>) Name: Podman Description: Podman CLI configuration Required: No Referenced object: Podman (see in the Objects section below) Objects Config (<code>object</code>) Type: <code>object</code> Properties deployment (<code>reference[Deployment]</code>) Name: Deployment Description: Deployment configuration for the plugin. Required: No Referenced object: Deployment (see in the Objects section below) podman (<code>reference[Podman]</code>) Name: Podman Description: Podman CLI configuration Required: No Referenced object: Podman (see in the Objects section below) ContainerConfig (<code>object</code>) Type: <code>object</code> Properties Domainname (<code>string</code>) Name: Domain name Description: Domain name for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> Env (<code>list[string]</code>) Name: Environment variables Description: Environment variables to set on the plugin container. Required: No List Items Type: <code>string</code> Minimum: 1 Maximum: 32760 Must match pattern: <code>^.&amp;#43;=.&amp;#43;$</code> Hostname (<code>string</code>) Name: Hostname Description: Hostname for the plugin container. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-zA-Z0-9-_.]&amp;#43;$</code> MacAddress (<code>string</code>) Name: MAC address Description: Media Access Control address for the container. Required: No Must match pattern: <code>^[a-fA-F0-9]{2}(:[a-fA-F0-9]{2}){5}$</code> NetworkDisabled (<code>bool</code>) Name: Disable network Description: Disable container networking completely. Required: No User (<code>string</code>) Name: Username Description: User that will run the command inside the container. Optionally, a group can be specified in the user:group format. Required: No Minimum: 1 Maximum: 255 Must match pattern: <code>^[a-z_][a-z0-9_-]*[$]?(:[a-z_][a-z0-9_-]*[$]?)$</code> Deployment (<code>object</code>) Type: <code>object</code> Properties container (<code>reference[ContainerConfig]</code>) Name: Container configuration Description: Provides information about the container for the plugin. Required: No Referenced object: ContainerConfig (see in the Objects section below) host (<code>reference[HostConfig]</code>) Name: Host configuration Description: Provides information about the container host for the plugin. Required: No Referenced object: HostConfig (see in the Objects section below) imagePullPolicy (<code>enum[string]</code>) Name: Image pull policy Description: When to pull the plugin image. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> HostConfig (<code>object</code>) Type: <code>object</code> Properties Binds (<code>list[string]</code>) Name: Volume Bindings Description: Volumes Required: No List Items Type: <code>string</code> Minimum: 1 Maximum: 32760 Must match pattern: <code>^.&amp;#43;:.&amp;#43;$</code> CapAdd (<code>list[string]</code>) Name: Add capabilities Description: Add capabilities to the container. Required: No List Items Type: <code>string</code> CapDrop (<code>list[string]</code>) Name: Drop capabilities Description: Drop capabilities from the container. Required: No List Items Type: <code>string</code> CgroupnsMode (<code>enum[string]</code>) Name: CGroup namespace mode Description: CGroup namespace mode to use for the container. Required: No Values <ul> <li>`` Empty</li> <li><code>host</code> Host</li> <li><code>private</code> Private</li> </ul> Dns (<code>list[string]</code>) Name: DNS servers Description: DNS servers to use for lookup. Required: No List Items Type: <code>string</code> DnsOptions (<code>list[string]</code>) Name: DNS options Description: DNS options to look for. Required: No List Items Type: <code>string</code> DnsSearch (<code>list[string]</code>) Name: DNS search Description: DNS search domain. Required: No List Items Type: <code>string</code> ExtraHosts (<code>list[string]</code>) Name: Extra hosts Description: Extra hosts entries to add Required: No List Items Type: <code>string</code> NetworkMode (<code>string</code>) Name: Network mode Description: Specifies either the network mode, the container network to attach to, or a name of a Docker network to use. Required: No Must match pattern: <code>^(none|bridge|host|container:[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;|[a-zA-Z0-9][a-zA-Z0-9_.-]&amp;#43;)$</code> Examples <pre><code>\"none\"\n</code></pre> <p>\u201d     <pre><code>\"bridge\"\n</code></pre> \u201d     <pre><code>\"host\"\n</code></pre> \u201d     <pre><code>\"container:container-name\"\n</code></pre> \u201d     <pre><code>\"network-name\"\n</code></pre></p> PortBindings (<code>map[string, list[reference[PortBinding]]]</code>) Name: Port bindings Description: Ports to expose on the host machine. Ports are specified in the format of portnumber/protocol. Required: No Key type Type: <code>string</code> Must match pattern: <code>^[0-9]&amp;#43;(/[a-zA-Z0-9]&amp;#43;)$</code> Value type Type: <code>list[reference[PortBinding]]</code> List Items Type: <code>reference[PortBinding]</code> Referenced object: PortBinding (see in the Objects section below) Podman (<code>object</code>) Type: <code>object</code> Properties cgroupNs (<code>string</code>) Name: CGroup namespace Description: Provides the Cgroup Namespace settings for the container Required: No Must match pattern: <code>^host|ns:/proc/\\d&amp;#43;/ns/cgroup|container:.&amp;#43;|private$</code> containerName (<code>string</code>) Name: Container Name Description: Provides name of the container Required: No Must match pattern: <code>^.*$</code> imageArchitecture (<code>string</code>) Name: Podman image Architecture Description: Provides Podman Image Architecture Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"amd64\"\n</code></pre> imageOS (<code>string</code>) Name: Podman Image OS Description: Provides Podman Image Operating System Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"linux\"\n</code></pre> networkMode (<code>string</code>) Name: Network Mode Description: Provides network settings for the container Required: No Must match pattern: <code>^bridge:.*|host|none$</code> path (<code>string</code>) Name: Podman path Description: Provides the path of podman executable Required: No Must match pattern: <code>^.*$</code> Default<pre><code>\"podman\"\n</code></pre> PortBinding (<code>object</code>) Type: <code>object</code> Properties HostIP (<code>string</code>) Name: Host IP Required: No HostPort (<code>string</code>) Name: Host port Required: No Must match pattern: <code>^0-9&amp;#43;$</code> <p>The Kubernetes deployer deploys on top of Kubernetes. You can set up the deployer like this:</p> <pre><code>step:\n  your_step_id:\n    plugin: ...\n    input: ...\n    deploy: # You can use expressions here\n      type: kubernetes\n      connection:\n        host: localhost:6443\n        cert: |\n          Add your client cert in PEM format here.\n        key: |\n          Add your client key in PEM format here.\n        cacert: |\n          Add the server CA cert in PEM format here.\n</code></pre> All options for the Kubernetes deployer Type: <code>scope</code> Root object: Config Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) pod (<code>reference[Pod]</code>) Name: Pod Description: Pod configuration for the plugin. Required: No Referenced object: Pod (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) Objects AWSElasticBlockStoreVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> AzureDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> AzureFileVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CSIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CephFSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> CinderVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Config (<code>object</code>) Type: <code>object</code> Properties connection (<code>reference[Connection]</code>) Name: Connection Description: Docker connection information. Required: No Referenced object: Connection (see in the Objects section below) pod (<code>reference[Pod]</code>) Name: Pod Description: Pod configuration for the plugin. Required: No Referenced object: Pod (see in the Objects section below) timeouts (<code>reference[Timeouts]</code>) Name: Timeouts Description: Timeouts for the Docker connection. Required: No Referenced object: Timeouts (see in the Objects section below) ConfigMapVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Connection (<code>object</code>) Type: <code>object</code> Properties bearerToken (<code>string</code>) Name: Bearer token Description: Bearer token to authenticate against the Kubernetes API with. Required: No burst (<code>int</code>) Name: Burst Description: Burst value for query throttling. Required: No Minimum: 0 Default<pre><code>10\n</code></pre> cacert (<code>string</code>) Name: CA certificate Description: CA certificate in PEM format to verify Kubernetes server certificate against. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> cert (<code>string</code>) Name: Client certificate Description: Client certificate in PEM format to authenticate against Kubernetes with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN CERTIFICATE-----(\\s*.*\\s*)*-----END CERTIFICATE-----\\s*$</code> Examples <pre><code>\"-----BEGIN CERTIFICATE-----\\nMIIB4TCCAYugAwIBAgIUCHhhffY1lzezGatYMR02gpEJChkwDQYJKoZIhvcNAQEL\\nBQAwRTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM\\nGEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDAeFw0yMjA5MjgwNTI4MTJaFw0yMzA5\\nMjgwNTI4MTJaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEw\\nHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwXDANBgkqhkiG9w0BAQEF\\nAANLADBIAkEArr89f2kggSO/yaCB6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1\\nnEiPnLbzDDgMU8KCPAMhI7JpYRlHnipxWwIDAQABo1MwUTAdBgNVHQ4EFgQUiZ6J\\nDwuF9QCh1vwQGXs2MutuQ9EwHwYDVR0jBBgwFoAUiZ6JDwuF9QCh1vwQGXs2Mutu\\nQ9EwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAANBAFYIFM27BDiG725d\\nVkhRblkvZzeRHhcwtDOQTC9d8M/LymN2y0nHSlJCZm/Lo/aH8viSY1vi1GSHfDz7\\nTlfe8gs=\\n-----END CERTIFICATE-----\\n\"\n</code></pre> host (<code>string</code>) Name: Host Description: Host name and port of the Kubernetes server Required: No Default<pre><code>\"kubernetes.default.svc\"\n</code></pre> key (<code>string</code>) Name: Client key Description: Client private key in PEM format to authenticate against Kubernetes with. Required: No Minimum: 1 Must match pattern: <code>^\\s*-----BEGIN ([A-Z]&amp;#43;) PRIVATE KEY-----(\\s*.*\\s*)*-----END ([A-Z]&amp;#43;) PRIVATE KEY-----\\s*$</code> Examples <pre><code>\"-----BEGIN PRIVATE KEY-----\\nMIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEArr89f2kggSO/yaCB\\n6EwIQeT6ZptBoX0ZvCMI+DpkCwqOS5fwRbj1nEiPnLbzDDgMU8KCPAMhI7JpYRlH\\nnipxWwIDAQABAkBybu/x0MElcGi2u/J2UdwScsV7je5Tt12z82l7TJmZFFJ8RLmc\\nrh00Gveb4VpGhd1+c3lZbO1mIT6v3vHM9A0hAiEA14EW6b+99XYza7+5uwIDuiM+\\nBz3pkK+9tlfVXE7JyKsCIQDPlYJ5xtbuT+VvB3XOdD/VWiEqEmvE3flV0417Rqha\\nEQIgbyxwNpwtEgEtW8untBrA83iU2kWNRY/z7ap4LkuS+0sCIGe2E+0RmfqQsllp\\nicMvM2E92YnykCNYn6TwwCQSJjRxAiEAo9MmaVlK7YdhSMPo52uJYzd9MQZJqhq+\\nlB1ZGDx/ARE=\\n-----END PRIVATE KEY-----\\n\"\n</code></pre> password (<code>string</code>) Name: Password Description: Password for basic authentication. Required: No path (<code>string</code>) Name: Path Description: Path to the API server. Required: No Default<pre><code>\"/api\"\n</code></pre> qps (<code>float</code>) Name: QPS Description: Queries Per Second allowed against the API. Required: No Minimum: 0 Units: queries Default<pre><code>5.0\n</code></pre> serverName (<code>string</code>) Name: TLS server name Description: Expected TLS server name to verify in the certificate. Required: No username (<code>string</code>) Name: Username Description: Username for basic authentication. Required: No Container (<code>object</code>) Type: <code>object</code> Properties args (<code>list[string]</code>) Name: Arguments Description: Arguments to the entypoint (command). Required: No List Items Type: <code>string</code> command (<code>list[string]</code>) Name: Command Description: Override container entry point. Not executed with a shell. Required: No Minimum items: 1 List Items Type: <code>string</code> env (<code>list[object]</code>) Name: Environment Description: Environment variables for this container. Required: No List Items Type: <code>object</code> Properties name (<code>string</code>) Name: Name Description: Environment variables name. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> value (<code>string</code>) Name: Value Description: Value for the environment variable. Required: No valueFrom (<code>reference[EnvFromSource]</code>) Name: Value source Description: Load the environment variable from a secret or config map. Required: No Referenced object: EnvFromSource (see in the Objects section below) envFrom (<code>list[reference[EnvFromSource]]</code>) Name: Environment sources Description: List of sources to populate the environment variables from. Required: No List Items Type: <code>reference[EnvFromSource]</code> Referenced object: EnvFromSource (see in the Objects section below) image (<code>string</code>) Name: Image Description: Container image to use for this container. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9_\\-:./]&amp;#43;$</code> imagePullPolicy (<code>enum[string]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> name (<code>string</code>) Name: Name Description: Name for the container. Each container in a pod must have a unique name. Required: Yes Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> securityContext (<code>object</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Properties capabilities (<code>object</code>) Name: Capabilities Description: Add or drop POSIX capabilities. Required: No Properties add (<code>list[string]</code>) Name: Add Description: Add POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> drop (<code>list[string]</code>) Name: Drop Description: Drop POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> privileged (<code>bool</code>) Name: Privileged Description: Run the container in privileged mode. Required: No volumeDevices (<code>list[object]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No List Items Type: <code>object</code> Properties devicePath (<code>string</code>) Name: Device path Description: Path inside the container the device will be mapped to. Required: Yes Minimum: 1 name (<code>string</code>) Name: Name Description: Must match the persistent volume claim in the pod. Required: Yes Minimum: 1 volumeMounts (<code>list[object]</code>) Name: Volume mounts Description: Pod volumes to mount on this container. Required: No List Items Type: <code>object</code> Properties mountPath (<code>string</code>) Name: Mount path Description: Path to mount the volume on inside the container. Required: Yes Minimum: 1 name (<code>string</code>) Name: Volume name Description: Must match the pod volume to mount. Required: Yes Minimum: 1 readOnly (<code>bool</code>) Name: Read only Description: Mount volume as read-only. Required: No Default<pre><code>false\n</code></pre> subPath (<code>string</code>) Name: Subpath Description: Path from the volume to mount. Required: No Minimum: 1 workingDir (<code>string</code>) Name: Working directory Description: Override the container working directory. Required: No DownwardAPIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> EmptyDirVolumeSource (<code>object</code>) Type: <code>object</code> Properties medium (<code>string</code>) Name: Medium Description: How to store the empty directory Required: No Minimum: 1 Must match pattern: <code>^(|Memory|HugePages|HugePages-.*)$</code> EnvFromSource (<code>object</code>) Type: <code>object</code> Properties configMapRef (<code>object</code>) Name: Config map source Description: Populates the source from a config map. Required: No Properties name (<code>string</code>) Name: Name Description: Name of the referenced config map. Required: Yes Minimum: 1 optional (<code>bool</code>) Name: Optional Description: Specify whether the config map must be defined. Required: No prefix (<code>string</code>) Name: Prefix Description: An optional identifier to prepend to each key in the ConfigMap. Required: No Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> secretRef (<code>object</code>) Name: Secret source Description: Populates the source from a secret. Required: No Properties name (<code>string</code>) Name: Name Description: Name of the referenced secret. Required: Yes Minimum: 1 optional (<code>bool</code>) Name: Optional Description: Specify whether the secret must be defined. Required: No EphemeralVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FCVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FlexVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> FlockerVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> GCEPersistentDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> GlusterfsVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> HostPathVolumeSource (<code>object</code>) Type: <code>object</code> Properties path (<code>string</code>) Name: Path Description: Path to the directory on the host. Required: Yes Minimum: 1 Examples <pre><code>\"/srv/volume1\"\n</code></pre> type (<code>enum[string]</code>) Name: Type Description: Type of the host path. Required: No Values <ul> <li>`` Unset</li> <li><code>BlockDevice</code> Block device</li> <li><code>CharDevice</code> Character device</li> <li><code>Directory</code> Directory</li> <li><code>DirectoryOrCreate</code> Create directory if not found</li> <li><code>File</code> File</li> <li><code>FileOrCreate</code> Create file if not found</li> <li><code>Socket</code> Socket</li> </ul> ISCSIVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> NFSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ObjectMeta (<code>object</code>) Type: <code>object</code> Properties annotations (<code>map[string, string]</code>) Name: Annotations Description: Kubernetes annotations to appy. See https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/ for details. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> generateName (<code>string</code>) Name: Name prefix Description: Name prefix to generate pod names from. Required: No labels (<code>map[string, string]</code>) Name: Labels Description: Kubernetes labels to appy. See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ for details. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> name (<code>string</code>) Name: Name Description: Pod name. Required: No namespace (<code>string</code>) Name: Namespace Description: Kubernetes namespace to deploy in. Required: No Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> Default<pre><code>\"default\"\n</code></pre> PersistentVolumeClaimVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> PhotonPersistentDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Pod (<code>object</code>) Type: <code>object</code> Properties metadata (<code>reference[ObjectMeta]</code>) Name: Metadata Description: Pod metadata. Required: No Referenced object: ObjectMeta (see in the Objects section below) spec (<code>reference[PodSpec]</code>) Name: Specification Description: Pod specification. Required: No Referenced object: PodSpec (see in the Objects section below) PodSpec (<code>object</code>) Type: <code>object</code> Properties affinity (<code>object</code>) Name: Affinity rules Description: Affinity rules. Required: No Properties podAffinity (<code>object</code>) Name: Pod Affinity Description: The pod affinity rules. Required: No Properties requiredDuringSchedulingIgnoredDuringExecution (<code>list[object]</code>) Name: Required During Scheduling Ignored During Execution Description: Hard pod affinity rules. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties labelSelector (<code>object</code>) Name: MatchExpressions Description: Expressions for the label selector. Required: No Properties matchExpressions (<code>list[object]</code>) Name: MatchExpression Description: Expression for the label selector. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties key (<code>string</code>) Name: Key Description: Key for the label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> operator (<code>string</code>) Name: Operator Description: Logical operator for Kubernetes to use when interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt. Required: No Maximum: 253 Must match pattern: <code>In|NotIn|Exists|DoesNotExist|Gt|Lt</code> values (<code>list[string]</code>) Name: Values Description: Values for the label that the system uses to denote the domain. Required: No Minimum items: 1 List Items Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> topologyKey (<code>string</code>) Name: TopologyKey Description: Key for the node label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_./][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> podAntiAffinity (<code>object</code>) Name: Pod Affinity Description: The pod affinity rules. Required: No Properties requiredDuringSchedulingIgnoredDuringExecution (<code>list[object]</code>) Name: Required During Scheduling Ignored During Execution Description: Hard pod affinity rules. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties labelSelector (<code>object</code>) Name: MatchExpressions Description: Expressions for the label selector. Required: No Properties matchExpressions (<code>list[object]</code>) Name: MatchExpression Description: Expression for the label selector. Required: No Minimum items: 1 List Items Type: <code>object</code> Properties key (<code>string</code>) Name: Key Description: Key for the label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> operator (<code>string</code>) Name: Operator Description: Logical operator for Kubernetes to use when interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt. Required: No Maximum: 253 Must match pattern: <code>In|NotIn|Exists|DoesNotExist|Gt|Lt</code> values (<code>list[string]</code>) Name: Values Description: Values for the label that the system uses to denote the domain. Required: No Minimum items: 1 List Items Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> topologyKey (<code>string</code>) Name: TopologyKey Description: Key for the node label that the system uses to denote the domain. Required: No Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_./][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> containers (<code>list[reference[Container]]</code>) Name: Containers Description: A list of containers belonging to the pod. Required: No List Items Type: <code>reference[Container]</code> Referenced object: Container (see in the Objects section below) initContainers (<code>list[reference[Container]]</code>) Name: Init containers Description: A list of initialization containers belonging to the pod. Required: No List Items Type: <code>reference[Container]</code> Referenced object: Container (see in the Objects section below) nodeSelector (<code>map[string, string]</code>) Name: Labels Description: Node labels you want the target node to have. Required: No Key type Type: <code>string</code> Must match pattern: <code>^(|([a-zA-Z](|[a-zA-Z\\-.]{0,251}[a-zA-Z0-9]))/)([a-zA-Z](|[a-zA-Z\\\\-]{0,61}[a-zA-Z0-9]))$</code> Value type Type: <code>string</code> Maximum: 63 Must match pattern: <code>^(|[a-zA-Z0-9]&amp;#43;(|[-_.][a-zA-Z0-9]&amp;#43;)*[a-zA-Z0-9])$</code> pluginContainer (<code>object</code>) Name: Plugin container Description: The container to run the plugin in. Required: Yes Properties env (<code>list[object]</code>) Name: Environment Description: Environment variables for this container. Required: No List Items Type: <code>object</code> Properties name (<code>string</code>) Name: Name Description: Environment variables name. Required: Yes Minimum: 1 Must match pattern: <code>^[a-zA-Z0-9-._]&amp;#43;$</code> value (<code>string</code>) Name: Value Description: Value for the environment variable. Required: No valueFrom (<code>reference[EnvFromSource]</code>) Name: Value source Description: Load the environment variable from a secret or config map. Required: No Referenced object: EnvFromSource (see in the Objects section below) envFrom (<code>list[reference[EnvFromSource]]</code>) Name: Environment sources Description: List of sources to populate the environment variables from. Required: No List Items Type: <code>reference[EnvFromSource]</code> Referenced object: EnvFromSource (see in the Objects section below) imagePullPolicy (<code>enum[string]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Values <ul> <li><code>Always</code> Always</li> <li><code>IfNotPresent</code> If not present</li> <li><code>Never</code> Never</li> </ul> Default<pre><code>\"IfNotPresent\"\n</code></pre> name (<code>string</code>) Name: Name Description: Name for the container. Each container in a pod must have a unique name. Required: No Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> Default<pre><code>\"arcaflow-plugin-container\"\n</code></pre> securityContext (<code>object</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No Properties capabilities (<code>object</code>) Name: Capabilities Description: Add or drop POSIX capabilities. Required: No Properties add (<code>list[string]</code>) Name: Add Description: Add POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> drop (<code>list[string]</code>) Name: Drop Description: Drop POSIX capabilities. Required: No List Items Type: <code>string</code> Minimum: 1 Must match pattern: <code>^[A-Z_]&amp;#43;$</code> privileged (<code>bool</code>) Name: Privileged Description: Run the container in privileged mode. Required: No volumeDevices (<code>list[object]</code>) Name: Volume device Description: Mount a raw block device within the container. Required: No List Items Type: <code>object</code> Properties devicePath (<code>string</code>) Name: Device path Description: Path inside the container the device will be mapped to. Required: Yes Minimum: 1 name (<code>string</code>) Name: Name Description: Must match the persistent volume claim in the pod. Required: Yes Minimum: 1 volumeMounts (<code>list[object]</code>) Name: Volume mounts Description: Pod volumes to mount on this container. Required: No List Items Type: <code>object</code> Properties mountPath (<code>string</code>) Name: Mount path Description: Path to mount the volume on inside the container. Required: Yes Minimum: 1 name (<code>string</code>) Name: Volume name Description: Must match the pod volume to mount. Required: Yes Minimum: 1 readOnly (<code>bool</code>) Name: Read only Description: Mount volume as read-only. Required: No Default<pre><code>false\n</code></pre> subPath (<code>string</code>) Name: Subpath Description: Path from the volume to mount. Required: No Minimum: 1 volumes (<code>list[reference[Volume]]</code>) Name: Volumes Description: A list of volumes that can be mounted by containers belonging to the pod. Required: No List Items Type: <code>reference[Volume]</code> Referenced object: Volume (see in the Objects section below) PortworxVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ProjectedVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> QuobyteVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> RBDVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> ScaleIOVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> SecretVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> StorageOSVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p> Timeouts (<code>object</code>) Type: <code>object</code> Properties http (<code>int</code>) Name: HTTP Description: HTTP timeout for the Docker API. Required: No Minimum: 100000000 Units: nanoseconds Default<pre><code>\"15s\"\n</code></pre> Volume (<code>object</code>) Type: <code>object</code> Properties awsElasticBlockStore (<code>reference[AWSElasticBlockStoreVolumeSource]</code>) Name: AWS EBS Description: AWS Elastic Block Storage. Required: No Referenced object: AWSElasticBlockStoreVolumeSource (see in the Objects section below) azureDisk (<code>reference[AzureDiskVolumeSource]</code>) Name: Azure Data Disk Description: Mount an Azure Data Disk as a volume. Required: No Referenced object: AzureDiskVolumeSource (see in the Objects section below) azureFile (<code>reference[AzureFileVolumeSource]</code>) Name: Azure File Description: Mount an Azure File Service mount. Required: No Referenced object: AzureFileVolumeSource (see in the Objects section below) cephfs (<code>reference[CephFSVolumeSource]</code>) Name: CephFS Description: Mount a CephFS volume. Required: No Referenced object: CephFSVolumeSource (see in the Objects section below) cinder (<code>reference[CinderVolumeSource]</code>) Name: Cinder Description: Mount a cinder volume attached and mounted on the host machine. Required: No Referenced object: CinderVolumeSource (see in the Objects section below) configMap (<code>reference[ConfigMapVolumeSource]</code>) Name: ConfigMap Description: Mount a ConfigMap as a volume. Required: No Referenced object: ConfigMapVolumeSource (see in the Objects section below) csi (<code>reference[CSIVolumeSource]</code>) Name: CSI Volume Description: Mount a volume using a CSI driver. Required: No Referenced object: CSIVolumeSource (see in the Objects section below) downwardAPI (<code>reference[DownwardAPIVolumeSource]</code>) Name: Downward API Description: Specify a volume that the pod should mount itself. Required: No Referenced object: DownwardAPIVolumeSource (see in the Objects section below) emptyDir (<code>reference[EmptyDirVolumeSource]</code>) Name: Empty directory Description: Temporary empty directory. Required: No Referenced object: EmptyDirVolumeSource (see in the Objects section below) ephemeral (<code>reference[EphemeralVolumeSource]</code>) Name: Ephemeral Description: Mount a volume that is handled by a cluster storage driver. Required: No Referenced object: EphemeralVolumeSource (see in the Objects section below) fc (<code>reference[FCVolumeSource]</code>) Name: Fibre Channel Description: Mount a Fibre Channel volume that's attached to the host machine. Required: No Referenced object: FCVolumeSource (see in the Objects section below) flexVolume (<code>reference[FlexVolumeSource]</code>) Name: Flex Description: Mount a generic volume provisioned/attached using an exec based plugin. Required: No Referenced object: FlexVolumeSource (see in the Objects section below) flocker (<code>reference[FlockerVolumeSource]</code>) Name: Flocker Description: Mount a Flocker volume. Required: No Referenced object: FlockerVolumeSource (see in the Objects section below) gcePersistentDisk (<code>reference[GCEPersistentDiskVolumeSource]</code>) Name: GCE disk Description: Google Cloud disk. Required: No Referenced object: GCEPersistentDiskVolumeSource (see in the Objects section below) glusterfs (<code>reference[GlusterfsVolumeSource]</code>) Name: GlusterFS Description: Mount a Gluster volume. Required: No Referenced object: GlusterfsVolumeSource (see in the Objects section below) hostPath (<code>reference[HostPathVolumeSource]</code>) Name: Host path Description: Mount volume from the host. Required: No Referenced object: HostPathVolumeSource (see in the Objects section below) iscsi (<code>reference[ISCSIVolumeSource]</code>) Name: iSCSI Description: Mount an iSCSI volume. Required: No Referenced object: ISCSIVolumeSource (see in the Objects section below) name (<code>string</code>) Name: Name Description: The name this volume can be referenced by. Required: Yes Maximum: 253 Must match pattern: <code>^[a-z0-9]($|[a-z0-9\\-_]*[a-z0-9])$</code> nfs (<code>reference[NFSVolumeSource]</code>) Name: NFS Description: Mount an NFS share. Required: No Referenced object: NFSVolumeSource (see in the Objects section below) persistentVolumeClaim (<code>reference[PersistentVolumeClaimVolumeSource]</code>) Name: Persistent Volume Claim Description: Mount a Persistent Volume Claim. Required: No Referenced object: PersistentVolumeClaimVolumeSource (see in the Objects section below) photonPersistentDisk (<code>reference[PhotonPersistentDiskVolumeSource]</code>) Name: PhotonController persistent disk Description: Mount a PhotonController persistent disk as a volume. Required: No Referenced object: PhotonPersistentDiskVolumeSource (see in the Objects section below) portworxVolume (<code>reference[PortworxVolumeSource]</code>) Name: Portworx Volume Description: Mount a Portworx volume. Required: No Referenced object: PortworxVolumeSource (see in the Objects section below) projected (<code>reference[ProjectedVolumeSource]</code>) Name: Projected Description: Projected items for all in one resources secrets, configmaps, and downward API. Required: No Referenced object: ProjectedVolumeSource (see in the Objects section below) quobyte (<code>reference[QuobyteVolumeSource]</code>) Name: quobyte Description: Mount Quobyte volume from the host. Required: No Referenced object: QuobyteVolumeSource (see in the Objects section below) rbd (<code>reference[RBDVolumeSource]</code>) Name: Rados Block Device Description: Mount a Rados Block Device. Required: No Referenced object: RBDVolumeSource (see in the Objects section below) scaleIO (<code>reference[ScaleIOVolumeSource]</code>) Name: ScaleIO Persistent Volume Description: Mount a ScaleIO persistent volume. Required: No Referenced object: ScaleIOVolumeSource (see in the Objects section below) secret (<code>reference[SecretVolumeSource]</code>) Name: Secret Description: Mount a Kubernetes secret. Required: No Referenced object: SecretVolumeSource (see in the Objects section below) storageos (<code>reference[StorageOSVolumeSource]</code>) Name: StorageOS Volume Description: Mount a StorageOS volume. Required: No Referenced object: StorageOSVolumeSource (see in the Objects section below) vsphereVolume (<code>reference[VsphereVirtualDiskVolumeSource]</code>) Name: vSphere Virtual Disk Description: Mount a vSphere Virtual Disk as a volume. Required: No Referenced object: VsphereVirtualDiskVolumeSource (see in the Objects section below) VsphereVirtualDiskVolumeSource (<code>object</code>) Type: <code>object</code> Properties <p>None</p>"},{"location":"arcaflow/workflows/versioning/","title":"Workflow schema versions","text":""},{"location":"arcaflow/workflows/versioning/#valid-version-string","title":"Valid version string","text":"<p>All workflow schema versions conform to semantic version 2.0.0 with a major, minor, and patch version. In this document, since the prepended <code>v</code> is unnecessary it is not used. However, it is required as a value for the version key in your workflow file.</p> <p>Invalid version string for <code>workflow.yaml</code>.</p> <pre><code>version: 0.2.0\ninput:\nsteps:\noutputs:\n</code></pre> <p>Valid version string for <code>workflow.yaml</code>.</p> <pre><code>version: v0.2.0\ninput:\nsteps:\noutputs:\n</code></pre>"},{"location":"arcaflow/workflows/versioning/#supported-versions","title":"Supported versions","text":"<ul> <li>0.2.0</li> </ul>"},{"location":"arcaflow/workflows/versioning/#compatibility-matrix","title":"Compatibility Matrix","text":"Workflow schema version Arcaflow Engine release 0.2.0 0.9.0"},{"location":"arcaflow/workflows/versioning/#upgrading","title":"Upgrading","text":""},{"location":"arcaflow/workflows/versioning/#020","title":"0.2.0","text":"<p>For the configuration file, <code>config.yaml</code>, two types of deployers are now possible, <code>image</code> and <code>python</code>, so <code>deployer</code> has become <code>deployers</code>. Effectively, the <code>type</code> key has become the <code>deployer_name</code> key. The <code>deployer_name</code> key and value are required which means you must also have either the <code>image</code> key or the <code>python</code> key.</p> <pre><code>deployers:\n  image:\n    deployer_name: docker|podman|kubernetes\n  python:\n    deployer_name: python\n</code></pre> <p>For your workflow file, <code>workflow.yaml</code>, the <code>version</code> key and value are required, and they must be at the root of the file.</p> <pre><code>version: v0.2.0\ninputs: {}\nsteps: {}\noutputs: {}\n</code></pre>"},{"location":"arcalog/","title":"Arcalog: Assisted Root Cause Analysis for Your Logs","text":"<p>Arcalog is still in early development. A scientific paper describing the project is available as a preprint.</p> <p>The README contains a guide on how to use Arcalog to gather data as well as how to use the <code>--http</code> flag to run a minimal user interface for downloading individual build IDs from Prow.</p> <p>Pre-release developer documentation is also available if you want to use the early pre-release version of Arcalog to embed the data gathering steps into your own application.</p>"}]}